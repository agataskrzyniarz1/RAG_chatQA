user_input,retrieved_contexts,response,reference,faithfulness,answer_relevancy,context_precision,context_recall
What are the two main research objectives of this thesis?,"[""Headers: Introduction {#introduction .unnumbered} > Objectives {#objectives .unnumbered}\nHeaders: Introduction {#introduction .unnumbered} > Objectives {#objectives .unnumbered}\n\nThis research is structured around two main objectives. The first objective is a qualitative linguistic analysis of learners' productions. Upon completion of corpus processing and extraction of learners' utterances, the study aims to identify the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction. An additional goal is to investigate the influence of learners' native languages on error patterns, determining whether specific trends can be observed among groups sharing the same mother tongue.  \nThe second objective is the evaluation of the Whisper system's performance in transcribing Polish interlanguage. A key goal is to ensure that Whisper produces faithful transcriptions of learner speech, capturing the interlanguage exactly as spoken, including all deviations, errors, and disfluencies. This assessment examines the extent to which Whisper can accurately reflect learner utterances, while categorizing the types of outputs the system introduces. The qualitative analysis of these renderings will inform the limitations and strengths of Whisper in this context. Ultimately, the findings of this thesis aim to support potential adaptations to Whisper's architecture, enhancing its ability to transcribe Polish interlanguage precisely as articulated by the learner, thereby providing a reliable tool for second language acquisition research."", ""Headers: General Context > Context {#chap:articles} > Conclusions\nHeaders: General Context > Context {#chap:articles} > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Introduction\n\nThe first analysis conducted in this study focused on the non-standard forms made by learners. The primary objective was to identify the most common types of deviations produced by learners of Polish after a 14-hour course. In addition, the second goal was to investigate the potential influence of the learners' native languages on the nature of these productions. To facilitate a clearer visualization of deviations, a dedicated tool-platform will also be developed, enabling an easier and more systematic analysis of the data.""]","The two main research objectives of this thesis are:

1. A qualitative linguistic analysis of learners' productions, focusing on identifying the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction, as well as investigating the influence of learners' native languages on error patterns.

2. The evaluation of the Whisper system's performance in transcribing Polish interlanguage, aiming to ensure that Whisper produces faithful transcriptions of learner speech, capturing all deviations, errors, and disfluencies, and assessing its accuracy in reflecting learner utterances while informing potential adaptations to enhance its transcription capabilities for second language acquisition research.","The thesis has two main objectives. The first is to conduct a qualitative linguistic analysis of learners' productions to identify the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction, including investigating the influence of learners' native languages on error patterns. The second objective is to evaluate the Whisper ASR system's performance in transcribing Polish interlanguage, assessing the extent to which Whisper can faithfully reproduce learner speech including all deviations, errors, and disfluencies.",1.0,0.9580117919229493,0.9999999999666667,1.0
What is interlanguage and why is it relevant to this study?,"['Headers: General Context > Context {#chap:articles} > Interlanguage in Second Language Acquisition > Definition of Interlanguage\nHeaders: General Context > Context {#chap:articles} > Interlanguage in Second Language Acquisition > Definition of Interlanguage\n\n*Interlanguage* is a concept introduced by [@selinker-1972] to describe the linguistic system that emerges when an adult learns a second language. It refers to a transitional linguistic system developed by the learner to communicate in the target language. This system is shaped by several factors, including the target language and the learner\'s native language [@tarone-2006]. In other words, interlanguage represents a transitional stage situated between the target language -- through the partial application of its lexical items and grammatical rules -- and the native language, from which the learner may potentially transfer previously acquired structures and patterns. As a result, interlanguage is typically marked by a high frequency of variations from the norm [@tarone-2006], reflecting its evolving and dynamic nature.  \n![Diagram of Interlanguage (Source: [@selinker-1972])](photos/interlanguage.png){#fig:interlanguage width=""60%""}', ""Headers: General Context > Context {#chap:articles} > Conclusions\nHeaders: General Context > Context {#chap:articles} > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", 'Headers: General Context > Context {#chap:articles} > Introduction\nHeaders: General Context > Context {#chap:articles} > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","Interlanguage is a concept introduced by (Selinker, 1972) that describes the linguistic system emerging when an adult learns a second language. It is a transitional linguistic system developed by the learner for communication in the target language, shaped by factors such as the target language and the learner's native language (Tarone, 2006). This system reflects a stage situated between the target language and the native language, characterized by the partial application of lexical items and grammatical rules from both languages, leading to variations from the norm (Tarone, 2006).

This study is relevant to interlanguage as it delves into the challenges faced by learners of Polish, particularly concerning its phonetics and morphosyntax, and explores the systematic nature of interlanguage in adult second language acquisition. The presentation of the VILLA project and the Route Direction task provides a methodological framework for analyzing learner language patterns, highlighting the potential of automatic tools to process interlanguage data. Thus, understanding interlanguage is essential for comprehending the learner's difficulties and for conducting effective error analysis within the study.","Interlanguage is a concept introduced by Selinker to describe the transitional linguistic system that emerges when an adult learns a second language. It represents a stage situated between the target language (through partial application of its lexical items and grammatical rules) and the native language (from which the learner may transfer previously acquired structures and patterns). Interlanguage is typically marked by a high frequency of variations from the norm, reflecting its evolving and dynamic nature. This concept is central to the study because the thesis analyzes non-standard forms produced by Polish learners, and evaluates whether ASR tools can faithfully capture these interlanguage features rather than automatically correcting them.",1.0,0.7442814395156523,0.9999999999666667,0.75
What are the main linguistic challenges that Polish presents to foreign language learners?,"['Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n::: {#tab:forms}\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', ""Headers: Experimentations > General conclusion {#general-conclusion .unnumbered}\nHeaders: Experimentations > General conclusion {#general-conclusion .unnumbered}\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy.""]","The main linguistic challenges that Polish presents to foreign language learners include:

1. **Phonological System**: Polish has numerous sounds that are absent in many other languages, making its phonological system particularly difficult to acquire. For example, complex consonant clusters and unfamiliar sounds pose challenges for pronunciation. A specific instance is the verb *skręcić* (""to turn""), which features a challenging initial consonant cluster (*skr*-) and requires precise articulation of sounds like the nasal vowel *ę* and soft *ć* at the end (Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations).

2. **Grammar**: Polish grammar is complicated, especially due to its intricate system of case inflection. This grammatical complexity contributes to the numerous errors learners are expected to produce, especially after limited exposure (Experimentations > Corpus {#chap:corpus} > Learner Corpus).

3. **Pronunciation Errors**: Errors in pronunciation are regularly indicated through Polish spelling rather than phonetic transcription. These errors result from challenges in articulating certain sounds, leading to distorted forms in learners' speech (Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations).

The study highlights that these challenges significantly affect language acquisition, particularly for learners with no prior exposure to Slavic languages (Experimentations > General conclusion {#general-conclusion .unnumbered}).","Polish presents several major challenges for learners:
- **Phonological challenges:** Polish contains phonemes not present in many Western languages, including retroflex consonants, nasal vowels, and complex consonant clusters that are difficult to articulate.
- **Morphological challenges:** The Polish case system is highly complex, with seven grammatical cases (nominative, genitive, dative, accusative, instrumental, locative, and vocative). The inflectional forms depend on grammatical gender, phonetic factors, and semantic categories such as animacy.
- **Orthographic challenges:** The language uses the Latin alphabet enriched with diacritical marks and digraphs that represent single sounds.",1.0,1.0,0.8333333332916666,0.75
What is the VILLA project and how does it provide data for this thesis?,"['Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\n\nAt the end of the course, the students\' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \n![Map for the Route Direction task](photos/route-direction.png){#fig:Route Direction width=""60%""}  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work.', 'Headers: General Context > Context {#chap:articles} > Introduction\nHeaders: General Context > Context {#chap:articles} > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","The VILLA project, titled ""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation,"" investigates the initial stages of foreign language acquisition under controlled input conditions. Conducted by (Dimroth et al., 2013), it focused on complete beginners from various linguistic backgrounds—Dutch, English, French, German, and Italian—who underwent 14 hours of instruction in Polish as a foreign language. The project involved communication-based classes taught by native Polish teachers, utilizing visual aids and interactive methods, with participants not allowed to take notes or consult additional resources. 

Participants were divided into subgroups based on similar profiles, and their language skills were assessed through tasks such as *Route Direction*, which required them to give directions using a map. The oral productions during these tests were recorded and transcribed, forming the corpus analyzed in this thesis. This corpus provides essential data for conducting automatic transcription and error analysis of Polish interlanguage (Dimroth et al., 2013).","The VILLA project (Varieties of Initial Learners in Language Acquisition) investigated the initial stages of foreign language acquisition under controlled input conditions. It involved complete beginners from five linguistic backgrounds (Dutch, English, French, German, and Italian) who received 14 hours of Polish instruction from native teachers using communication-based methods. Participants were university students with no prior knowledge of Polish or other Slavic languages. The classes were monolingual, and learners were not allowed to take notes. The thesis specifically uses recordings from the Route Direction task, where students had to give directions from point A to point B using a map, speaking Polish independently without help.",1.0,0.5679295481768853,0.9999999999666667,1.0
Why is automatic speech recognition (ASR) particularly challenging when applied to second language learner speech?,"['Headers: General Context > State of the Art {#chap:methodes} > Introduction\nHeaders: General Context > State of the Art {#chap:methodes} > Introduction\n\nAutomatic Speech Recognition (ASR) has undergone remarkable progress in recent decades, evolving from early systems limited to a small set of commands to deep learning--based models capable of handling spontaneous, continuous speech in real-world conditions. While ASR technologies are now widely applied in domains such as virtual assistants, customer service, and accessibility tools, their use in second language (L2) learning and assessment still requires careful evaluation of their performance.', 'Headers: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech\n\nASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. For example, the system might produce incorrect text or suggest pronunciation corrections that do not match the learner\'s actual production, potentially providing misleading guidance. However, continuous improvements in machine learning and the increasing availability of diverse speech data have significantly reduced the accuracy gap between native and non-native recognition (e.g., Google ASR reduced this gap from 20% to 3--5%) [@gottardi; @https://doi.org/10.1002/tesq.3006].  \nRecent research highlights both the potential and the challenges of using automatic speech recognition (ASR) for pronunciation training. [@michot2024errorpreservingautomaticspeechrecognition] addressed the crucial issue of designing an ASR system that not only transcribes learner speech accurately but also preserves their errors, thus enabling effective corrective feedback. To this end, they collected approximately 85 hours of spontaneous English speech from Swiss learners in grades 4--6 (about 45,000 utterances) and manually transcribed it with explicit error annotations. They proposed a new evaluation metric, the Word-Based Error Preservation Rate (WEPR), to measure the extent to which ASR systems maintain learner errors instead of automatically ""correcting"" them. Their findings demonstrated that a fine-tuned ASR model, trained directly on children\'s data, achieved a substantially higher WEPR and lower Word Error Rate (WER) than off-the-shelf systems, underscoring the promise of error-preserving ASR for pedagogical purposes.', 'Headers: General Context > State of the Art {#chap:methodes} > Conclusions\nHeaders: General Context > State of the Art {#chap:methodes} > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.']","Automatic Speech Recognition (ASR) is particularly challenging when applied to second language (L2) learner speech for several reasons. Primarily, ASR systems are trained on native speech, which leads to poor performance with non-native input. This results in lower transcription accuracy and inaccurate evaluations of learner speech. For instance, ASR systems might produce incorrect text or suggest pronunciation corrections that do not align with the learner's actual production, providing misleading guidance.

Moreover, the complexity of L2 learner speech is compounded by additional factors such as the rich morphology, free word order, and complex phonetics of certain languages, like Polish. Early ASR systems showed potential but were often insufficiently robust, while modern end-to-end models risk excessive normalization of learner outputs. These challenges necessitate fine-tuning ASR models on learner corpora to better capture learner-specific patterns rather than erasing them, making the task of developing effective ASR systems for L2 learners particularly complex (Michot et al., 2024).","ASR systems are trained primarily on native speech and tend to perform poorly with non-native input because learners' productions exhibit variations that differ from native speakers, which standard ASR systems are not trained to recognize. This can result in lower transcription accuracy and inaccurate evaluations of learner speech. A critical issue is that ASR systems often 'overcorrect' or 'hyper-normalize' learner speech by automatically correcting errors, introducing hallucinations, or omitting disfluencies. This behavior compromises reliability for second language acquisition research, since deviations from the target norm are precisely the phenomena under investigation.",1.0,0.8527549639143114,0.9999999999666667,0.75
What is Whisper and why was it chosen for evaluation in this study?,"['Headers: General Context > State of the Art {#chap:methodes} > The Whisper Model\nHeaders: General Context > State of the Art {#chap:methodes} > The Whisper Model\n\nWhisper [@radford2022robustspeechrecognitionlargescale] represents a new generation of ASR: a transformer encoder--decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. Models are released in multiple sizes, enabling a balance between speed and accuracy.  \nFor L2 speech, Whisper performs better than many commercial systems, but it often \\""over-corrects\\"" learner speech -- for example, restoring omitted particles or ignoring disfluencies. This behavior, observed in L2 French [@elayari:hal-04769687], risks erasing the very interlanguage phenomena. In the context of Polish, such normalization could obscure substitutions of nasal vowels or partial palatalization.  \nNevertheless, Whisper\'s open-source nature, high baseline accuracy, and multilingual scope make it an attractive candidate for adaptation. With targeted fine-tuning on learner corpora, it could become a powerful tool for L2 research.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena.""]","Whisper (Radford et al., 2022) is a transformer encoder–decoder model trained on 680,000 hours of multilingual data, representing a new generation of Automatic Speech Recognition (ASR). It directly predicts text tokens from log-Mel spectrograms, unlike traditional HMM-based systems, which contributes to its robustness across various domains, languages, and accents. Whisper was chosen for evaluation in this study due to its high baseline accuracy, multilingual scope, and open-source nature, making it an attractive candidate for adaptation. The study specifically focuses on its performance in transcribing Polish interlanguage, assessing its ability to faithfully reproduce learners' speech, including errors and non-standard forms, which is essential for understanding learner speech behavior.","Whisper is an end-to-end ASR system developed by OpenAI, representing a new generation of automatic speech recognition. It is a transformer encoder-decoder model trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. It was chosen for this study because of its open-source nature, high baseline accuracy, multilingual scope, and potential for adaptation through fine-tuning. These characteristics make it an attractive candidate for processing Polish interlanguage.",1.0,0.9940884016405094,0.9999999999666667,0.8
What corpus was used in this study and how was it composed?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus {#chap:corpus} > Introduction\nHeaders: Experimentations > Corpus {#chap:corpus} > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', ""Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n::: {#tab:recordings}\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::""]","The corpus used in this study consists of a learner corpus derived from the VILLA project and a smaller native speaker corpus for comparative purposes. The learner corpus is made up of manual transcriptions of voice recordings from the Route Direction task, transcribed by the author, who is a native speaker of Polish, using ELAN software. It includes both parallel tiers: **\*STU**, which reflects the learners' utterances, and **%pol**, which represents corrected versions in standard Polish.

The dataset contains 89 files with a total duration of 2 hours and 19 minutes of recordings, and it focuses on data from meaning-based groups across five countries (France, Italy, Netherlands, England, and Germany), while excluding the limited data from form-based groups and children. Each country has a similar structure of data including audio recordings (`.wav`), manual transcriptions (`.eaf`), and automatic transcriptions generated by Whisper (`.txt`). The annotation and preprocessing pipeline integrated multiple data sources into a structured JSON file, providing a reliable foundation for further linguistic error evaluation and ASR tool performance assessment {#chap:corpus}.","The corpus consists of manual transcriptions of voice recordings from the Route Direction task in the VILLA project. Key characteristics include:
- **Learner corpus:** 89 files totaling 2 hours and 19 minutes of recordings from meaning-based groups across five countries (France, Italy, Netherlands, England, and Germany)
- **Native speaker corpus:** A smaller reference corpus from four native Polish speakers
- **Transcription format:** Each file includes two parallel tiers—*STU (manual transcriptions reflecting exactly what learners said) and %pol (corrected versions in standard Polish)
- **Scope:** Only adult learners from meaning-based instruction groups were included to maintain balance and due to limited availability of form-based group recordings",1.0,0.8816991217711582,0.9999999999666667,0.6666666666666666
What is the composition of the learner corpus used in this study in terms of countries and total recording duration?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n::: {#tab:recordings}\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus {#chap:corpus} > Introduction\nHeaders: Experimentations > Corpus {#chap:corpus} > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.']","The composition of the learner corpus used in this study includes data from five countries along with their total recording durations:

- **France**: 17 files, 23 minutes 32 seconds
- **Italy**: 17 files, 26 minutes 39 seconds
- **Netherlands**: 18 files, 28 minutes 34 seconds
- **England**: 17 files, 29 minutes 34 seconds
- **Germany**: 20 files, 30 minutes 42 seconds  

In total, the learner corpus consists of 89 files and 2 hours and 19 minutes of recordings across these countries.","The learner corpus includes recordings from five countries with the following distribution:

| Country     | Number of files | Total duration          |
|-------------|-----------------|-------------------------|
| France      | 17              | 23 minutes 32 seconds   |
| Italy       | 17              | 26 minutes 39 seconds   |
| Netherlands | 18              | 28 minutes 34 seconds   |
| England     | 17              | 29 minutes 34 seconds   |
| Germany     | 20              | 30 minutes 42 seconds   |

The total corpus amounts to 89 files and 2 hours and 19 minutes of recordings.",0.8888888888888888,0.7859200497387703,0.99999999995,0.875
Why were learner productions transcribed using standard Polish orthography rather than the International Phonetic Alphabet (IPA)?,"['Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThere are a few reasons why the recordings were transcribed in accordance with standard Polish orthography instead of the phonetic alphabet. Firstly, manual transcription is a very tedious and time-consuming process that requires a lot of attention. Consequently, the annotation rules should be as simple and intuitive as possible [@Grochola-Szczepanek_Woźniak_2018]. In addition, full phonemic transcription using the IPA would have been significantly more time-consuming. Given the limited time, this would have led to a substantial reduction in the size of the corpus. Moreover, such transcription facilitates processing by automated tools. Only general orthographic transcription allows the use of tools such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection, which are designed for standard orthography. Finally, the corpus and the analysis are intended for further work by other researchers in the laboratory, not only phoneticians and phonologists.  \nNevertheless, in the subsequent analysis of phonetic errors, the orthographic representations were automatically converted into IPA symbols to enable a more precise visualization of pronunciation deviations.  \nThe same task was also carried out by four native Polish speakers, whose utterances were recorded and transcribed following the same procedure as for the learner corpus. While this native speaker corpus is significantly smaller in size, it serves as a reference point for the subsequent evaluation of the performance of automatic linguistic tools.', 'Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n::: {#tab:forms}\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', ""Headers: Experimentations > General conclusion {#general-conclusion .unnumbered}\nHeaders: Experimentations > General conclusion {#general-conclusion .unnumbered}\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy.""]","Learner productions were transcribed using standard Polish orthography rather than the International Phonetic Alphabet (IPA) for several reasons:

1. **Manual Transcription Challenges**: Transcription is a tedious and time-consuming process, requiring significant attention. Simple and intuitive annotation rules were deemed necessary to facilitate this task (Grochola-Szczepanek and Woźniak, 2018).

2. **Time Constraints**: Full phonemic transcription using IPA would have taken significantly more time, which could have resulted in a substantial reduction in the size of the corpus.

3. **Processing Compatibility**: Standard orthographic transcription allows for the use of automated tools designed for tasks such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection, which are compatible with orthographic norms.

4. **Broader Research Accessibility**: The corpus and analysis are intended for use by various researchers in the laboratory, not exclusively by phoneticians and phonologists, making standard orthography more accessible.

Additionally, for the analysis of phonetic errors, the orthographic representations were later converted into IPA symbols to enable precise visualization of pronunciation deviations.","Several reasons justified using standard Polish orthography:
1. Manual transcription is time-consuming, so annotation rules needed to be simple and intuitive
2. Full phonemic IPA transcription would have significantly reduced the corpus size given time constraints
3. Standard orthography enables processing by automated tools such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection
4. The corpus is intended for further work by researchers who may not be phoneticians

However, for the subsequent phonetic error analysis, orthographic representations were automatically converted into IPA symbols to enable more precise visualization of pronunciation deviations.",1.0,0.9986522094098746,0.9999999999666667,1.0
How were learner errors classified and what were the two main categories?,"['Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations > Corpus Processing\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations > Corpus Processing\n\n: Excerpt: Distribution of correct vs. erroneous forms and example words per learner country\n:::  \nNevertheless, this way of presenting phonetic errors is not ideal. For future linguistic analysis, it is crucial to retain information about the specific words in which a given phonetic error occurred, as this can help identify underlying factors such as native language interference or target language influence. While in this representation we can see which words contained a particular phoneme error, it does not indicate whether all learners actually mispronounced those words. For instance, in the first example, one learner might have pronounced Juliusza correctly but made an error in proszę. Although this representation already offers some insights, it lacks precision and may not be sufficiently informative for in-depth phonetic analysis or error pattern discovery.  \nWe developped a second method of grouping pronunciation errors involved organizing them by lemma in order to identify recurring mispronunciations of the same lexical item. For each entry, the script extracts the lemma of the correct form using the Polish *spaCy* model. Then, it groups all instances that share the same lemma, correct form, and corresponding erroneous pronunciation. Within each group, it aggregates the different correct and incorrect forms as well as the learner IDs associated with the error. As always, the script also shows the number of learners from each country and the total number of learners for each error.', ""Headers: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\n\nA key question in designing such a system is whether it should be tailored to learners of a specific native language or whether a more general model would suffice. On the one hand, the error analysis in this study shows that speakers of different native languages often exhibit consistent patterns, particularly in pronunciation. This suggests that separate models for pronunciation errors could be developed for different L1 groups, although some errors may also be universal across learners. On the other hand, case-related errors appear to be largely independent of the learner's native language, indicating that a universal model would likely be sufficient for handling morphological deviations.  \nA major challenge remains the inherently dynamic and individual nature of interlanguage. Learners follow unique developmental trajectories, and errors evolve over time depending on exposure, proficiency, and learning strategies. This raises questions about whether separate corpora or models would be needed for different proficiency levels, which would significantly increase data requirements and necessitate careful learner selection.  \nFinally, the corpus used in this study is highly task-specific, focusing exclusively on giving and understanding route directions. To develop a more robust and generalizable interlanguage-adapted Whisper, training data would need to cover a broader variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across different communicative situations.""]","Learner errors were classified into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. This classification was based on the nature of the task, where learners were reproducing utterances heard from native Polish speakers rather than memorizing grammatical rules or case endings, leading to errors stemming from inaccurate pronunciation or misusage of case endings {#chap:resultats}.","Learner errors were classified into two main categories based on the nature of the Route Direction task:
1. **Declension errors:** Incorrect grammatical case inflections, since learners needed to use correctly inflected forms in their utterances
2. **Pronunciation errors:** Deviations in how learners articulated Polish sounds

This classification was appropriate because learners were reproducing utterances they had previously heard and repeated after native Polish speakers rather than learning grammatical rules explicitly. Therefore, their errors typically stemmed from either inaccurate pronunciation or misusage of case endings.",1.0,0.8767264931096355,0.9999999999,0.8
What patterns emerged from the analysis of declension errors made by learners?,"['Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\n\nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1.""]","From the analysis of declension errors, several key patterns emerged:

1. **Overuse of the Nominative Case**: Learners tended to overgeneralize the nominative case, which is the default form in Polish, to contexts where other grammatical cases were required.

2. **Confusion Among Cases**: There was frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their similar morphological suffixes, making them challenging to acquire.

3. **Limited Influence of Native Language**: The analysis indicated that the learners' native languages did not significantly influence their case-related errors. Instead, challenges arose more from the inherent complexity of the Polish case system itself.

4. **Impact of Pedagogical Approaches**: The method employed focused on auditory learning through exposure to native speaker input and repetition, which may have mitigated potential native language transfer in declension errors.

These findings suggest that case-related difficulties are primarily linked to the complexity of the Polish language rather than the learners' first languages {#chap:resultats}.","The analysis revealed several key patterns in declension errors:
- **Overuse of nominative:** Learners massively overused the nominative case (941.67% relative increase), as it is the default 'base' form they are most familiar with
- **Underuse of genitive and instrumental:** The genitive was underused by 95.28% and instrumental by 88.14%, despite being the most frequently required cases in the task
- **Case confusion:** Common confusions occurred between genitive, instrumental, and locative cases due to their morphologically similar suffixes
- **Limited L1 influence:** Little evidence suggested that learners' native languages significantly influenced case-related errors; errors appeared to reflect universal developmental patterns and the inherent complexity of the Polish case system rather than cross-linguistic transfer",1.0,0.8185292715992645,0.9999999999666667,0.8
What pronunciation difficulties were most commonly observed among learners?,"[""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations > Results\n\nThe five most frequent pronunciation errors observed in the learner corpus reveal recurring patterns and potential phonological challenges, most likely influenced by the learners' native languages. The most common error concerned the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups, with the highest number found among German speakers (10); however, all groups exhibited this error at some point. The second most common error involved the replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, where learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/. This suggests difficulty in distinguishing between retroflex and alveolar fricatives. Once again, German speakers accounted for the highest number of errors (10), while French learners made the fewest (2). A similar phenomenon appeared in the third error, where the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/ was omitted, resulting in the simplified form *iś* /iɕ/, produced by 25 learners. This pattern may indicate difficulty pronouncing complex affricates in word-final position. Interestingly, the English group committed this error most frequently (11), whereas it was least common among German learners (1). The fourth error again reflected confusion between retroflex and alveolar consonants: *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This error was most common among Dutch speakers (9) and was not observed at all in the English group. An interesting case worth mentioning, although it ranks only thirteenth most frequent error,"", 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.']","The most commonly observed pronunciation difficulties among learners included:

1. **Substitution of /w/ with /l/**: This error was particularly noted in the word *szkoły* /ʂkɔwɨ/, frequently realized as forms like *skola* /skɔla/ and *szkole* /ʂkɔlɛ/. It was made by 32 learners, primarily among German speakers (10) {#chap:resultats}.

2. **Replacement of /ʂ/ with /s/**: In the word *szpital* /ʂpital/, learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/, suggesting confusion between retroflex and alveolar fricatives. German speakers accounted for the most errors (10), while French learners had the fewest (2) {#chap:resultats}.

3. **Omission of the affricate /t͡ɕ/**: This occurred in the verb *iść* /iɕt͡ɕ/, where a simplified form *iś* /iɕ/ was produced by 25 learners. The English group made this error most frequently (11), and it was least common among German learners (1) {#chap:resultats}.

4. **Confusion between retroflex and alveolar consonants**: The word *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This was most common among Dutch speakers (9) and was not seen in the English group {#chap:resultats}.

Additionally, challenges with complex consonant clusters and unfamiliar sounds were highlighted, such as in the verb *skręcić* (\""to turn\""), which features a difficult consonant cluster at the beginning and specific nasal vowels and soft consonants that may not exist in learners' native languages {#chap:resultats}.","The most common pronunciation difficulties included:
- **Retroflex consonants:** Substitution of retroflex /ʂ/ with alveolar /s/ (e.g., *szpital* → *spital*) and /ʐ/ with /z/
- **The phoneme /w/ (spelled ł):** Frequently replaced with /l/ (e.g., *szkoły* /ʂkɔwɨ/ → *skola* /skɔla/)
- **Complex affricates:** Difficulty with /t͡ɕ/ in word-final position, often omitted entirely (e.g., *iść* → *iś*)
- **Affricate confusion:** Replacement of /t͡ʂ/ with /ʂ/ (e.g., *cztery* → *sztere*)
- **Nasal vowels:** Tendency to replace nasal vowel /ɔ̃w̃/ with /ɔn/ (particularly among Italian learners)

These patterns suggest learners substitute unfamiliar Polish sounds with more familiar ones from their native phonological inventories.",,0.9168695085216858,0.9999999999666667,0.7142857142857143
How did Whisper perform overall on Polish interlanguage compared to native Polish speech?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner\'s pronunciation and the model\'s output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper\'s inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena.""]",This question is not related to the provided thesis context.,"Whisper showed significantly different performance between learner and native speech:

| Metric | Interlanguage | Native Polish |
|--------|---------------|---------------|
| WER (mean) | 75.4% | 13.74% |
| CER (mean) | 46.4% | 6.44% |
| WER (median) | 50% | — |
| CER (median) | 22.2% | — |

The native Polish WER of 10-20% is considered good performance, indicating Whisper can reliably transcribe standard Polish. The stark difference clearly illustrates the impact of interlanguage on ASR performance, highlighting challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns.",0.0,0.0,0.9999999999666667,0.25
What were the global WER and CER results for Whisper when transcribing Polish interlanguage compared to native Polish speech?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\n\nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\n\n::: {#tab:global_statistics}\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \n![WER and CER results on the global corpus](photos/wer_cer_comparison.png){#fig:wer_cer width=""100%""}  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \n$$WER = \\frac{S + D + I}{N_{\\text{words}}}$$  \n$$CER = \\frac{S + D + I}{N_{\\text{characters}}}$$  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance.""]","The global WER for Whisper when transcribing Polish interlanguage was 75.4%, while the CER was 46.4%. In contrast, evaluation on the small corpus of native Polish speech revealed a WER of 13.74% and a CER of 6.44% {#chap:discussion}. This stark difference highlights the challenges Whisper faces with interlanguage due to factors like non-native pronunciation and variable articulation.","For Polish interlanguage, Whisper achieved an average WER of 75.4% and an average CER of 46.4%, with median values of 50% for WER and 22.2% for CER. In contrast, for native Polish speech, Whisper achieved substantially lower error rates with a WER of 13.74% and a CER of 6.44%.",1.0,0.9354243918825326,0.9999999999666667,1.0
How did Whisper's transcription behavior differ between pronunciation-related and declension-related learner errors?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.']","Whisper's transcription behavior exhibited distinct differences between pronunciation-related and declension-related learner errors. For pronunciation errors, the system often overcorrected learner speech, reproducing canonical forms rather than the actual interlanguage output, resulting in a low faithful reproduction rate of 10.88%. In contrast, for declension errors, Whisper was more faithful, reproducing 42.10% of the learners' erroneous forms accurately. However, it also generated invented forms in 20.57% of cases and overcorrections in 21.71%, where it replaced the learner's form with a different, correct form, potentially obscuring the actual interlanguage patterns. This indicates that Whisper's architecture is better suited for detecting grammatical errors than phonetic inaccuracies, highlighting the need for improvements in capturing both types of error effectively {#chap:discussion}.","Whisper showed notably different behavior for the two error types:

**Pronunciation-related errors (662 examples):**
- Identical reproduction: 10.88%
- Overcorrection (correct in context): 30.51%
- Overcorrection (incorrect in context): 26.59%
- Hallucinations: 16.31%
- Omissions: 15.71%

**Declension-related errors (525 examples):**
- Faithful reproduction: 42.10%
- Overcorrection: 21.71%
- Invented forms: 20.57%
- Not transcribed: 8.19%
- Unknown: 7.43%

Whisper reproduced declension errors much more faithfully (42%) than pronunciation errors (11%), suggesting the model often normalizes non-standard phonetic forms into standard Polish while being more tolerant of grammatical case deviations.",1.0,0.9695909355348116,0.9999999999666667,0.7142857142857143
What are the main limitations of the spaCy tool for grammatical case attribution in this study?,"[""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context."", ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nAn evaluation of *spaCy*'s performance in case detection was conducted separately for the incorrect learner forms and their corrected counterparts. The results show that *spaCy* achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.  \n**Case**                           **Precision**    **Recall**   **F1-score**   **Support**\n--------------------------------- ---------------- ------------ -------------- -------------\n*Evaluation on erroneous cases*\nAcc                                     0.38           0.40          0.39           20\nDat                                     0.00           0.00          0.00            0\nGen                                     0.60           0.59          0.60           61\nIns                                     0.75           0.55          0.63           22\nLoc                                     0.00           0.00          0.00           21\nNom                                     0.74           0.73          0.73           142\nnan                                     0.10           0.50          0.16            6\n**Accuracy**                       **0.60** / 272\n**Macro avg**                           0.37           0.39          0.36           272\n**Weighted avg**                        0.61           0.60          0.60           272\n*Evaluation on correct cases*\nAcc                                     1.00           1.00          1.00           23\nDat                                     0.00           0.00          0.00            0\nGen                                     0.90           0.65          0.75           162\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13"", ""Headers: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\n\nAnother avenue for future development is the creation of a dual-model system for language learning. One model could faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while a second model could provide the corrected, standard version of the utterance. Such a setup would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction.  \nMoreover, for case-related learning, tools such as *spaCy* could be employed to automatically identify cases in learner speech. However, current results indicate that *spaCy* does not yet handle this task with high accuracy, highlighting an area for potential improvement in future work.""]","The main limitations of the *spaCy* tool for grammatical case attribution in this study include:

1. **Interlanguage Influence**: The interlanguage nature of the data significantly affects *spaCy*'s performance in case detection, particularly with pronunciation deviations impacting word suffixes (e.g., errors in forms like *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/) {#chap:resultats}.

2. **Complexity of Polish Case System**: The inherent complexity of the Polish case system poses a challenge for *spaCy*, leading to difficulties in analyzing both incorrect learner forms and native utterances {#chap:resultats}.

3. **Variable Accuracy on Different Case Forms**: The accuracy metrics indicate variances across different grammatical cases, with particularly low precision and recall for the dative (0.00) and locative (0.00) cases when evaluating erroneous forms, and a lack of data for these forms also impacts performance assessment {#chap:resultats}.

4. **Performance on Learner Forms**: The tool achieved only 60% accuracy on incorrect learner forms compared to a higher accuracy of 75% on corrected forms, suggesting limitations in handling errors made by learners {#chap:resultats}.

5. **Lack of Enhanced Context**: The suggestion that future work might benefit from a broader syntactic context indicates that *spaCy* currently lacks the ability to improve performance when more linguistic context is provided {#chap:resultats}. 

Overall, these limitations highlight significant obstacles in *spaCy*'s application for accurate case attribution in the study's context.","The evaluation revealed several limitations of spaCy for case attribution:
- **Accuracy on learner forms:** Only 60% accuracy on incorrect learner forms
- **Accuracy on correct forms:** 75% accuracy on corrected Polish versions
- **Accuracy on native speech:** 67% accuracy on the native Polish corpus
- **Specific weaknesses:** The tool particularly struggled with the locative case (0% recall) and had difficulty with non-standard or unrecognized interlanguage forms not in the Polish lexicon
- **Contextual limitations:** A single inflected form in Polish may correspond to multiple cases, requiring broader syntactic context for accurate identification

These results suggest that both the interlanguage nature of the data and the inherent complexity of the Polish case system pose significant challenges for automatic case detection.",0.8461538461538461,0.9999993333055853,0.9999999999666667,0.7142857142857143
What future directions does the thesis suggest for improving ASR performance on Polish interlanguage?,"[""Headers: Experimentations > Future Perspectives {#chap:discussion} > Introduction\nHeaders: Experimentations > Future Perspectives {#chap:discussion} > Introduction\n\nOne promising direction for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage. This could potentially be achieved through fine-tuning the model using a dedicated interlanguage corpus. In such a setup, the system would be trained to recognize and transcribe interlanguage forms, rather than correcting them into standard Polish. The new vocabulary -- reflecting common learner errors -- would help the model predict and output words closer to what the learner actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers, ideally with a background in linguistics or second language acquisition."", 'Headers: General Context > State of the Art {#chap:methodes} > Conclusions\nHeaders: General Context > State of the Art {#chap:methodes} > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', 'Headers: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech > Automatic Speech Recognition for L2 Polish Speech\nHeaders: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech > Automatic Speech Recognition for L2 Polish Speech\n\nResearch on ASR for Polish, particularly for non-native speech, remains limited compared to English. The Polish language presents unique challenges for automatic recognition due to its rich inflectional system, free word order, and complex phonetic features, including nasal vowels, consonant clusters, and palatal fricatives [@zioko11_interspeech]. These linguistic characteristics make both accurate transcription and error detection in learner speech considerably more difficult than in less morphologically complex languages.  \nOne of the earliest Computer-Assisted Pronunciation Training (CAPT) systems for Polish, AzAR, was developed specifically for German learners and combined HMM-based ASR with error patterns typical of L2 Polish [@wagner2010]. This system successfully helped learners identify and practice problematic contrasts(e.g., /ɕ/, /ʐ/, nasal vowels), and nasal vowels, demonstrating the potential of ASR-assisted feedback in targeted pronunciation training. However, AzAR faced limitations in recognition accuracy and robustness, particularly when handling spontaneous or less controlled speech.  \nMore recently, end-to-end deep learning approaches, such as Whisper and wav2vec2, have opened new possibilities for Polish ASR. These models offer robustness across domains and the capacity to learn complex acoustic patterns directly from data. A promising direction is the fine-tuning of such large models on learner-specific corpora, like EURONOUNCE [@cylwik09_slate], which contains non-native Polish speech. Fine-tuning on these datasets could ensure that interlanguage features are preserved in the transcription rather than automatically normalized, thus providing more accurate feedback and enabling detailed analysis of learner errors.']","The thesis suggests that one promising direction for improving ASR performance on Polish interlanguage is the development of a version of the system specifically adapted to Polish interlanguage through fine-tuning the model using a dedicated interlanguage corpus. This approach would train the system to recognize and transcribe interlanguage forms rather than correcting them into standard Polish. The incorporation of new vocabulary that reflects common learner errors would help the model better predict and output what learners actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers with expertise in linguistics or second language acquisition {#chap:discussion}. 

Additionally, the thesis highlights the importance of adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis to capture learner-specific patterns rather than erasing them. This tailored approach holds promise for advancing research on non-native speech, particularly in the context of Polish, which has unique linguistic challenges due to its rich morphology and complex phonetics {#chap:methodes}.","The thesis suggests several directions for future improvement:
1. **Fine-tuning on learner corpora:** Developing a Whisper version adapted specifically to Polish interlanguage by training on dedicated interlanguage datasets manually annotated by native Polish speakers
2. **L1-specific models:** Creating separate models for pronunciation errors tailored to learners of specific native languages, since error patterns vary by L1 group
3. **Universal morphological models:** Developing a single model for case-related errors, as these appear largely independent of learners' native languages
4. **Dual-model systems:** Creating paired systems where one model faithfully reproduces learner interlanguage and another provides corrected versions, allowing learners to compare their productions with target forms
5. **Broader training data:** Expanding beyond task-specific data to cover diverse linguistic contexts and speaking styles
6. **Integration with morphosyntactic analysis:** Improving tools like spaCy for automatic case identification in learner speech",1.0,0.9496680810403553,0.9999999999666667,0.42857142857142855
What does the acronym VILLA stand for?,"['Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\n\nAt the end of the course, the students\' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \n![Map for the Route Direction task](photos/route-direction.png){#fig:Route Direction width=""60%""}  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work.']","The acronym VILLA stands for ""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation"" (Dimroth et al., 2013).",VILLA stands for 'Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation.',1.0,0.9999993669844447,0.9999999999,1.0
How many hours of Polish instruction did participants in the VILLA project receive?,"['Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', ""Headers: Experimentations > General conclusion {#general-conclusion .unnumbered}\nHeaders: Experimentations > General conclusion {#general-conclusion .unnumbered}\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", 'Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n::: {#tab:forms}\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\']",Participants in the VILLA project received 14 hours of instruction in Polish as a foreign language.,Participants in the VILLA project received 14 hours of instruction in Polish as a foreign language.,1.0,0.9540211770447768,0.8333333332916666,1.0
What were the five linguistic backgrounds of learners in the VILLA project?,"['Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > Introduction\nHeaders: General Context > Context {#chap:articles} > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","The five linguistic backgrounds of learners in the VILLA project were Dutch, English, French, German, and Italian (Dimroth et al., 2013).","The five linguistic backgrounds of learners in the VILLA project were Dutch, English, French, German, and Italian.",1.0,1.0,0.9999999999,1.0
What task did learners complete at the end of the VILLA course?,"['Headers: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\n\nAt the end of the course, the students\' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \n![Map for the Route Direction task](photos/route-direction.png){#fig:Route Direction width=""60%""}  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work.', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].']","At the end of the VILLA course, learners completed a task called *Route Direction*, which required them to give directions from point A to point B using a map.","At the end of the course, learners completed a Route Direction task, which required them to give directions from point A to point B using a map.",1.0,0.9999994970626226,0.9999999999,1.0
What is the difference between meaning-based and form-based input in the VILLA project?,"['Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Description of the Task\n\nAt the end of the course, the students\' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \n![Map for the Route Direction task](photos/route-direction.png){#fig:Route Direction width=""60%""}  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work.']","In the VILLA project, the difference between meaning-based and form-based input lies in the focus and instructional approach provided to learners. 

Learners receiving meaning-based input were exposed only to structured input aimed at communication, without any meta-linguistic explanations or explicit corrections. The teacher did not encourage reflection on language forms in this approach.

Conversely, learners receiving form-based input were explicitly directed to notice morphological forms and rules. This approach involved an explicit focus on the structure of the language, highlighting specific forms to aid understanding and learning (Dimroth et al., 2013).","Learners exposed to meaning-based input received only structured input focused on communication without meta-linguistic explanations or explicit correction, while learners who received form-based input were explicitly directed to notice morphological forms and rules.",0.75,0.9999995390052121,0.9999999999,1.0
What problematic behavior does Whisper exhibit when transcribing L2 French speech?,"['Headers: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context.""]","Whisper exhibits problematic behavior in transcribing L2 French speech by ""hyper-normalizing"" learner speech, which involves correcting errors such as changing *expériencer* to *expérimenter*. This overcorrection can introduce hallucinations and omits disfluencies like repetitions and pauses. Such tendencies compromise the reliability of ASR as a tool for second language acquisition (SLA) research, as they interfere with the investigation of deviations from the target norm. Despite effective performance on advanced learners, these issues highlight the need for fine-tuning ASR models on learner corpora to ensure faithful transcription and avoid overcorrection ({El Ayari} and Li, 2024).","Whisper often 'hyper-normalized' learner speech by correcting errors, introducing hallucinations, or omitting disfluencies such as repetitions and pauses.",1.0,0.9917734306542618,0.99999999995,1.0
What tool was used for morphosyntactic analysis in this thesis?,"[""Headers: General Context > State of the Art {#chap:methodes} > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art {#chap:methodes} > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors."", ""Headers: General Context > Context {#chap:articles} > Conclusions\nHeaders: General Context > Context {#chap:articles} > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", ""Headers: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Tools and Implementation\nHeaders: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Tools and Implementation\n\nAll scripts developed in this thesis were implemented in Python within a Jupyter Notebook environment. For the automatic speech recognition of learners' utterances, we used the small model of Whisper[^3] by OpenAI, in automatic language mode, provided by Huma-Num[^4] servers, since Polish was not available.  \nThe implementation further relied on a range of Python libraries, including *spaCy*[^5] for morphosyntactic analysis, *pandas*[^6] for data manipulation, *fuzzywuzzy*[^7] (Levenshtein distance) for fuzzy string matching, *Epitran*[^8] for grapheme-to-phoneme transcription, *langdetect*[^9] for language detecting, *matplotlib*[^10] and *seaborn*[^11] for visualization, *JiWER*[^12] for calculating WER and CER, as well as *json*, *xml.etree*, and *csv* for structured data processing and file management.  \nThis configuration ensured reproducibility and scalability, while enabling the efficient integration of data processing, linguistic analysis, and evaluation procedures.""]",The tool used for morphosyntactic analysis in this thesis was *spaCy* {#chap:methodes}.,"The tool used for morphosyntactic analysis in this thesis was spaCy, which provides lemmatization, part-of-speech tagging, and morphological features including case information.",1.0,0.982467162558354,0.8333333332916666,1.0
What accuracy did spaCy achieve in case detection for incorrect learner forms?,"[""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nAn evaluation of *spaCy*'s performance in case detection was conducted separately for the incorrect learner forms and their corrected counterparts. The results show that *spaCy* achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.  \n**Case**                           **Precision**    **Recall**   **F1-score**   **Support**\n--------------------------------- ---------------- ------------ -------------- -------------\n*Evaluation on erroneous cases*\nAcc                                     0.38           0.40          0.39           20\nDat                                     0.00           0.00          0.00            0\nGen                                     0.60           0.59          0.60           61\nIns                                     0.75           0.55          0.63           22\nLoc                                     0.00           0.00          0.00           21\nNom                                     0.74           0.73          0.73           142\nnan                                     0.10           0.50          0.16            6\n**Accuracy**                       **0.60** / 272\n**Macro avg**                           0.37           0.39          0.36           272\n**Weighted avg**                        0.61           0.60          0.60           272\n*Evaluation on correct cases*\nAcc                                     1.00           1.00          1.00           23\nDat                                     0.00           0.00          0.00            0\nGen                                     0.90           0.65          0.75           162\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13"", ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context."", 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5\n**Accuracy**                       **0.75** / 306\n**Macro avg**                           0.44           0.52          0.46           306\n**Weighted avg**                        0.77           0.75          0.74           306  \n: Classification metrics for erroneous and correct forms by grammatical case  \nTo better understand whether these difficulties stem from interlanguage or from the complexity of the language itself, the same procedure was applied to the small Polish native corpus. The overall accuracy in this case was only 67%, which falls between the scores observed for learner errors and corrected forms.  \n**Case**            **Precision**   **Recall**   **F1-score**   **Support**\n------------------ --------------- ------------ -------------- -------------\nAcc                     1.00           0.50          0.67            2\nDat                     0.00           0.00          0.00            0\nGen                     0.25           0.67          0.36            3\nIns                     0.86           1.00          0.92            6\nLoc                     0.00           0.00          0.00            7\nNom                     0.79           0.94          0.86           16\nUNK                     0.00           0.00          0.00            2\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36']",*spaCy* achieved 60% accuracy on the incorrect learner forms {#chap:resultats}.,spaCy achieved 60% accuracy on the incorrect learner forms.,1.0,0.878073854921171,0.9999999999,1.0
What accuracy did spaCy achieve in case detection for corrected forms?,"[""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nAn evaluation of *spaCy*'s performance in case detection was conducted separately for the incorrect learner forms and their corrected counterparts. The results show that *spaCy* achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.  \n**Case**                           **Precision**    **Recall**   **F1-score**   **Support**\n--------------------------------- ---------------- ------------ -------------- -------------\n*Evaluation on erroneous cases*\nAcc                                     0.38           0.40          0.39           20\nDat                                     0.00           0.00          0.00            0\nGen                                     0.60           0.59          0.60           61\nIns                                     0.75           0.55          0.63           22\nLoc                                     0.00           0.00          0.00           21\nNom                                     0.74           0.73          0.73           142\nnan                                     0.10           0.50          0.16            6\n**Accuracy**                       **0.60** / 272\n**Macro avg**                           0.37           0.39          0.36           272\n**Weighted avg**                        0.61           0.60          0.60           272\n*Evaluation on correct cases*\nAcc                                     1.00           1.00          1.00           23\nDat                                     0.00           0.00          0.00            0\nGen                                     0.90           0.65          0.75           162\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13"", ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context."", 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5\n**Accuracy**                       **0.75** / 306\n**Macro avg**                           0.44           0.52          0.46           306\n**Weighted avg**                        0.77           0.75          0.74           306  \n: Classification metrics for erroneous and correct forms by grammatical case  \nTo better understand whether these difficulties stem from interlanguage or from the complexity of the language itself, the same procedure was applied to the small Polish native corpus. The overall accuracy in this case was only 67%, which falls between the scores observed for learner errors and corrected forms.  \n**Case**            **Precision**   **Recall**   **F1-score**   **Support**\n------------------ --------------- ------------ -------------- -------------\nAcc                     1.00           0.50          0.67            2\nDat                     0.00           0.00          0.00            0\nGen                     0.25           0.67          0.36            3\nIns                     0.86           1.00          0.92            6\nLoc                     0.00           0.00          0.00            7\nNom                     0.79           0.94          0.86           16\nUNK                     0.00           0.00          0.00            2\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36']",*spaCy* achieved 75% accuracy in case detection for corrected forms {#chap:resultats}.,spaCy achieved 75% accuracy on the corrected forms.,1.0,0.9552693056243715,0.8333333332916666,1.0
What was spaCy's accuracy when applied to the native Polish corpus?,"[""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context."", 'Headers: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Manual Preprocessing\n\n**Results:**\\\n`’de’: [’ich’, ’ichś’, ’uniwersitet’, ’uniwersiteć’, ’uniwersytet’, ’uniwerszitet’, ’uniweszitet’], ’nl’: [’en’, ’juniwersitet’, ’juwersytet’], ’it’: [’aller’, ’allora’, ’dicevi’, ’il’, ’ne’, ’ospitalem’, ’quattro’, ’spita’, ’spital’, ’spitala’, ’spitalem’, ’szpitale’, ’tiatr’, ’ulicon’], ’fr’: [’desolée’, ’du’, ’es’, ’est’, ’le’, ’oublié’, ’oui’, ’où’, ’plus’, ’questo’, ’tourner’], ’en’: [’ctery’, ’o’, ’teatr’, ’teatry’, ’to’, ’tourner’]`\\\nAt this point, the corpus was not yet complete; however, the preliminary results showed that the majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners\' Polish interlanguage. Although some words were correctly classified (in bold), they remained a minority. Unfortunately, as many words from the \\*STU segments were simplified attempts at Polish words, the program sometimes incorrectly classified them as belonging to other languages.  \nTo allow for comparison with the native Polish corpus, the same language detection library was applied to the transcriptions produced by the four native speakers. Out of a total of 96 words, only one word -- the Polish word *teraz* (\\""now\\"") -- was mistakenly identified as Italian, representing just 1% of the data. This result confirms the overall reliability of the language detection tool and suggests that the challenges observed in the learner corpus are primarily due to the deformed nature of interlanguage forms rather than limitations of the library itself.  \nThis demonstrates that the automatic method was unreliable. As a result, the removal of non-Polish words had to be done manually.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n##### Corpus Processing  \nTo assess Whisper's ability to process learner interlanguage features stemming from declension errors, a corresponding subcorpus was compiled using data from an error CSV file containing manual transcriptions and their correct versions, alongside a JSON file with organized transcriptions providing the automatic transcriptions. The script filtered the data to include only nouns and adjectives, which are pertinent to grammatical case analysis.  \nFor each instance, pairs of the learner's non-standard forms and the correct Polish counterpart were extracted, accompanied by metadata such as learner ID and country. These entries were further enriched with grammatical case annotations derived from previously curated and manually refined error datasets, ensuring precise labeling of both interlanguage and correct forms.  \nConsistent with the format adopted for the pronunciation error subcorpus, the data was organized into columns displaying the complete automatic transcription, manual transcription, and the corresponding correct Polish version for each utterance segment. Manual alignment of automatic transcription words to their respective entries was performed to enable detailed analysis.  \nAn automatic morphosyntactic tagging procedure was then applied to assign grammatical case labels to words in the automatic transcriptions. When a word was found in either the interlanguage or correct form dictionaries, the corresponding case was assigned. If absent from both, the Polish *spaCy* model was employed to predict the case. Entries for which automatic tagging failed were flagged for manual review and correction. Among 697 lexical items, 59 cases were automatically identified by *spaCy*, and 15 entries were marked for manual completion.""]",This question is not related to the provided thesis context.,The overall accuracy when applied to the native Polish corpus was only 67%.,0.0,0.0,0.9999999999,1.0
What percentage of words in the manual transcriptions were successfully aligned with their correct counterparts?,"['Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners\' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners\' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [\\[app:json3-example\\]](#app:json3-example){reference-type=""autoref"" reference=""app:json3-example""} for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\n\nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.  \nThe next step was the extraction of the erroneous words, i.e. the pairs where the word from the manual transcription differs from the corresponding correct version. To achieve this, a script was written to process the JSON file containing aligned segments for each learner. For every pair of words, the script checks whether both manual and correct forms are present and different. If so, the error is registered along with the learner ID and their country. To avoid double-counting, each unique error per learner is stored only once. The results are then grouped by correct form, incorrect (manual) form, and country, and saved into a CSV file listing the number of learners per country who made each error, along with their IDs. In addition, global statistics are computed to count the total number of aligned word pairs and how many of them contain an error.  \n**Correct form**   **Erroneous form**    **No. of learners**   **FR**   **IT**   **NL**   **UK**   **GE**  **Learners**\n------------------ -------------------- --------------------- -------- -------- -------- -------- -------- --------------------\niść                idź                            5              5        0        0        0        0     1104, 1108, (\\...)\niść                iś                            25              2        8        3        11       1     1115, 1118, (\\...)\niść                iszcze                         1              1        0        0        0        0     1117\niść                iścz                           1              1        0        0        0        0     1117', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.']","82.96% of the words in the manual transcriptions were successfully aligned with their correct counterparts (see [\[app:json3-example\]](#app:json3-example){reference-type=""autoref"" reference=""app:json3-example""}).","Out of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.",1.0,0.9957011211869244,0.9999999999666667,1.0
What percentage of aligned word pairs were identified as erroneous?,"['Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners\' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners\' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [\\[app:json3-example\\]](#app:json3-example){reference-type=""autoref"" reference=""app:json3-example""} for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\n\nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.  \nThe next step was the extraction of the erroneous words, i.e. the pairs where the word from the manual transcription differs from the corresponding correct version. To achieve this, a script was written to process the JSON file containing aligned segments for each learner. For every pair of words, the script checks whether both manual and correct forms are present and different. If so, the error is registered along with the learner ID and their country. To avoid double-counting, each unique error per learner is stored only once. The results are then grouped by correct form, incorrect (manual) form, and country, and saved into a CSV file listing the number of learners per country who made each error, along with their IDs. In addition, global statistics are computed to count the total number of aligned word pairs and how many of them contain an error.  \n**Correct form**   **Erroneous form**    **No. of learners**   **FR**   **IT**   **NL**   **UK**   **GE**  **Learners**\n------------------ -------------------- --------------------- -------- -------- -------- -------- -------- --------------------\niść                idź                            5              5        0        0        0        0     1104, 1108, (\\...)\niść                iś                            25              2        8        3        11       1     1115, 1118, (\\...)\niść                iszcze                         1              1        0        0        0        0     1117\niść                iścz                           1              1        0        0        0        0     1117', ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Corpus Processing for Extraction of Deviations\n\niść                iścz                           1              1        0        0        0        0     1117\niść                isze                           1              0        1        0        0        0     5109  \n: Excerpt with correct and erroneous forms and learner distribution  \nOut of 3,466 aligned pairs, 1,352 were identified as erroneous, accounting for 39.01% of the data. This corpus serves as the foundation for the subsequent analysis of learners' errors.""]","Out of 3,466 aligned pairs, 1,352 were identified as erroneous, accounting for 39.01% of the data.","Out of 3,466 aligned pairs, 1,352 were identified as erroneous, accounting for 39.01% of the data.",1.0,0.9069955789580577,0.5833333333041666,1.0
What annotation tool was used to create manual transcriptions of learner recordings?,"['Headers: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Manual Preprocessing\n\nDuring the task, teachers typically did not contribute to the learners\' utterances. However, the learners\' recordings of the task always began with a teacher who asked for the student\'s identifier and then gave a brief introduction to the task in Polish:\\\n*We are here at the train station in Kraków. I\'m a tourist from Warsaw, and you live in Kraków. I, the tourist, am asking for information. Excuse me, how can I get to 4 Dobra Street?*\\\nAt the end of each recording, they thanked the learner and made brief encouraging remarks, such as \\""very good,\\"" etc.  \nAll teacher utterances were excluded from the corpus, as the analysis focuses solely on the learners\' interlanguage. Since the transcriptions of these utterances were not identical, automatically removing them would have been difficult. Therefore, the teachers\' speech at the beginning and end of each recording was removed manually.  \nAnother challenge in the corpus was the presence of words in the learners\' native languages, which were sometimes produced during the recordings. These fragments were also initially transcribed, but they complicated the comparison between the automatic and manual transcriptions, as well as the analysis of learner errors.  \nTo address this issue, a function was created to automatically detect words belonging to the native languages of the learners involved in the project (French, Italian, English, German, and Dutch), using the *langdetect* library.\\\n**Results:**\\', 'Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThere are a few reasons why the recordings were transcribed in accordance with standard Polish orthography instead of the phonetic alphabet. Firstly, manual transcription is a very tedious and time-consuming process that requires a lot of attention. Consequently, the annotation rules should be as simple and intuitive as possible [@Grochola-Szczepanek_Woźniak_2018]. In addition, full phonemic transcription using the IPA would have been significantly more time-consuming. Given the limited time, this would have led to a substantial reduction in the size of the corpus. Moreover, such transcription facilitates processing by automated tools. Only general orthographic transcription allows the use of tools such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection, which are designed for standard orthography. Finally, the corpus and the analysis are intended for further work by other researchers in the laboratory, not only phoneticians and phonologists.  \nNevertheless, in the subsequent analysis of phonetic errors, the orthographic representations were automatically converted into IPA symbols to enable a more precise visualization of pronunciation deviations.  \nThe same task was also carried out by four native Polish speakers, whose utterances were recorded and transcribed following the same procedure as for the learner corpus. While this native speaker corpus is significantly smaller in size, it serves as a reference point for the subsequent evaluation of the performance of automatic linguistic tools.', ""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage.""]",This question is not related to the provided thesis context.,"ELAN, a tool for annotating audio and video recordings, was used to create manual transcriptions, and the files were saved in .eaf format.",0.0,0.0,0.0,0.0
What are the two parallel tiers included in each transcription file?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n::: {#tab:recordings}\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Automatic Preprocessing\nHeaders: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Automatic Preprocessing\n\nThe automatic data‑processing workflow comprises a few successive stages. First, the code systematically traverses all corrected `.eaf` files. For each file, it retrieves the learner identifier together with every learner utterance (\\*STU) and its corresponding corrected version in Polish (%pol). These elements are then compiled into an individual, well‑structured XML document that records the learner\'s ID, country of origin, and each pair of learner and target‑language statements (see [\\[app:xml-example\\]](#app:xml-example){reference-type=""autoref"" reference=""app:xml-example""} for an example XML file).  \nThe second stage focuses on the automatic transcriptions stored as `.txt` files. The function first verifies that the content is indeed Polish; non-Polish segments are named differently in the final file. Out of 89 examples, 15 were generated in a language other than Polish. These hallucinations are caused by the highly distorted nature of the interlanguage, as well as by rare instances where some learners briefly switched to their native language.  \nThe program subsequently normalises the remaining text by converting it to lower case, removing all punctuation except hyphens, and eliminating superfluous whitespace.  \nDuring the enrichment phase, the procedure aligns each cleaned automatic transcription with its counterpart XML file, matching them by filename. For every resulting entry it records the learner number, the country, the automatic transcription, and the full set of manual transcriptions together with their Polish corrections, each labelled with its segment number. This step yields a comprehensive dataset that integrates all available sources.']","The two parallel tiers included in each transcription file are:  
- **\*STU**: manual transcriptions that accurately reflect what the learner said;  
- **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.",The two parallel tiers are *STU (manual transcriptions that accurately reflect what the learner said) and %pol (corrected versions in standard Polish representing the intended meaning of the learner's utterance).,1.0,0.9999995006734133,0.8333333332916666,1.0
How many audio files were included in the learner corpus from each country?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n::: {#tab:recordings}\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus {#chap:corpus} > Introduction\nHeaders: Experimentations > Corpus {#chap:corpus} > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.']","The number of audio files included in the learner corpus from each country is as follows:

- **France**: 17 files
- **Italy**: 17 files
- **Netherlands**: 18 files
- **England**: 17 files
- **Germany**: 20 files  

This information is summarized in the provided table related to the recordings by country {#tab:recordings}.","The corpus included 17 files from France, 17 from Italy, 18 from the Netherlands, 17 from England, and 20 from Germany.",1.0,0.9887326502166414,0.9999999999,1.0
What was the total duration of recordings analyzed in the learner corpus?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n::: {#tab:recordings}\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus {#chap:corpus} > Introduction\nHeaders: Experimentations > Corpus {#chap:corpus} > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.']","The total duration of recordings analyzed in the learner corpus amounts to 2 hours and 19 minutes, as stated in the context.",The total duration of recordings analyzed was 2 hours and 19 minutes across 89 files.,1.0,0.974914690039408,0.49999999995,1.0
What is Whisper?,"['Headers: General Context > State of the Art {#chap:methodes} > The Whisper Model\nHeaders: General Context > State of the Art {#chap:methodes} > The Whisper Model\n\nWhisper [@radford2022robustspeechrecognitionlargescale] represents a new generation of ASR: a transformer encoder--decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. Models are released in multiple sizes, enabling a balance between speed and accuracy.  \nFor L2 speech, Whisper performs better than many commercial systems, but it often \\""over-corrects\\"" learner speech -- for example, restoring omitted particles or ignoring disfluencies. This behavior, observed in L2 French [@elayari:hal-04769687], risks erasing the very interlanguage phenomena. In the context of Polish, such normalization could obscure substitutions of nasal vowels or partial palatalization.  \nNevertheless, Whisper\'s open-source nature, high baseline accuracy, and multilingual scope make it an attractive candidate for adaptation. With targeted fine-tuning on learner corpora, it could become a powerful tool for L2 research.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context.""]","Whisper (Radford et al., 2022) represents a new generation of automatic speech recognition (ASR) systems. It is a transformer encoder-decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, providing robustness across various domains, languages, and accents. The models are available in multiple sizes, allowing for a balance between speed and accuracy. In the context of L2 speech, Whisper performs better than many commercial systems, although it sometimes ""over-corrects"" learner speech, potentially obscuring important interlanguage phenomena.","Whisper is an end-to-end automatic speech recognition (ASR) system developed by OpenAI, representing a transformer encoder-decoder trained on 680,000 hours of multilingual data.",1.0,0.7671501319777295,0.9999999999,1.0
What is a major challenge when using ASR systems for second language speech?,"['Headers: General Context > State of the Art {#chap:methodes} > Conclusions\nHeaders: General Context > State of the Art {#chap:methodes} > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', 'Headers: General Context > State of the Art {#chap:methodes} > Introduction\nHeaders: General Context > State of the Art {#chap:methodes} > Introduction\n\nAutomatic Speech Recognition (ASR) has undergone remarkable progress in recent decades, evolving from early systems limited to a small set of commands to deep learning--based models capable of handling spontaneous, continuous speech in real-world conditions. While ASR technologies are now widely applied in domains such as virtual assistants, customer service, and accessibility tools, their use in second language (L2) learning and assessment still requires careful evaluation of their performance.', 'Headers: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art {#chap:methodes} > Automatic Speech Recognition for L2 Speech\n\nASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. For example, the system might produce incorrect text or suggest pronunciation corrections that do not match the learner\'s actual production, potentially providing misleading guidance. However, continuous improvements in machine learning and the increasing availability of diverse speech data have significantly reduced the accuracy gap between native and non-native recognition (e.g., Google ASR reduced this gap from 20% to 3--5%) [@gottardi; @https://doi.org/10.1002/tesq.3006].  \nRecent research highlights both the potential and the challenges of using automatic speech recognition (ASR) for pronunciation training. [@michot2024errorpreservingautomaticspeechrecognition] addressed the crucial issue of designing an ASR system that not only transcribes learner speech accurately but also preserves their errors, thus enabling effective corrective feedback. To this end, they collected approximately 85 hours of spontaneous English speech from Swiss learners in grades 4--6 (about 45,000 utterances) and manually transcribed it with explicit error annotations. They proposed a new evaluation metric, the Word-Based Error Preservation Rate (WEPR), to measure the extent to which ASR systems maintain learner errors instead of automatically ""correcting"" them. Their findings demonstrated that a fine-tuned ASR model, trained directly on children\'s data, achieved a substantially higher WEPR and lower Word Error Rate (WER) than off-the-shelf systems, underscoring the promise of error-preserving ASR for pedagogical purposes.']","A major challenge when using ASR systems for second language (L2) speech is that these systems are typically trained on native speech, which leads to poor performance with non-native input. This can result in lower transcription accuracy and inaccurate evaluations of learner speech, where the system might produce incorrect text or suggest pronunciation corrections that do not match the learner's actual production, providing misleading guidance (Gottardi et al., 2022) (McCrocklin and Edalatishams, 2020).","A major challenge is that ASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech.",1.0,0.9999631405280657,0.9999999999666667,1.0
What are the seven grammatical cases in the Polish language?,"['Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nOne of the greatest grammatical challenges in the Polish language is the inflection of words for case. Case is an inflectional category with a textual function, used to signal the grammatical relationships between elements of a sentence. In Polish, we distinguish seven forms of cases:\\  \n-   Nominative -- Nominativus (Nom.),  \n-   Genitive -- Generativus (Gen.),  \n-   Dative -- Dativus (Dat.),  \n-   Accusative -- Accusativus (Acc.),  \n-   Instrumental -- Instrumentalis (Instr.),  \n-   Locative -- Locativus (Loc.),  \n-   Vocative -- Vocativus (Voc.).  \nParts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.\\\nBelow is an example of the declension of a Polish word -- *sklep* (store) -- depending on its syntactic role within a sentence:  \n::: {#tab:sklep-declension}\n**Case**     **Singular**    **Plural**   **Question (function)**\n-------------- -------------- -------------- -----------------------------------------------------\nNominative       sklep        sklep**y**   who? what? -- subject\nGenitive      sklep**u**    sklep**ów**   of whom? of what? -- possession, negation\nDative      sklep**owi**   sklep**om**   to whom? to what? -- indirect object\nAccusative       sklep        sklep**y**   whom? what? -- direct object\nInstrumental   sklep**em**    sklep**ami**  with whom? with what? -- means or accompaniment\nLocative     sklep**ie**    sklep**ach**  where? about whom? about what? -- location or topic\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::', 'Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::  \nHowever, the case system does not end with just seven suffixes. The inflectional forms of nouns also depend on grammatical gender. Every noun has a gender: masculine, feminine, or neuter. The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) [@bartnicka-1990].', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.']","The seven grammatical cases in the Polish language are:  
- Nominative -- Nominativus (Nom.)  
- Genitive -- Generativus (Gen.)  
- Dative -- Dativus (Dat.)  
- Accusative -- Accusativus (Acc.)  
- Instrumental -- Instrumentalis (Instr.)  
- Locative -- Locativus (Loc.)  
- Vocative -- Vocativus (Voc.)  
(@bartnicka-1990)","The seven grammatical cases in Polish are:
- Nominative (Nominativus)
- Genitive (Generativus)
- Dative (Dativus)
- Accusative (Accusativus)
- Instrumental (Instrumentalis)
- Locative (Locativus)
- Vocative (Vocativus)",1.0,0.9999999999999998,0.9999999999,1.0
How many letters does the Polish alphabet have?,"['Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nPolish belongs to the family of West Slavic languages [@bartnicka-1990]. It uses the Latin alphabet, enriched with special diacritical marks and with double letters pronounced as one sound [@foland-2007].\\\nThe Polish alphabet has 32 letters[^1]:  \n![Polish alphabet](photos/Polish-alphabet.png){#fig:Polish alphabet width=""60%""}  \nBelow are selected letters that may present particular pronunciation challenges for non-native speakers[^2]:  \n::: {#tab:polish-alphabet}\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ -----------------------------------------------------------------\nĄ                ą          /ɔŋ/, /ɔ̃w̃/  łąka /wɔŋka/ (\\""meadow\\""), szkołą /ʂkɔwɔ̃w̃/ (\\""school\\"", Instr.)\nC                c             /t͡s/     taca /tat͡sa/ (\\""plate\\"")\nĆ                ć             /t͡ɕ/     kochać /kɔxat͡ɕ/ (\\""to love\\"")\nĘ                ę          /ɛŋ/, /ɛ̃w̃/  ręka /rɛŋka/ (\\""arm\\""), szkołę /ʂkɔwɛ̃w̃/ (\\""school\\"", Acc.)\nJ                j             /j/      pająk /pajɔŋk/ (\\""spider\\"")\nK                k             /k/      sklep /sklɛp/ (\\""store\\"")\nŁ                ł             /w/      koło /kɔwɔ/ (\\""circle\\"")\nŃ                ń             /ɲ/      koń /kɔɲ/ (\\""horse\\"")\nÓ                ó             /u/      król /krul/ (\\""king\\"")\nŚ                ś             /ɕ/      śruba /ɕruba/ (\\""bolt\\"")\nU                u             /u/      drut /drut/ (\\""wire\\"")\nW                w           /v/, /f/   woda /vɔda/ (\\""water\\""), konewka /kɔnɛfka/ (\\""watering can\\"")\nY                y             /ɨ/      ryba /rɨba/ (\\""fish\\"")\nŹ                ź           /ʑ/, /ɕ/   źrebię /ʑrɛbjɛ̃w̃/ (\\""colt\\""), gryźć /ɡrɨɕt͡ɕ/ (\\""to bite\\"")\nŻ                ż           /ʐ/, /ʂ/   żaba /ʐaba/ (\\""frog\\""), wąż /vɔ̃w̃ʂ/ (\\""snake\\"")', 'Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nŹ                ź           /ʑ/, /ɕ/   źrebię /ʑrɛbjɛ̃w̃/ (\\""colt\\""), gryźć /ɡrɨɕt͡ɕ/ (\\""to bite\\"")\nŻ                ż           /ʐ/, /ʂ/   żaba /ʐaba/ (\\""frog\\""), wąż /vɔ̃w̃ʂ/ (\\""snake\\"")  \n: Selected Polish letters and their IPA transcriptions\n:::  \nIn addition, Polish includes several digraphs -- graphic combinations of two letters that represent a single sound [@foland-2007]:  \n::: {#tab:polish-digraphs}\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ ------------------------------------------------------------------\nCh               ch            /x/      chata /xata/ (\\""hut\\"")\nCz               cz            /t͡ʂ/     czysty /t͡ʂɨstɨ/ (\\""clean\\"")\nDz               dz         /d͡z/, /t͡s/  dzwon /d͡zvɔn/ (\\""bell\\""), powiedz /pɔvjɛt͡s/ (\\""say\\"", imp., 2sg)\nDź               dź         /d͡ʑ/, /t͡ɕ/  dźwięk /d͡ʑvjɛŋk/ (\\""sound\\""), powódź /pɔvud͡ʑ/ (\\""flood\\"")\nDż               dż            /d͡ʐ/     dżem /d͡ʐɛm/ (\\""jam\\"")\nRz               rz          /ʐ/, /ʂ/   rzeka /ʐɛka/ (\\""river\\""), malarz /malaʂ/ (\\""painter\\"")\nSz               sz            /ʂ/      kosz /kɔʂ/ (\\""basket\\"")  \n: Polish digraphs and their IPA transcriptions\n:::  \nOne of the more challenging aspects of learning Polish is its pronunciation. The language contains phonemes that are not present in other widely spoken Western languages, even if some may appear similar. Moreover, the frequent occurrence of complex phoneme clusters (difficult sounds placed directly next to each other) further complicates pronunciation for learners attempting to articulate Polish words accurately.', 'Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n::: {#tab:forms}\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\']",The Polish alphabet has 32 letters [^1].,The Polish alphabet has 32 letters.,1.0,0.9693666957963937,0.9999999999,1.0
What language family does Polish belong to?,"['Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nPolish belongs to the family of West Slavic languages [@bartnicka-1990]. It uses the Latin alphabet, enriched with special diacritical marks and with double letters pronounced as one sound [@foland-2007].\\\nThe Polish alphabet has 32 letters[^1]:  \n![Polish alphabet](photos/Polish-alphabet.png){#fig:Polish alphabet width=""60%""}  \nBelow are selected letters that may present particular pronunciation challenges for non-native speakers[^2]:  \n::: {#tab:polish-alphabet}\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ -----------------------------------------------------------------\nĄ                ą          /ɔŋ/, /ɔ̃w̃/  łąka /wɔŋka/ (\\""meadow\\""), szkołą /ʂkɔwɔ̃w̃/ (\\""school\\"", Instr.)\nC                c             /t͡s/     taca /tat͡sa/ (\\""plate\\"")\nĆ                ć             /t͡ɕ/     kochać /kɔxat͡ɕ/ (\\""to love\\"")\nĘ                ę          /ɛŋ/, /ɛ̃w̃/  ręka /rɛŋka/ (\\""arm\\""), szkołę /ʂkɔwɛ̃w̃/ (\\""school\\"", Acc.)\nJ                j             /j/      pająk /pajɔŋk/ (\\""spider\\"")\nK                k             /k/      sklep /sklɛp/ (\\""store\\"")\nŁ                ł             /w/      koło /kɔwɔ/ (\\""circle\\"")\nŃ                ń             /ɲ/      koń /kɔɲ/ (\\""horse\\"")\nÓ                ó             /u/      król /krul/ (\\""king\\"")\nŚ                ś             /ɕ/      śruba /ɕruba/ (\\""bolt\\"")\nU                u             /u/      drut /drut/ (\\""wire\\"")\nW                w           /v/, /f/   woda /vɔda/ (\\""water\\""), konewka /kɔnɛfka/ (\\""watering can\\"")\nY                y             /ɨ/      ryba /rɨba/ (\\""fish\\"")\nŹ                ź           /ʑ/, /ɕ/   źrebię /ʑrɛbjɛ̃w̃/ (\\""colt\\""), gryźć /ɡrɨɕt͡ɕ/ (\\""to bite\\"")\nŻ                ż           /ʐ/, /ʂ/   żaba /ʐaba/ (\\""frog\\""), wąż /vɔ̃w̃ʂ/ (\\""snake\\"")', 'Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n::: {#tab:forms}\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', 'Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nŹ                ź           /ʑ/, /ɕ/   źrebię /ʑrɛbjɛ̃w̃/ (\\""colt\\""), gryźć /ɡrɨɕt͡ɕ/ (\\""to bite\\"")\nŻ                ż           /ʐ/, /ʂ/   żaba /ʐaba/ (\\""frog\\""), wąż /vɔ̃w̃ʂ/ (\\""snake\\"")  \n: Selected Polish letters and their IPA transcriptions\n:::  \nIn addition, Polish includes several digraphs -- graphic combinations of two letters that represent a single sound [@foland-2007]:  \n::: {#tab:polish-digraphs}\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ ------------------------------------------------------------------\nCh               ch            /x/      chata /xata/ (\\""hut\\"")\nCz               cz            /t͡ʂ/     czysty /t͡ʂɨstɨ/ (\\""clean\\"")\nDz               dz         /d͡z/, /t͡s/  dzwon /d͡zvɔn/ (\\""bell\\""), powiedz /pɔvjɛt͡s/ (\\""say\\"", imp., 2sg)\nDź               dź         /d͡ʑ/, /t͡ɕ/  dźwięk /d͡ʑvjɛŋk/ (\\""sound\\""), powódź /pɔvud͡ʑ/ (\\""flood\\"")\nDż               dż            /d͡ʐ/     dżem /d͡ʐɛm/ (\\""jam\\"")\nRz               rz          /ʐ/, /ʂ/   rzeka /ʐɛka/ (\\""river\\""), malarz /malaʂ/ (\\""painter\\"")\nSz               sz            /ʂ/      kosz /kɔʂ/ (\\""basket\\"")  \n: Polish digraphs and their IPA transcriptions\n:::  \nOne of the more challenging aspects of learning Polish is its pronunciation. The language contains phonemes that are not present in other widely spoken Western languages, even if some may appear similar. Moreover, the frequent occurrence of complex phoneme clusters (difficult sounds placed directly next to each other) further complicates pronunciation for learners attempting to articulate Polish words accurately.']","Polish belongs to the family of West Slavic languages (Bartnicka and Satkiewicz, 1990).",Polish belongs to the family of West Slavic languages.,1.0,1.0,0.9999999999,1.0
Which parts of speech are conjugated by cases in Polish?,"['Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nOne of the greatest grammatical challenges in the Polish language is the inflection of words for case. Case is an inflectional category with a textual function, used to signal the grammatical relationships between elements of a sentence. In Polish, we distinguish seven forms of cases:\\  \n-   Nominative -- Nominativus (Nom.),  \n-   Genitive -- Generativus (Gen.),  \n-   Dative -- Dativus (Dat.),  \n-   Accusative -- Accusativus (Acc.),  \n-   Instrumental -- Instrumentalis (Instr.),  \n-   Locative -- Locativus (Loc.),  \n-   Vocative -- Vocativus (Voc.).  \nParts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.\\\nBelow is an example of the declension of a Polish word -- *sklep* (store) -- depending on its syntactic role within a sentence:  \n::: {#tab:sklep-declension}\n**Case**     **Singular**    **Plural**   **Question (function)**\n-------------- -------------- -------------- -----------------------------------------------------\nNominative       sklep        sklep**y**   who? what? -- subject\nGenitive      sklep**u**    sklep**ów**   of whom? of what? -- possession, negation\nDative      sklep**owi**   sklep**om**   to whom? to what? -- indirect object\nAccusative       sklep        sklep**y**   whom? what? -- direct object\nInstrumental   sklep**em**    sklep**ami**  with whom? with what? -- means or accompaniment\nLocative     sklep**ie**    sklep**ach**  where? about whom? about what? -- location or topic\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::', 'Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::  \nHowever, the case system does not end with just seven suffixes. The inflectional forms of nouns also depend on grammatical gender. Every noun has a gender: masculine, feminine, or neuter. The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) [@bartnicka-1990].', ""Headers: General Context > State of the Art {#chap:methodes} > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art {#chap:methodes} > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors.""]","In Polish, the parts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.","The parts of speech that are conjugated by cases in Polish are nouns, adjectives, numerals, and pronouns.",1.0,0.97925781754681,0.9999999999,1.0
What visualization tool was developed in this study?,"['Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations > Visualisation tool\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Pronunciation Deviations > Visualisation tool\n\nAs reading data directly from the raw tables can be somewhat unclear, an interactive HTML platform was developed to facilitate the analysis of learners\' pronunciation deviations. This tool allows users to filter all identical correct--erroneous phoneme pairs across the corpus, providing a clear overview of recurring patterns. Additionally, the interface includes buttons for switching between standard IPA representations, offering flexibility depending on the focus of the analysis. The platform serves as a valuable resource for further examining tendencies in Polish interlanguage among learners from the aforementioned countries. Moreover, it enables more detailed investigations into how specific characteristics of learners\' native languages may contribute to disfluencies and other systematic deviations.  \n![Screenshot of the pronunciation errors platform](photos/plateforme.png){#fig:platform width=""100%""}', ""Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Introduction\n\nThe first analysis conducted in this study focused on the non-standard forms made by learners. The primary objective was to identify the most common types of deviations produced by learners of Polish after a 14-hour course. In addition, the second goal was to investigate the potential influence of the learners' native languages on the nature of these productions. To facilitate a clearer visualization of deviations, a dedicated tool-platform will also be developed, enabling an easier and more systematic analysis of the data."", 'Headers: Experimentations > General conclusion {#general-conclusion .unnumbered}\nHeaders: Experimentations > General conclusion {#general-conclusion .unnumbered}\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.']","An interactive HTML platform was developed to facilitate the analysis of learners' pronunciation deviations. This tool allows users to filter all identical correct--erroneous phoneme pairs across the corpus, providing a clear overview of recurring patterns. Additionally, it includes buttons for switching between standard IPA representations, enhancing the flexibility depending on the focus of the analysis {#chap:resultats}.","An interactive HTML platform was developed to facilitate the analysis of learners' pronunciation deviations, allowing users to filter identical correct-erroneous phoneme pairs and switch between standard IPA representations.",1.0,0.3564134656443923,0.99999999995,1.0
"What are WER and CER, and how are they calculated?","[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate]."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\n\n::: {#tab:global_statistics}\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \n![WER and CER results on the global corpus](photos/wer_cer_comparison.png){#fig:wer_cer width=""100%""}  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \n$$WER = \\frac{S + D + I}{N_{\\text{words}}}$$  \n$$CER = \\frac{S + D + I}{N_{\\text{characters}}}$$  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance.""]","WER (Word Error Rate) and CER (Character Error Rate) are standard evaluation metrics used to quantify the performance of Automatic Speech Recognition (ASR) systems.

**Calculation of WER and CER:**
- **WER** is calculated using the formula:
  $$WER = \frac{S + D + I}{N_{\text{words}}}$$
  where \(S\) represents the number of substitutions, \(D\) the number of deletions, and \(I\) the number of insertions needed to transform the ASR output into the reference transcription, and \(N_{\text{words}}\) is the total number of words in the reference transcription.

- **CER** is calculated using the formula:
  $$CER = \frac{S + D + I}{N_{\text{characters}}}$$
  where \(N_{\text{characters}}\) is the total number of characters in the reference transcription.

Both metrics are based on the Levenshtein distance, which counts the number of necessary edits (substitutions, deletions, and insertions) to align the ASR output with the correct transcription ({El Ayari} and Li, 2024).","WER (Word Error Rate) and CER (Character Error Rate) are standard ASR evaluation metrics based on the Levenshtein distance, calculated as the number of substitutions, deletions, and insertions divided by the total number of words (for WER) or characters (for CER) in the reference transcription.",1.0,0.8395506764633569,0.9999999999666667,1.0
What was the average WER for Whisper on Polish interlanguage?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\n\nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner\'s pronunciation and the model\'s output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper\'s inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\n\n::: {#tab:global_statistics}\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \n![WER and CER results on the global corpus](photos/wer_cer_comparison.png){#fig:wer_cer width=""100%""}  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.']",The average WER for Whisper on Polish interlanguage is 75.4% {#tab:global_statistics}.,The average WER for Whisper on Polish interlanguage was 75.4%.,1.0,0.9860822054327545,0.3333333333,1.0
What was the average CER for Whisper on Polish interlanguage?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\n\nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\n\n::: {#tab:global_statistics}\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \n![WER and CER results on the global corpus](photos/wer_cer_comparison.png){#fig:wer_cer width=""100%""}  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner\'s pronunciation and the model\'s output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper\'s inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.']",The average CER for Whisper on Polish interlanguage is 46.4% {#chap:discussion}.,The average CER for Whisper on Polish interlanguage was 46.4%.,1.0,0.9865376642605445,0.49999999995,1.0
What were Whisper's WER and CER scores on native Polish speech?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance > WER and CER Results\n\nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\n\n::: {#tab:global_statistics}\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \n![WER and CER results on the global corpus](photos/wer_cer_comparison.png){#fig:wer_cer width=""100%""}  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \n$$WER = \\frac{S + D + I}{N_{\\text{words}}}$$  \n$$CER = \\frac{S + D + I}{N_{\\text{characters}}}$$  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance.""]","Whisper's WER and CER scores on native Polish speech were 13.74% and 6.44%, respectively. Additionally, the mean scores for native speakers were reported as a WER mean of 0.137 and a CER mean of 0.064 {#chap:discussion}.",Whisper achieved a WER of 13.74% and a CER of 6.44% on native Polish speech.,1.0,0.9999994781348719,0.8333333332916666,1.0
Why is CER considered a more informative metric than WER for evaluating interlanguage transcription?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate]."", ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \n$$WER = \\frac{S + D + I}{N_{\\text{words}}}$$  \n$$CER = \\frac{S + D + I}{N_{\\text{characters}}}$$  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Global Performance > WER and CER Results\n\n::: {#tab:global_statistics}\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \n![WER and CER results on the global corpus](photos/wer_cer_comparison.png){#fig:wer_cer width=""100%""}  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.']","CER is considered a more informative metric than WER for evaluating interlanguage transcription because it offers a finer-grained perspective on transcription accuracy. While WER penalises the system heavily for entire word misrecognition, often missing important contextual nuances, CER rewards even partially correct transcriptions based on character-level similarity. This is particularly crucial in the context of learner speech, where pronunciation deviations can lead to significant misrecognition at the word level, skewing the results. CER reflects the degree to which the Automatic Speech Recognition (ASR) output retains elements of the learner's original production, making it a more relevant measure in situations characterized by deformed and unstable forms of language, as noted in the context of multilingualism (K et al., 2024).","CER is more informative because it provides a more fine-grained perspective where even partially correct transcriptions are rewarded for character-level similarity, better reflecting the degree to which the ASR output preserves traces of the learner's original production.",0.9090909090909091,1.0,0.9999999999666667,1.0
What percentage of pronunciation-related interlanguage words were identically transcribed by Whisper?,"['Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner\'s pronunciation and the model\'s output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper\'s inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\nOvercorrected words (existing in Polish but incorrect in context)                     176                     26.59%\nWords invented by Whisper                                                             108                     16.31%\nUntranscribed words                                                                   104                     15.71%\n**Total**                                                                             662                       100%  \n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.']","72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output {#chap:discussion}.","Within the pronunciation-related interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper.",1.0,0.8990992170326525,0.8333333332916666,1.0
What percentage of pronunciation-related interlanguage words were overcorrected by Whisper?,"['Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\nOvercorrected words (existing in Polish but incorrect in context)                     176                     26.59%\nWords invented by Whisper                                                             108                     16.31%\nUntranscribed words                                                                   104                     15.71%\n**Total**                                                                             662                       100%  \n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner\'s pronunciation and the model\'s output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper\'s inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.']",The percentage of pronunciation-related interlanguage words that were overcorrected by Whisper is 26.59% {#chap:discussion}.,"A total of 57.1% of pronunciation-related interlanguage words were overcorrected, with 30.51% being contextually correct overcorrections and 26.59% being contextually inappropriate substitutions.",1.0,0.9999999999999999,0.49999999995,1.0
What percentage of declension-related interlanguage words were faithfully reproduced by Whisper?,"['Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n:::  \n![Distribution of word categories -- interlanguage (pronunciation-related errors)](photos/camembert_categories.png){#fig:camembert_pron width=""80%""}  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner\'s pronunciation and the model\'s output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper\'s inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.']",Whisper faithfully reproduced learners' declension-related interlanguage forms in 42.10% of cases {#chap:discussion}.,Whisper faithfully reproduced learners' declension errors in 42.10% of cases.,1.0,0.8060904179588798,0.99999999995,1.0
How does Whisper's performance differ between pronunciation errors and declension errors?,"[""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context.""]","Whisper's performance shows a notable difference between pronunciation errors and declension errors. For pronunciation errors, the system tends to overcorrect learner speech by reproducing canonical forms instead of the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully, achieving a 42.10% rate of faithful reproduction of these errors. This is significantly higher than the 10.88% observed in pronunciation error data. These findings suggest that Whisper is better at detecting systematic grammatical errors, such as declension, than phonetic inaccuracies, indicating the need for improvements in capturing both types of errors effectively ({#chap:discussion}).","For pronunciation errors, Whisper often overcorrects learner speech by reproducing canonical forms, while for declension errors, Whisper more frequently reproduces the learner's forms faithfully, with 42.10% faithful reproduction compared to only 10.88% for pronunciation errors.",1.0,0.9351073309392629,0.9999999999666667,1.0
What percentage of automatic transcriptions were generated in a language other than Polish?,"['Headers: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Manual Preprocessing\n\n**Results:**\\\n`’de’: [’ich’, ’ichś’, ’uniwersitet’, ’uniwersiteć’, ’uniwersytet’, ’uniwerszitet’, ’uniweszitet’], ’nl’: [’en’, ’juniwersitet’, ’juwersytet’], ’it’: [’aller’, ’allora’, ’dicevi’, ’il’, ’ne’, ’ospitalem’, ’quattro’, ’spita’, ’spital’, ’spitala’, ’spitalem’, ’szpitale’, ’tiatr’, ’ulicon’], ’fr’: [’desolée’, ’du’, ’es’, ’est’, ’le’, ’oublié’, ’oui’, ’où’, ’plus’, ’questo’, ’tourner’], ’en’: [’ctery’, ’o’, ’teatr’, ’teatry’, ’to’, ’tourner’]`\\\nAt this point, the corpus was not yet complete; however, the preliminary results showed that the majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners\' Polish interlanguage. Although some words were correctly classified (in bold), they remained a minority. Unfortunately, as many words from the \\*STU segments were simplified attempts at Polish words, the program sometimes incorrectly classified them as belonging to other languages.  \nTo allow for comparison with the native Polish corpus, the same language detection library was applied to the transcriptions produced by the four native speakers. Out of a total of 96 words, only one word -- the Polish word *teraz* (\\""now\\"") -- was mistakenly identified as Italian, representing just 1% of the data. This result confirms the overall reliability of the language detection tool and suggests that the challenges observed in the learner corpus are primarily due to the deformed nature of interlanguage forms rather than limitations of the library itself.  \nThis demonstrates that the automatic method was unreliable. As a result, the removal of non-Polish words had to be done manually.', 'Headers: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance {#chap:discussion} > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \n![Distribution of word categories -- interlanguage (declination-related errors)](photos/camembert_categories_declinaison.png){#fig:camembert_dec width=""80%""}  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners\' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner\'s and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner\'s form with a different, correct form, potentially masking the learner\'s actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.', ""Headers: Experimentations > General conclusion {#general-conclusion .unnumbered}\nHeaders: Experimentations > General conclusion {#general-conclusion .unnumbered}\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy.""]","The percentage of automatic transcriptions generated in a language other than Polish was 66%, as the preliminary results indicated that the majority of the words detected as belonging to another language were erroneous forms from the learners' Polish interlanguage.","Out of 89 examples, 15 (approximately 17%) were generated in a language other than Polish due to hallucinations caused by the highly distorted nature of the interlanguage.",0.5,0.9999995049353639,0.9999999999,0.0
What Python libraries were used in this thesis?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Tools and Implementation\nHeaders: Experimentations > Corpus {#chap:corpus} > Annotation and Preprocessing > Tools and Implementation\n\nAll scripts developed in this thesis were implemented in Python within a Jupyter Notebook environment. For the automatic speech recognition of learners' utterances, we used the small model of Whisper[^3] by OpenAI, in automatic language mode, provided by Huma-Num[^4] servers, since Polish was not available.  \nThe implementation further relied on a range of Python libraries, including *spaCy*[^5] for morphosyntactic analysis, *pandas*[^6] for data manipulation, *fuzzywuzzy*[^7] (Levenshtein distance) for fuzzy string matching, *Epitran*[^8] for grapheme-to-phoneme transcription, *langdetect*[^9] for language detecting, *matplotlib*[^10] and *seaborn*[^11] for visualization, *JiWER*[^12] for calculating WER and CER, as well as *json*, *xml.etree*, and *csv* for structured data processing and file management.  \nThis configuration ensured reproducibility and scalability, while enabling the efficient integration of data processing, linguistic analysis, and evaluation procedures."", 'Front Matter > Title Page\nFront Matter > Title Page\n\nThis is the title page and metadata of the thesis.\nauthor:\n- Agata SKRZYNIARZ\nbibliography: biblio.bib\ntitle: Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage\n---\n\n::: center\n  ![image](logo-inalco){width=""3.9cm""}   ![image](logo-entreprise){width=""3.9cm""}\n  -------------------------------------- ------------------------------------------\n:::\n\n::: center\n**Institut National des Langues et Civilisations Orientales**\\\n(National Institute for Oriental Languages and Civilizations)\n\nDépartement Textes, Informatique, Multilinguisme\\\n(Department of Texts, Computing, and Multilingualism)\n\n------------------------------------------------------------------------\n\n**Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage**\n\n------------------------------------------------------------------------\n\n[Master]{.smallcaps}\n\n[Traitement Automatique des Langues]{.smallcaps}\\\n[(Natural Language Processing)]{.smallcaps}\n\n*Specialization:*\n\n*Research and Development*\n\nby\n\n**Agata [Skrzyniarz]{.smallcaps}**\n\n*Thesis Supervisor:*\n\n*Sarra El Ayari*\n\nAcademic Year 2024/2025\n:::', ""Headers: General Context > Context {#chap:articles} > Conclusions\nHeaders: General Context > Context {#chap:articles} > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data.""]","The Python libraries used in this thesis include *spaCy*[^5] for morphosyntactic analysis, *pandas*[^6] for data manipulation, *fuzzywuzzy*[^7] (Levenshtein distance) for fuzzy string matching, *Epitran*[^8] for grapheme-to-phoneme transcription, *langdetect*[^9] for language detection, *matplotlib*[^10] and *seaborn*[^11] for visualization, and *JiWER*[^12] for calculating WER and CER, along with *json*, *xml.etree*, and *csv* for structured data processing and file management.","The implementation relied on libraries including spaCy for morphosyntactic analysis, pandas for data manipulation, fuzzywuzzy for fuzzy string matching, Epitran for grapheme-to-phoneme transcription, langdetect for language detection, matplotlib and seaborn for visualization, JiWER for calculating WER and CER, and json, xml.etree, and csv for structured data processing.",1.0,0.8789956348379622,0.9999999999,1.0
What size of Whisper model was used in this study?,"['Headers: General Context > State of the Art {#chap:methodes} > The Whisper Model\nHeaders: General Context > State of the Art {#chap:methodes} > The Whisper Model\n\nWhisper [@radford2022robustspeechrecognitionlargescale] represents a new generation of ASR: a transformer encoder--decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. Models are released in multiple sizes, enabling a balance between speed and accuracy.  \nFor L2 speech, Whisper performs better than many commercial systems, but it often \\""over-corrects\\"" learner speech -- for example, restoring omitted particles or ignoring disfluencies. This behavior, observed in L2 French [@elayari:hal-04769687], risks erasing the very interlanguage phenomena. In the context of Polish, such normalization could obscure substitutions of nasal vowels or partial palatalization.  \nNevertheless, Whisper\'s open-source nature, high baseline accuracy, and multilingual scope make it an attractive candidate for adaptation. With targeted fine-tuning on learner corpora, it could become a powerful tool for L2 research.', ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context.""]",This question is not related to the provided thesis context.,"The small model of Whisper by OpenAI was used in this study, in automatic language mode.",0.0,0.0,0.0,0.0
What is one promising direction suggested for improving Whisper's performance on learner speech?,"[""Headers: Experimentations > Future Perspectives {#chap:discussion} > Introduction\nHeaders: Experimentations > Future Perspectives {#chap:discussion} > Introduction\n\nOne promising direction for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage. This could potentially be achieved through fine-tuning the model using a dedicated interlanguage corpus. In such a setup, the system would be trained to recognize and transcribe interlanguage forms, rather than correcting them into standard Polish. The new vocabulary -- reflecting common learner errors -- would help the model predict and output words closer to what the learner actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers, ideally with a background in linguistics or second language acquisition."", ""Headers: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance {#chap:discussion} > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: General Context > State of the Art {#chap:methodes} > The Whisper Model\nHeaders: General Context > State of the Art {#chap:methodes} > The Whisper Model\n\nWhisper [@radford2022robustspeechrecognitionlargescale] represents a new generation of ASR: a transformer encoder--decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. Models are released in multiple sizes, enabling a balance between speed and accuracy.  \nFor L2 speech, Whisper performs better than many commercial systems, but it often \\""over-corrects\\"" learner speech -- for example, restoring omitted particles or ignoring disfluencies. This behavior, observed in L2 French [@elayari:hal-04769687], risks erasing the very interlanguage phenomena. In the context of Polish, such normalization could obscure substitutions of nasal vowels or partial palatalization.  \nNevertheless, Whisper\'s open-source nature, high baseline accuracy, and multilingual scope make it an attractive candidate for adaptation. With targeted fine-tuning on learner corpora, it could become a powerful tool for L2 research.']","One promising direction suggested for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage, potentially achieved through fine-tuning the model using a dedicated interlanguage corpus. This would allow the system to recognize and transcribe interlanguage forms without correcting them into standard Polish, using a vocabulary that reflects common learner errors to better predict and output what the learner actually said {#chap:discussion}.",One promising direction is the development of a version adapted specifically to Polish interlanguage through fine-tuning the model using a dedicated interlanguage corpus.,1.0,0.9499373398802388,0.9999999999666667,1.0
What type of dual-model system is proposed for language learning?,"[""Headers: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\n\nAnother avenue for future development is the creation of a dual-model system for language learning. One model could faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while a second model could provide the corrected, standard version of the utterance. Such a setup would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction.  \nMoreover, for case-related learning, tools such as *spaCy* could be employed to automatically identify cases in learner speech. However, current results indicate that *spaCy* does not yet handle this task with high accuracy, highlighting an area for potential improvement in future work."", ""Headers: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives {#chap:discussion} > Open Questions and Obstacles\n\nA key question in designing such a system is whether it should be tailored to learners of a specific native language or whether a more general model would suffice. On the one hand, the error analysis in this study shows that speakers of different native languages often exhibit consistent patterns, particularly in pronunciation. This suggests that separate models for pronunciation errors could be developed for different L1 groups, although some errors may also be universal across learners. On the other hand, case-related errors appear to be largely independent of the learner's native language, indicating that a universal model would likely be sufficient for handling morphological deviations.  \nA major challenge remains the inherently dynamic and individual nature of interlanguage. Learners follow unique developmental trajectories, and errors evolve over time depending on exposure, proficiency, and learning strategies. This raises questions about whether separate corpora or models would be needed for different proficiency levels, which would significantly increase data requirements and necessitate careful learner selection.  \nFinally, the corpus used in this study is highly task-specific, focusing exclusively on giving and understanding route directions. To develop a more robust and generalizable interlanguage-adapted Whisper, training data would need to cover a broader variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across different communicative situations."", 'Headers: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\nHeaders: General Context > Context {#chap:articles} > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].']","The proposed dual-model system for language learning includes one model that faithfully reproduces the learner's interlanguage, showing exactly what the learner said, while a second model provides the corrected, standard version of the utterance. This setup is intended to allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction.","A dual-model system is proposed where one model faithfully reproduces the learner's interlanguage showing exactly what the learner said, while a second model provides the corrected standard version of the utterance, allowing learners to compare their productions with target forms.",1.0,0.9363015376368529,0.9999999999666667,1.0
What is the EURONOUNCE corpus?,"[""Headers: Experimentations > Corpus {#chap:corpus} > Learner Corpus\nHeaders: Experimentations > Corpus {#chap:corpus} > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n::: {#tab:recordings}\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus {#chap:corpus} > Conclusions\nHeaders: Experimentations > Corpus {#chap:corpus} > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus {#chap:corpus} > Introduction\nHeaders: Experimentations > Corpus {#chap:corpus} > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.']",This question is not related to the provided thesis context.,"EURONOUNCE is a corpus that contains non-native Polish speech, which could be used for fine-tuning large ASR models to ensure that interlanguage features are preserved in transcription rather than automatically normalized.",0.0,0.0,0.9999999999,0.0
What factors determine the inflectional forms of nouns in Polish?,"['Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nOne of the greatest grammatical challenges in the Polish language is the inflection of words for case. Case is an inflectional category with a textual function, used to signal the grammatical relationships between elements of a sentence. In Polish, we distinguish seven forms of cases:\\  \n-   Nominative -- Nominativus (Nom.),  \n-   Genitive -- Generativus (Gen.),  \n-   Dative -- Dativus (Dat.),  \n-   Accusative -- Accusativus (Acc.),  \n-   Instrumental -- Instrumentalis (Instr.),  \n-   Locative -- Locativus (Loc.),  \n-   Vocative -- Vocativus (Voc.).  \nParts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.\\\nBelow is an example of the declension of a Polish word -- *sklep* (store) -- depending on its syntactic role within a sentence:  \n::: {#tab:sklep-declension}\n**Case**     **Singular**    **Plural**   **Question (function)**\n-------------- -------------- -------------- -----------------------------------------------------\nNominative       sklep        sklep**y**   who? what? -- subject\nGenitive      sklep**u**    sklep**ów**   of whom? of what? -- possession, negation\nDative      sklep**owi**   sklep**om**   to whom? to what? -- indirect object\nAccusative       sklep        sklep**y**   whom? what? -- direct object\nInstrumental   sklep**em**    sklep**ami**  with whom? with what? -- means or accompaniment\nLocative     sklep**ie**    sklep**ach**  where? about whom? about what? -- location or topic\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', 'Headers: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context {#chap:articles} > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::  \nHowever, the case system does not end with just seven suffixes. The inflectional forms of nouns also depend on grammatical gender. Every noun has a gender: masculine, feminine, or neuter. The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) [@bartnicka-1990].']","The inflectional forms of nouns in Polish are determined by grammatical gender, which can be masculine, feminine, or neuter. Additionally, the choice of endings is influenced by phonetic factors, such as whether the noun stem ends in a hard or soft consonant, or a vowel. Semantic factors also play a role, particularly the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender (Bartnicka and Satkiewicz, 1990).","The inflectional forms of nouns in Polish depend on grammatical gender (masculine, feminine, or neuter) and are influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender).",1.0,0.9679514571770461,0.3333333333,1.0
Which grammatical case did learners most frequently overuse incorrectly?,"['Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\n\nIn addition, heatmaps were generated to visualize the distribution of grammatical case errors, comparing the incorrect cases used by learners with the correct ones. Cells outlined in green correspond to correct case usage, but since such examples were excluded from the corpus at an earlier stage, these cells all show zero values.  \n![Use of 999IVC erroneous cases to represent correct cases](photos/heatmap_déclinaison_corrigé_par_cas_correct.png){#fig:heatmap_2 width=""\\\\linewidth""}  \n![Use of 999IVC erroneous cases to represent correct cases](photos/heatmap_déclinaison_par_cas_erroné_ligne.png){#fig:heatmap_2 width=""\\\\linewidth""}  \nFrom the first table (Figure[\\[fig:heatmap_1\\]](#fig:heatmap_1){reference-type=""ref"" reference=""fig:heatmap_1""}), we can confirm the previously mentioned observation that the nominative case is dominant among incorrect usages. Although the overall number of accusative and locative errors is relatively low, in most of these cases (around 80%), learners incorrectly used the nominative instead of the expected form. Similarly, both genitive and instrumental cases are frequently replaced by the nominative -- approximately 63% of the time -- though some of these errors also involve confusion between genitive, instrumental, and locative.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\n\n![Relative difference between actually used cases and expected correct cases](photos/différence_cas_produits_vs_attendus_pourcentage.png){#fig:difference_cases width=""\\\\linewidth""}  \nThe following analysis of learner data shows that the most frequently required cases, presented in Table[2.1](#tab:most_cases){reference-type=""ref"" reference=""tab:most_cases""} -- the genitive and instrumental -- also generate the highest number of errors among learners. The genitive case is typically used to express possession and appears frequently in phrases referring to street names, such as *ulica Juliusza Słowackiego* (\\""Juliusz Słowacki Street\\""). It also follows prepositions like *obok* (\\""next to\\"" or, in this context, \\""past\\""), which are commonly used in giving directions. The instrumental case, on the other hand, is used when describing movement along a path, especially after verbs of motion such as *iść* (\\""to go\\""), as in *iść ulicą Niską* (\\""go along Niska Street\\""). It is also required after the preposition *za* (\\""behind\\""), which frequently appears in this route direction task.  \nMoreover, one of the most common incorrect cases used by learners is the nominative. This is not unexpected, as the nominative is the default case in Polish. It is the form learners are most familiar with, and in the absence of explicit knowledge about declension rules, they often overgeneralize and use the nominative in contexts that require a different case. This tendency reflects a typical stage in interlanguage development, where learners rely on the most salient or frequent forms of the target language.', 'Headers: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis {#chap:resultats} > Declension Deviations > Results\n\nThe locative case, which also appears to be slightly overused, is typically required after prepositions such as *na* (\\""on\\"") or *w* (\\""in\\""). This overuse may stem from learners relying on familiar phrases and generalising them to contexts where other cases are expected. The characteristic suffixes of Polish cases (such as -*u*, -*e*, -*em*, or -*a*) can be particularly misleading for learners. For example, the phrase *obok szpitalu* instead of the correct *obok szpitala* (\\""next to the hospital\\"") illustrates confusion between the genitive and locative, likely influenced by more frequent expressions like *w szpitalu* (\\""in the hospital\\""). In fact, 52.63% of incorrect uses of the locative occurred in contexts where the genitive case was required. Furthermore, 36.84% of the same locative errors involved confusion with the instrumental (*za szpitalem* (\\""behind the hospital\\"")).  \nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners\' oral productions.']","Learners most frequently overused the nominative case incorrectly. It accounted for a significant majority of errors, as learners tended to default to the nominative in contexts that required other cases, reflecting their familiarity with it as the default form in Polish (see the text discussing the nominative's prevalence and the tendency to overgeneralize) {#chap:resultats}.","Learners most frequently overused the nominative case, as it functions as the default or 'base' form in Polish.",1.0,0.8481680953723657,0.99999999995,1.0
