[
    {
        "question": "What are the two main research objectives of this thesis?",
        "ground_truth": "The thesis has two main objectives:\n1. **Qualitative linguistic analysis of learner productions** – to identify the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction, and to investigate whether learners' native languages influence error patterns.\n2. **Evaluation of Whisper's performance** – to assess how well the Whisper automatic speech recognition system transcribes Polish interlanguage, with a focus on ensuring faithful reproduction of learner speech including all deviations, errors, and disfluencies rather than overcorrecting them."
    },
    {
        "question": "What is interlanguage and why is it important in this study?",
        "ground_truth": "Interlanguage is a concept introduced by Selinker (1972) to describe the transitional linguistic system that emerges when an adult learns a second language. It represents a stage between the target language (through partial application of its lexical items and grammatical rules) and the native language (from which the learner may transfer previously acquired structures). Interlanguage is typically marked by a high frequency of variations from the norm (Tarone, 2006), reflecting its evolving and dynamic nature. This concept is central to the study because the research aims to faithfully capture and analyze these interlanguage features in learner speech rather than having them automatically corrected by ASR systems."
    },
    {
        "question": "What is the VILLA project and how does it relate to the corpus used in this thesis?",
        "ground_truth": "The VILLA project (\"Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\"), conducted by Dimroth et al. (2013), investigated the initial stages of foreign language acquisition under controlled input conditions. The study involved complete beginners from five linguistic backgrounds (Dutch, English, French, German, and Italian) who each received 14 hours of instruction in Polish as a foreign language. The corpus used in this thesis consists of manual transcriptions of voice recordings from the Route Direction task, where learners had to give directions in Polish using a map. This corpus includes 89 files totaling 2 hours and 19 minutes of recordings from learners in the meaning-based groups across all five countries."
    },
    {
        "question": "What are the main linguistic challenges of Polish for foreign language learners?",
        "ground_truth": "Polish presents several significant challenges for learners:\n\n**Phonological challenges:**\n- Complex consonant clusters (e.g., the *skr-* cluster in *skręcić*)\n- Retroflex consonants (/ʂ/, /ʐ/, /t͡ʂ/) that are absent in many Western languages\n- Nasal vowels (*ą* /ɔ̃w̃/ and *ę* /ɛ̃w̃/)\n- Palatal fricatives and affricates\n\n**Morphological challenges:**\n- A complex case system with seven grammatical cases (Nominative, Genitive, Dative, Accusative, Instrumental, Locative, Vocative)\n- Case endings that vary based on grammatical gender (masculine, feminine, neuter)\n- Phonetic and semantic factors affecting inflectional forms (Bartnicka & Satkiewicz, 1990)"
    },
    {
        "question": "What methodology was used for transcribing and annotating the learner corpus?",
        "ground_truth": "The corpus was transcribed and annotated using the following methodology:\n- Manual transcriptions were created by the thesis author (a native Polish speaker) using ELAN software\n- Each file includes two parallel tiers: **\\*STU** (manual transcriptions reflecting exactly what the learner said) and **%pol** (corrected versions in standard Polish)\n- Transcriptions followed standard Polish orthographic norms rather than IPA phonetic transcription, for practical reasons including time efficiency, facilitating automated processing with NLP tools (lemmatization, POS tagging, case identification), and enabling future use by other researchers\n- Teacher utterances and non-Polish words were manually removed from the corpus\n- Automatic preprocessing included XML conversion, language detection, normalization, and alignment with automatic transcriptions in a consolidated JSON file"
    },
    {
        "question": "What tools and technologies were used for the automatic processing and analysis in this study?",
        "ground_truth": "The study employed several tools and technologies:\n- **Whisper (small model)** by OpenAI for automatic speech recognition, provided through Huma-Num servers\n- **spaCy** for Polish morphosyntactic analysis including lemmatization, part-of-speech tagging, and case identification\n- **pandas** for data manipulation\n- **fuzzywuzzy** (Levenshtein distance) for fuzzy string matching\n- **Epitran** for grapheme-to-phoneme transcription (IPA conversion)\n- **langdetect** for language detection\n- **matplotlib** and **seaborn** for visualization\n- **JiWER** for calculating Word Error Rate (WER) and Character Error Rate (CER)\n- **ELAN** for manual annotation of audio recordings\n- Python libraries including json, xml.etree, and csv for data processing"
    },
    {
        "question": "What were the main findings regarding declension errors made by the learners?",
        "ground_truth": "The analysis of declension errors revealed several key patterns:\n- **Overuse of the nominative case**: Learners frequently defaulted to the nominative (the base form) when other cases were required, with nominative usage increasing by 941.67% compared to expected\n- **Underuse of genitive and instrumental**: The genitive case showed a 95.28% decrease from expected usage, and the instrumental showed an 88.14% decrease\n- **Confusion between cases**: Approximately 80% of accusative and locative errors involved incorrect use of nominative; genitive and instrumental were also frequently replaced by nominative (~63% of the time)\n- **Locative-genitive confusion**: 52.63% of incorrect locative uses occurred where genitive was required, often influenced by familiar phrases\n- **Native language independence**: Case-related errors appeared largely independent of learners' native languages, suggesting these difficulties arise from the complexity of the Polish case system itself rather than L1 transfer"
    },
    {
        "question": "What were the most common pronunciation errors observed in the learner corpus?",
        "ground_truth": "The five most frequent pronunciation errors were:\n\n1. **Substitution of /w/ (ł) with /l/** – especially in *szkoły* /ʂkɔwɨ/ → *skola* /skɔla/ (32 learners)\n2. **Substitution of /ʂ/ (sz) with /s/** – in *szpital* /ʂpital/ → *spita* /spita/ (28 learners)\n3. **Omission of final affricate /t͡ɕ/ (ć)** – in *iść* /iɕt͡ɕ/ → *iś* /iɕ/ (25 learners)\n4. **Substitution of /t͡ʂ/ (cz) with /ʂ/ (sz)** – in *cztery* /t͡ʂtɛrɨ/ → *sztere* /ʂtɛrɛ/ (25 learners)\n5. **Substitution of /ʂ/ with /s/** – in *szkoły* (25 learners)\n\nThese errors indicate systematic challenges with Polish retroflex consonants and nasal vowels, with learners substituting unfamiliar sounds with more familiar ones from their native phonological inventories."
    },
    {
        "question": "How well did Whisper perform in transcribing Polish interlanguage overall?",
        "ground_truth": "Whisper faced significant challenges transcribing Polish interlanguage:\n\n| Metric | Score |\n|--------|-------|\n| WER mean (interlanguage) | 75.4% |\n| CER mean (interlanguage) | 46.4% |\n| WER median | 50% |\n| CER median | 22.2% |\n| WER mean (native speakers) | 13.74% |\n| CER mean (native speakers) | 6.44% |\n\nThe lower CER compared to WER reflects partially correct words preserving some letters. There was considerable variation across learner groups, with Italian and British learners showing the highest CERs (above 60%) while Dutch learners achieved the lowest (27%). The stark difference between learner and native corpora clearly demonstrates the impact of interlanguage on Whisper's performance."
    },
    {
        "question": "How did Whisper handle pronunciation-related interlanguage errors versus declension-related errors?",
        "ground_truth": "Whisper showed distinct tendencies depending on error type:\n\n**Pronunciation-related errors (662 examples):**\n- Identically transcribed: 10.88%\n- Overcorrected (correct in context): 30.51%\n- Overcorrected (incorrect in context): 26.59%\n- Hallucinated/invented words: 16.31%\n- Omitted: 15.71%\n\n**Declension-related errors (525 examples):**\n- Faithful reproduction (preserved error): 42.10%\n- Overcorrected: 21.71%\n- Invented form: 20.57%\n- Not transcribed: 8.19%\n- Unknown: 7.43%\n\nWhisper more frequently reproduced declension errors faithfully (42.10%) compared to pronunciation errors (10.88%), suggesting the system's architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, the 57.1% overcorrection rate for pronunciation errors indicates Whisper often normalizes non-standard learner forms into standard Polish."
    },
    {
        "question": "How well did spaCy perform in detecting grammatical cases in the corpus?",
        "ground_truth": "The evaluation of spaCy's case detection showed varying performance:\n\n| Corpus type | Accuracy |\n|-------------|----------|\n| Erroneous learner forms | 60% |\n| Corrected Polish forms | 75% |\n| Native Polish utterances | 67% |\n\nKey observations:\n- The interlanguage nature of the data significantly affected performance, particularly when errors impacted word suffixes due to pronunciation deviations\n- The tool also struggled with native Polish utterances, indicating that the complexity of the Polish case system itself poses challenges\n- The locative case was particularly problematic, with 0% precision and recall across all evaluations\n- The nominative case achieved the highest F1-scores (0.73 for erroneous forms, 0.62 for correct forms)\n\nThe author suggests that incorporating broader syntactic context by including preceding words might improve spaCy's performance."
    },
    {
        "question": "What are the main limitations of using ASR systems like Whisper for transcribing learner speech?",
        "ground_truth": "The study identified several key limitations:\n\n1. **Overcorrection tendency**: Whisper often \"hyper-normalizes\" learner speech by correcting errors, which obscures the interlanguage phenomena that SLA researchers need to study (El Ayari & Li, 2024)\n\n2. **Hallucinations**: The system sometimes produces entirely invented words or phrases, especially when confronted with highly deformed or unclear learner speech (16.31% of pronunciation-related cases)\n\n3. **Training data mismatch**: ASR systems are trained on native speech and perform poorly with non-native input, which exhibits variations that standard ASR systems are not trained to recognize\n\n4. **Language detection issues**: 15 out of 89 examples were transcribed in languages other than Polish due to the distorted nature of interlanguage and occasional code-switching\n\n5. **Missing transcriptions**: In 15.71% of pronunciation-related cases, no transcription was produced at all\n\n6. **Omission of disfluencies**: Systems tend to ignore repetitions, pauses, and other disfluencies that are important for SLA research"
    },
    {
        "question": "What future directions does the author propose for improving ASR systems for interlanguage transcription?",
        "ground_truth": "The author proposes several directions for future work:\n\n1. **Fine-tuning Whisper on interlanguage corpora**: Training the model to recognize and transcribe interlanguage forms rather than correcting them, using manually annotated data from native Polish speakers with linguistics or SLA backgrounds\n\n2. **L1-specific vs. universal models**: For pronunciation errors, separate models could be developed for different L1 groups since speakers show consistent patterns; for case-related errors, a universal model would likely suffice since these appear language-independent\n\n3. **Proficiency-level considerations**: Investigating whether separate corpora or models are needed for different proficiency levels, given the dynamic nature of interlanguage development\n\n4. **Broader training data**: Expanding beyond task-specific data (route directions) to cover various linguistic contexts and speaking styles\n\n5. **Dual-model system**: Creating one model to faithfully reproduce interlanguage and another to provide corrected versions, allowing learners to compare their productions with target forms\n\n6. **Improved morphosyntactic tools**: Enhancing tools like spaCy for better case identification in learner speech"
    },
    {
        "question": "What evaluation metrics were used to assess ASR performance and why?",
        "ground_truth": "Two standard ASR evaluation metrics were used:\n\n1. **Word Error Rate (WER)**: Based on Levenshtein distance, calculated as (Substitutions + Deletions + Insertions) / Number of words in reference\n\n2. **Character Error Rate (CER)**: Similarly calculated but at the character level\n\nThe author notes that **CER is a more informative metric for interlanguage evaluation** because:\n- WER does not correlate well with human intelligibility since it ignores semantics, pragmatics, and grammar (Hollands et al., 2022)\n- Pronunciation deviations often cause entire words to be misrecognized, heavily penalizing WER\n- CER provides finer-grained perspective where partially correct transcriptions are rewarded for character-level similarity\n- CER better reflects the degree to which ASR output preserves traces of the learner's original production\n- CER is more appropriate for multilingual contexts (K et al., 2024)"
    },
    {
        "question": "What is the significance of the study's findings for second language acquisition research and pedagogy?",
        "ground_truth": "The study's findings have several important implications:\n\n**For SLA research:**\n- Confirms that interlanguage is a systematic and dynamic system shaped by multiple factors beyond L1 transfer\n- Demonstrates that learners employ strategies such as simplification, overgeneralization, and omission in early acquisition\n- Provides detailed error patterns that can inform understanding of developmental sequences in Polish L2 acquisition\n- Highlights that case-related difficulties arise primarily from the target language complexity rather than native language interference\n\n**For pedagogy:**\n- Identifies specific pronunciation challenges (retroflex consonants, nasal vowels) and case confusions that instructors should address\n- Supports the development of targeted pronunciation training similar to earlier CAPT systems like AzAR (Wagner, 2010)\n- Suggests that error-preserving ASR could become a valuable tool for providing accurate feedback to learners\n\n**For computational tools:**\n- Demonstrates that learner corpora should be conceptualized as a low-resource language variety requiring specialized approaches (El Ayari & Li, 2024)\n- Shows the potential and current limitations of integrating ASR with morphosyntactic analysis for language learning applications"
    }
]