user_input,retrieved_contexts,response,reference,faithfulness,answer_relevancy,context_precision,context_recall
What are the two main research objectives of this thesis?,"[""Headers: Introduction > Objectives\nHeaders: Introduction > Objectives\n\nThis research is structured around two main objectives. The first objective is a qualitative linguistic analysis of learners' productions. Upon completion of corpus processing and extraction of learners' utterances, the study aims to identify the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction. An additional goal is to investigate the influence of learners' native languages on error patterns, determining whether specific trends can be observed among groups sharing the same mother tongue.  \nThe second objective is the evaluation of the Whisper system's performance in transcribing Polish interlanguage. A key goal is to ensure that Whisper produces faithful transcriptions of learner speech, capturing the interlanguage exactly as spoken, including all deviations, errors, and disfluencies. This assessment examines the extent to which Whisper can accurately reflect learner utterances, while categorizing the types of outputs the system introduces. The qualitative analysis of these renderings will inform the limitations and strengths of Whisper in this context. Ultimately, the findings of this thesis aim to support potential adaptations to Whisper's architecture, enhancing its ability to transcribe Polish interlanguage precisely as articulated by the learner, thereby providing a reliable tool for second language acquisition research."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Introduction\n\nThe first analysis conducted in this study focused on the non-standard forms made by learners. The primary objective was to identify the most common types of deviations produced by learners of Polish after a 14-hour course. In addition, the second goal was to investigate the potential influence of the learners' native languages on the nature of these productions. To facilitate a clearer visualization of deviations, a dedicated tool-platform will also be developed, enabling an easier and more systematic analysis of the data."", ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data.""]","The two main research objectives of this thesis are: 

1. To conduct a qualitative linguistic analysis of learners' productions, aiming to identify the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction, as well as to investigate the influence of learners' native languages on error patterns.

2. To evaluate the performance of the Whisper system in transcribing Polish interlanguage, ensuring that it produces faithful transcriptions of learner speech, capturing all deviations, errors, and disfluencies, while also assessing the accuracy of these transcriptions and the strengths and limitations of the system.","The thesis has two main objectives:
1. **Qualitative linguistic analysis of learner productions** – to identify the most frequent types of errors produced by adult learners of Polish after approximately 14 hours of instruction, and to investigate whether learners' native languages influence error patterns.
2. **Evaluation of Whisper's performance** – to assess how well the Whisper automatic speech recognition system transcribes Polish interlanguage, with a focus on ensuring faithful reproduction of learner speech including all deviations, errors, and disfluencies rather than overcorrecting them.",0.875,0.9580367157267076,0.999999999975,1.0
What is interlanguage and why is it important in this study?,"[""Headers: General Context > Context > Interlanguage in Second Language Acquisition > Definition of Interlanguage\nHeaders: General Context > Context > Interlanguage in Second Language Acquisition > Definition of Interlanguage\n\n*Interlanguage* is a concept introduced by [@selinker-1972] to describe the linguistic system that emerges when an adult learns a second language. It refers to a transitional linguistic system developed by the learner to communicate in the target language. This system is shaped by several factors, including the target language and the learner's native language [@tarone-2006]. In other words, interlanguage represents a transitional stage situated between the target language -- through the partial application of its lexical items and grammatical rules -- and the native language, from which the learner may potentially transfer previously acquired structures and patterns. As a result, interlanguage is typically marked by a high frequency of variations from the norm [@tarone-2006], reflecting its evolving and dynamic nature.  \n![Diagram of Interlanguage (Source: [@selinker-1972])](photos/interlanguage.png)"", ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.', ""Headers: Experimentations > Future Perspectives > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives > Open Questions and Obstacles\n\nA key question in designing such a system is whether it should be tailored to learners of a specific native language or whether a more general model would suffice. On the one hand, the error analysis in this study shows that speakers of different native languages often exhibit consistent patterns, particularly in pronunciation. This suggests that separate models for pronunciation errors could be developed for different L1 groups, although some errors may also be universal across learners. On the other hand, case-related errors appear to be largely independent of the learner's native language, indicating that a universal model would likely be sufficient for handling morphological deviations.  \nA major challenge remains the inherently dynamic and individual nature of interlanguage. Learners follow unique developmental trajectories, and errors evolve over time depending on exposure, proficiency, and learning strategies. This raises questions about whether separate corpora or models would be needed for different proficiency levels, which would significantly increase data requirements and necessitate careful learner selection.  \nFinally, the corpus used in this study is highly task-specific, focusing exclusively on giving and understanding route directions. To develop a more robust and generalizable interlanguage-adapted Whisper, training data would need to cover a broader variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across different communicative situations.  \nAnother avenue for future development is the creation of a dual-model system for language learning. One model could faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while a second model could provide the corrected, standard version of the utterance. Such a setup would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction.""]","Interlanguage is a linguistic system that emerges when an adult learns a second language, representing a transitional state influenced by both the target language and the learner's native language (Selinker, 1972). It is characterized by the partial application of the target language's lexical items and grammatical rules, along with the potential transfer of previously acquired structures from the native language (Tarone, 2006). The dynamic nature of interlanguage is reflected in its high frequency of variations from the norm, making it a crucial area of investigation in the context of second language acquisition.

In this study, interlanguage is important because it provides the theoretical foundation for understanding learner language patterns, especially in relation to Polish phonetics and morphosyntax, which present specific challenges for learners. The study aims to analyze these patterns and explores the potential of automatic tools for processing interlanguage data, thereby justifying the focus on this transitional system as a key aspect of adult second language acquisition.","Interlanguage is a concept introduced by Selinker (1972) to describe the transitional linguistic system that emerges when an adult learns a second language. It represents a stage between the target language (through partial application of its lexical items and grammatical rules) and the native language (from which the learner may transfer previously acquired structures). Interlanguage is typically marked by a high frequency of variations from the norm (Tarone, 2006), reflecting its evolving and dynamic nature. This concept is central to the study because the research aims to faithfully capture and analyze these interlanguage features in learner speech rather than having them automatically corrected by ASR systems.",1.0,0.8549704374842115,0.999999999975,0.75
What is the VILLA project and how does it relate to the corpus used in this thesis?,"[""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", ""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.', ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data.""]","The VILLA project is the source of the learner corpus analyzed in this thesis. It involved testing students' language skills in Polish through tasks such as *Route Direction*, where participants had to give directions using a provided map. The oral productions during these tests were recorded and later transcribed, forming the basis of the corpus used in the study. The learner corpus is complemented by a smaller native speaker corpus, which serves as a comparative benchmark, allowing for an evaluation of linguistic errors and the performance of automatic tools like Whisper in processing Polish interlanguage (General Context > Context > The VILLA Project > Description of the Task; Experimentations > Corpus > Conclusions).","The VILLA project (""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation""), conducted by Dimroth et al. (2013), investigated the initial stages of foreign language acquisition under controlled input conditions. The study involved complete beginners from five linguistic backgrounds (Dutch, English, French, German, and Italian) who each received 14 hours of instruction in Polish as a foreign language. The corpus used in this thesis consists of manual transcriptions of voice recordings from the Route Direction task, where learners had to give directions in Polish using a map. This corpus includes 89 files totaling 2 hours and 19 minutes of recordings from learners in the meaning-based groups across all five countries.",1.0,0.8674244023792299,0.999999999975,0.5
What are the main linguistic challenges of Polish for foreign language learners?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", 'Headers: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nIn addition, Polish includes several digraphs -- graphic combinations of two letters that represent a single sound [@foland-2007]:  \n:::\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ ------------------------------------------------------------------\nCh               ch            /x/      chata /xata/ (\\""hut\\"")\nCz               cz            /t͡ʂ/     czysty /t͡ʂɨstɨ/ (\\""clean\\"")\nDz               dz         /d͡z/, /t͡s/  dzwon /d͡zvɔn/ (\\""bell\\""), powiedz /pɔvjɛt͡s/ (\\""say\\"", imp., 2sg)\nDź               dź         /d͡ʑ/, /t͡ɕ/  dźwięk /d͡ʑvjɛŋk/ (\\""sound\\""), powódź /pɔvud͡ʑ/ (\\""flood\\"")\nDż               dż            /d͡ʐ/     dżem /d͡ʐɛm/ (\\""jam\\"")\nRz               rz          /ʐ/, /ʂ/   rzeka /ʐɛka/ (\\""river\\""), malarz /malaʂ/ (\\""painter\\"")\nSz               sz            /ʂ/      kosz /kɔʂ/ (\\""basket\\"")  \n: Polish digraphs and their IPA transcriptions\n:::  \nOne of the more challenging aspects of learning Polish is its pronunciation. The language contains phonemes that are not present in other widely spoken Western languages, even if some may appear similar. Moreover, the frequent occurrence of complex phoneme clusters (difficult sounds placed directly next to each other) further complicates pronunciation for learners attempting to articulate Polish words accurately.']","The main linguistic challenges of Polish for foreign language learners include its complex consonant clusters and unfamiliar sounds, such as the initial cluster in the verb *skręcić* (*skr*-) and nasal vowels like *ę*. These elements require precise articulation that may not exist in the learners' native phonetic systems, making accurate pronunciation particularly difficult, especially for beginners. Additionally, Polish has a phonological system with numerous sounds that are absent in many other languages, alongside a complex grammar system characterized by intricate case inflection. These factors contribute to frequent pronunciation and grammatical errors, complicating the acquisition of the language for non-Slavic learners, particularly after limited exposure (e.g., only 14 hours of study) (Foland-Kugler, 2007).","Polish presents several significant challenges for learners:

**Phonological challenges:**
- Complex consonant clusters (e.g., the *skr-* cluster in *skręcić*)
- Retroflex consonants (/ʂ/, /ʐ/, /t͡ʂ/) that are absent in many Western languages
- Nasal vowels (*ą* /ɔ̃w̃/ and *ę* /ɛ̃w̃/)
- Palatal fricatives and affricates

**Morphological challenges:**
- A complex case system with seven grammatical cases (Nominative, Genitive, Dative, Accusative, Instrumental, Locative, Vocative)
- Case endings that vary based on grammatical gender (masculine, feminine, neuter)
- Phonetic and semantic factors affecting inflectional forms (Bartnicka & Satkiewicz, 1990)",1.0,0.9999994629163874,0.999999999975,0.8
What methodology was used for transcribing and annotating the learner corpus?,"[""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThere are a few reasons why the recordings were transcribed in accordance with standard Polish orthography instead of the phonetic alphabet. Firstly, manual transcription is a very tedious and time-consuming process that requires a lot of attention. Consequently, the annotation rules should be as simple and intuitive as possible [@Grochola-Szczepanek_Woźniak_2018]. In addition, full phonemic transcription using the IPA would have been significantly more time-consuming. Given the limited time, this would have led to a substantial reduction in the size of the corpus. Moreover, such transcription facilitates processing by automated tools. Only general orthographic transcription allows the use of tools such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection, which are designed for standard orthography. Finally, the corpus and the analysis are intended for further work by other researchers in the laboratory, not only phoneticians and phonologists.  \nNevertheless, in the subsequent analysis of phonetic errors, the orthographic representations were automatically converted into IPA symbols to enable a more precise visualization of pronunciation deviations.  \nThe same task was also carried out by four native Polish speakers, whose utterances were recorded and transcribed following the same procedure as for the learner corpus. While this native speaker corpus is significantly smaller in size, it serves as a reference point for the subsequent evaluation of the performance of automatic linguistic tools.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [] for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.""]","The learner corpus was transcribed using standard Polish orthography instead of the phonetic alphabet. This choice was made to simplify the annotation process, as manual transcription is time-consuming. Standard orthographic transcription allows for the use of automated tools like lemmatization, part-of-speech tagging, and language detection, which are designed for this format. Additionally, the orthographic representations were later converted into IPA symbols for a more precise analysis of phonetic errors. The annotations included both manual transcriptions and their corresponding corrected Polish versions, and the preprocessing pipeline combined manual and automatic procedures to integrate data into a structured JSON file enriched with lemma-based alignments. An automatic word-by-word alignment procedure was implemented to identify and extract errors by comparing learners' transcriptions with the correct versions.","The corpus was transcribed and annotated using the following methodology:
- Manual transcriptions were created by the thesis author (a native Polish speaker) using ELAN software
- Each file includes two parallel tiers: **\*STU** (manual transcriptions reflecting exactly what the learner said) and **%pol** (corrected versions in standard Polish)
- Transcriptions followed standard Polish orthographic norms rather than IPA phonetic transcription, for practical reasons including time efficiency, facilitating automated processing with NLP tools (lemmatization, POS tagging, case identification), and enabling future use by other researchers
- Teacher utterances and non-Polish words were manually removed from the corpus
- Automatic preprocessing included XML conversion, language detection, normalization, and alignment with automatic transcriptions in a consolidated JSON file",1.0,0.6047823482550514,0.999999999975,0.5
What tools and technologies were used for the automatic processing and analysis in this study?,"[""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", 'Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.', ""Headers: Experimentations > Corpus > Annotation and Preprocessing > Tools and Implementation\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Tools and Implementation\n\nAll scripts developed in this thesis were implemented in Python within a Jupyter Notebook environment. For the automatic speech recognition of learners' utterances, we used the small model of Whisper by OpenAI, in automatic language mode, provided by Huma-Num servers, since Polish was not available.  \nThe implementation further relied on a range of Python libraries, including *spaCy* for morphosyntactic analysis, *pandas* for data manipulation, *fuzzywuzzy* (Levenshtein distance) for fuzzy string matching, *Epitran* for grapheme-to-phoneme transcription, *langdetect* for language detecting, *matplotlib* and *seaborn* for visualization, *JiWER* for calculating WER and CER, as well as *json*, *xml.etree*, and *csv* for structured data processing and file management.  \nThis configuration ensured reproducibility and scalability, while enabling the efficient integration of data processing, linguistic analysis, and evaluation procedures."", ""Headers: Experimentations > Corpus > Annotation and Preprocessing > Automatic Preprocessing\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Automatic Preprocessing\n\nThe automatic data‑processing workflow comprises a few successive stages. First, the code systematically traverses all corrected `.eaf` files. For each file, it retrieves the learner identifier together with every learner utterance (\\*STU) and its corresponding corrected version in Polish (%pol). These elements are then compiled into an individual, well‑structured XML document that records the learner's ID, country of origin, and each pair of learner and target‑language statements (see [] for an example XML file).  \nThe second stage focuses on the automatic transcriptions stored as `.txt` files. The function first verifies that the content is indeed Polish; non-Polish segments are named differently in the final file. Out of 89 examples, 15 were generated in a language other than Polish. These hallucinations are caused by the highly distorted nature of the interlanguage, as well as by rare instances where some learners briefly switched to their native language.  \nThe program subsequently normalises the remaining text by converting it to lower case, removing all punctuation except hyphens, and eliminating superfluous whitespace.  \nDuring the enrichment phase, the procedure aligns each cleaned automatic transcription with its counterpart XML file, matching them by filename. For every resulting entry it records the learner number, the country, the automatic transcription, and the full set of manual transcriptions together with their Polish corrections, each labelled with its segment number. This step yields a comprehensive dataset that integrates all available sources.  \nFinally, the entire enriched corpus is exported to a single JSON file (see [] for an example fragment of the JSON file). This consolidated resource provides an organised view of the data, thereby facilitating subsequent quantitative and qualitative analyses.""]","The study utilized several tools and technologies for automatic processing and analysis, implemented in Python within a Jupyter Notebook environment. The following key components were used:

1. **Whisper by OpenAI** - For automatic speech recognition of learners' utterances.
2. **Python Libraries**:
   - *spaCy* - For morphosyntactic analysis.
   - *pandas* - For data manipulation.
   - *fuzzywuzzy* - For fuzzy string matching using Levenshtein distance.
   - *Epitran* - For grapheme-to-phoneme transcription.
   - *langdetect* - For language detection.
   - *matplotlib* and *seaborn* - For visualization.
   - *JiWER* - For calculating Word Error Rate (WER) and Character Error Rate (CER).
   - *json*, *xml.etree*, and *csv* - For structured data processing and file management.

These tools ensured reproducibility and scalability, allowing efficient integration of data processing, linguistic analysis, and evaluation procedures.","The study employed several tools and technologies:
- **Whisper (small model)** by OpenAI for automatic speech recognition, provided through Huma-Num servers
- **spaCy** for Polish morphosyntactic analysis including lemmatization, part-of-speech tagging, and case identification
- **pandas** for data manipulation
- **fuzzywuzzy** (Levenshtein distance) for fuzzy string matching
- **Epitran** for grapheme-to-phoneme transcription (IPA conversion)
- **langdetect** for language detection
- **matplotlib** and **seaborn** for visualization
- **JiWER** for calculating Word Error Rate (WER) and Character Error Rate (CER)
- **ELAN** for manual annotation of audio recordings
- Python libraries including json, xml.etree, and csv for data processing",1.0,0.9482691992689403,0.4166666666458333,0.9090909090909091
What were the main findings regarding declension errors made by the learners?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nIn addition, heatmaps were generated to visualize the distribution of grammatical case errors, comparing the incorrect cases used by learners with the correct ones. Cells outlined in green correspond to correct case usage, but since such examples were excluded from the corpus at an earlier stage, these cells all show zero values.  \nFrom the first table (Figure[]), we can confirm the previously mentioned observation that the nominative case is dominant among incorrect usages. Although the overall number of accusative and locative errors is relatively low, in most of these cases (around 80%), learners incorrectly used the nominative instead of the expected form. Similarly, both genitive and instrumental cases are frequently replaced by the nominative -- approximately 63% of the time -- though some of these errors also involve confusion between genitive, instrumental, and locative.  \nThe locative case, which also appears to be slightly overused, is typically required after prepositions such as *na* (\\""on\\"") or *w* (\\""in\\""). This overuse may stem from learners relying on familiar phrases and generalising them to contexts where other cases are expected. The characteristic suffixes of Polish cases (such as -*u*, -*e*, -*em*, or -*a*) can be particularly misleading for learners. For example, the phrase *obok szpitalu* instead of the correct *obok szpitala* (\\""next to the hospital\\"") illustrates confusion between the genitive and locative, likely influenced by more frequent expressions like *w szpitalu* (\\""in the hospital\\""). In fact, 52.63% of incorrect uses of the locative occurred in contexts where the genitive case was required. Furthermore, 36.84% of the same locative errors involved confusion with the instrumental (*za szpitalem* (\\""behind the hospital\\"")).']","The main findings regarding declension errors made by the learners include:

1. Learners tended to overuse the nominative case, which functions as the default form in Polish, often applying it in contexts where other cases were required.
2. Frequent confusion among genitive, instrumental, locative, and accusative cases was noted, primarily due to the morphologically similar suffixes of these cases.
3. Specifically, 53.85% of incorrect accusative forms were used where the genitive was required, and 23.08% where the instrumental was expected.
4. There is little evidence to suggest that the learners' native languages significantly influenced their case-related errors, indicating that these difficulties are more reflective of the inherent complexity of the Polish case system rather than cross-linguistic transfer.
5. Overgeneralization of case forms and limited exposure were key factors leading to predictable error patterns, with many errors resulting from reliance on familiar phrases and incorrect assumptions about case usage.
6. The analysis indicated that the complexity of the Polish case system poses challenges for learners, with a notable percentage of locative errors stemming from confusion with the genitive and instrumental cases.","The analysis of declension errors revealed several key patterns:
- **Overuse of the nominative case**: Learners frequently defaulted to the nominative (the base form) when other cases were required, with nominative usage increasing by 941.67% compared to expected
- **Underuse of genitive and instrumental**: The genitive case showed a 95.28% decrease from expected usage, and the instrumental showed an 88.14% decrease
- **Confusion between cases**: Approximately 80% of accusative and locative errors involved incorrect use of nominative; genitive and instrumental were also frequently replaced by nominative (~63% of the time)
- **Locative-genitive confusion**: 52.63% of incorrect locative uses occurred where genitive was required, often influenced by familiar phrases
- **Native language independence**: Case-related errors appeared largely independent of learners' native languages, suggesting these difficulties arise from the complexity of the Polish case system itself rather than L1 transfer",1.0,0.8314843656984626,0.999999999975,0.3333333333333333
What were the most common pronunciation errors observed in the learner corpus?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nThe five most frequent pronunciation errors observed in the learner corpus reveal recurring patterns and potential phonological challenges, most likely influenced by the learners' native languages. The most common error concerned the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups, with the highest number found among German speakers (10); however, all groups exhibited this error at some point. The second most common error involved the replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, where learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/. This suggests difficulty in distinguishing between retroflex and alveolar fricatives. Once again, German speakers accounted for the highest number of errors (10), while French learners made the fewest (2). A similar phenomenon appeared in the third error, where the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/ was omitted, resulting in the simplified form *iś* /iɕ/, produced by 25 learners. This pattern may indicate difficulty pronouncing complex affricates in word-final position. Interestingly, the English group committed this error most frequently (11), whereas it was least common among German learners (1). The fourth error again reflected confusion between retroflex and alveolar consonants: *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This error was most common among Dutch speakers (9) and was not observed at all in the English group. An interesting case worth mentioning, although it ranks only thirteenth most frequent error, is the tendency of Italian learners to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as *niskon*. This substitution illustrates the difficulty of"", 'Headers: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nTaken together, these errors point to systematic challenges with Polish retroflex consonants and nasal vowels, as learners tend to replace them with more familiar alveolar sounds or denasalized vowels from their native phonological inventories. The full dataset provides a rich basis for further phonological and cross-linguistic analysis.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Corpus Processing\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Corpus Processing\n\n: Excerpt: Distribution of correct vs. erroneous forms and example words per learner country\n:::  \nNevertheless, this way of presenting phonetic errors is not ideal. For future linguistic analysis, it is crucial to retain information about the specific words in which a given phonetic error occurred, as this can help identify underlying factors such as native language interference or target language influence. While in this representation we can see which words contained a particular phoneme error, it does not indicate whether all learners actually mispronounced those words. For instance, in the first example, one learner might have pronounced Juliusza correctly but made an error in proszę. Although this representation already offers some insights, it lacks precision and may not be sufficiently informative for in-depth phonetic analysis or error pattern discovery.  \nWe developped a second method of grouping pronunciation errors involved organizing them by lemma in order to identify recurring mispronunciations of the same lexical item. For each entry, the script extracts the lemma of the correct form using the Polish *spaCy* model. Then, it groups all instances that share the same lemma, correct form, and corresponding erroneous pronunciation. Within each group, it aggregates the different correct and incorrect forms as well as the learner IDs associated with the error. As always, the script also shows the number of learners from each country and the total number of learners for each error.  \nIn the second part, the code uses the *Epitran* library to convert all correct and erroneous forms into their phonetic representations. This results in a final file where all entries are transcribed in IPA, allowing for a more fine-grained analysis of recurring pronunciation patterns and errors across learners. Both representations are saved into new CSV files.']","The most common pronunciation errors observed in the learner corpus included:

1. Substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which learners often pronounced as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners, notably by 10 German speakers.

2. Replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, resulting in pronunciations like *spita* /spita/ or *spytal* /spɨtal/. German speakers accounted for the highest number of these errors (10), while French learners made the fewest (2).

3. Omission of the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/, leading to the simplified form *iś* /iɕ/, which was produced by 25 learners. This error was most prevalent among English learners (11).

4. Confusion between retroflex and alveolar consonants, as seen in the word *cztery* /t͡ʂtɛrɨ/, commonly realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/. This error was most frequent among Dutch speakers (9) and not observed in the English group.

Additionally, Italian learners displayed a tendency to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with /ɔn/, creating forms like *niskon*, although this error ranked thirteenth in frequency.","The five most frequent pronunciation errors were:

1. **Substitution of /w/ (ł) with /l/** – especially in *szkoły* /ʂkɔwɨ/ → *skola* /skɔla/ (32 learners)
2. **Substitution of /ʂ/ (sz) with /s/** – in *szpital* /ʂpital/ → *spita* /spita/ (28 learners)
3. **Omission of final affricate /t͡ɕ/ (ć)** – in *iść* /iɕt͡ɕ/ → *iś* /iɕ/ (25 learners)
4. **Substitution of /t͡ʂ/ (cz) with /ʂ/ (sz)** – in *cztery* /t͡ʂtɛrɨ/ → *sztere* /ʂtɛrɛ/ (25 learners)
5. **Substitution of /ʂ/ with /s/** – in *szkoły* (25 learners)

These errors indicate systematic challenges with Polish retroflex consonants and nasal vowels, with learners substituting unfamiliar sounds with more familiar ones from their native phonological inventories.",1.0,0.9782630867655203,0.999999999975,0.5714285714285714
How well did Whisper perform in transcribing Polish interlanguage overall?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.""]","Whisper's performance in transcribing Polish interlanguage displayed distinct tendencies depending on the type of learner errors. For pronunciation-related errors, it showed a low rate of faithful reproduction (10.88%), often overcorrecting learner speech to reproduce canonical forms instead of the actual interlanguage output. In contrast, for declension-related errors, Whisper achieved a higher faithful reproduction rate of 42.10%. However, this still indicates that improvements are needed, particularly for better capturing phonetic inaccuracies. Overall, while Whisper can provide a foundation for monitoring learner productions, its architecture is currently more adept at detecting grammatical errors than phonetic inaccuracies, suggesting that enhancing its sensitivity to both types of deviations would make it a more effective tool for accurately capturing interlanguage phenomena.","Whisper faced significant challenges transcribing Polish interlanguage:

| Metric | Score |
|--------|-------|
| WER mean (interlanguage) | 75.4% |
| CER mean (interlanguage) | 46.4% |
| WER median | 50% |
| CER median | 22.2% |
| WER mean (native speakers) | 13.74% |
| CER mean (native speakers) | 6.44% |

The lower CER compared to WER reflects partially correct words preserving some letters. There was considerable variation across learner groups, with Italian and British learners showing the highest CERs (above 60%) while Dutch learners achieved the lowest (27%). The stark difference between learner and native corpora clearly demonstrates the impact of interlanguage on Whisper's performance.",1.0,0.8248309751556655,0.999999999975,0.18181818181818182
How did Whisper handle pronunciation-related interlanguage errors versus declension-related errors?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.']","Whisper handled pronunciation-related interlanguage errors and declension-related errors differently. For pronunciation errors, Whisper transcribed words identically in only 10.88% of cases, often normalizing non-standard learner forms into standard Polish. Overcorrections were prevalent, with 57.1% of words being replaced by correct but contextually inappropriate standard forms. Additionally, in 16.31% of cases, Whisper generated entirely new words, indicating challenges with recognizing unclear learner speech. In contrast, for declension errors, Whisper achieved a 42.10% rate of faithful reproduction of learners' incorrect forms. Although this was higher than for pronunciation errors, it still indicated a need for improvement, especially in capturing case-related deviations. Whisper thus showed a tendency to be more effective in detecting systematic grammatical errors than in handling phonetic inaccuracies. Overall, these patterns suggest that enhancements are necessary for Whisper to better accommodate both types of interlanguage errors.","Whisper showed distinct tendencies depending on error type:

**Pronunciation-related errors (662 examples):**
- Identically transcribed: 10.88%
- Overcorrected (correct in context): 30.51%
- Overcorrected (incorrect in context): 26.59%
- Hallucinated/invented words: 16.31%
- Omitted: 15.71%

**Declension-related errors (525 examples):**
- Faithful reproduction (preserved error): 42.10%
- Overcorrected: 21.71%
- Invented form: 20.57%
- Not transcribed: 8.19%
- Unknown: 7.43%

Whisper more frequently reproduced declension errors faithfully (42.10%) compared to pronunciation errors (10.88%), suggesting the system's architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, the 57.1% overcorrection rate for pronunciation errors indicates Whisper often normalizes non-standard learner forms into standard Polish.",1.0,0.9825201724317706,0.999999999975,1.0
How well did spaCy perform in detecting grammatical cases in the corpus?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nAn evaluation of *spaCy*'s performance in case detection was conducted separately for the incorrect learner forms and their corrected counterparts. The results show that *spaCy* achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.  \n**Case**                           **Precision**    **Recall**   **F1-score**   **Support**\n--------------------------------- ---------------- ------------ -------------- -------------\n*Evaluation on erroneous cases*\nAcc                                     0.38           0.40          0.39           20\nDat                                     0.00           0.00          0.00            0\nGen                                     0.60           0.59          0.60           61\nIns                                     0.75           0.55          0.63           22\nLoc                                     0.00           0.00          0.00           21\nNom                                     0.74           0.73          0.73           142\nnan                                     0.10           0.50          0.16            6\n**Accuracy**                       **0.60** / 272\n**Macro avg**                           0.37           0.39          0.36           272\n**Weighted avg**                        0.61           0.60          0.60           272\n*Evaluation on correct cases*\nAcc                                     1.00           1.00          1.00           23\nDat                                     0.00           0.00          0.00            0\nGen                                     0.90           0.65          0.75           162\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5"", ""Headers: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5\n**Accuracy**                       **0.75** / 306\n**Macro avg**                           0.44           0.52          0.46           306\n**Weighted avg**                        0.77           0.75          0.74           306  \n: Classification metrics for erroneous and correct forms by grammatical case  \nTo better understand whether these difficulties stem from interlanguage or from the complexity of the language itself, the same procedure was applied to the small Polish native corpus. The overall accuracy in this case was only 67%, which falls between the scores observed for learner errors and corrected forms.  \n**Case**            **Precision**   **Recall**   **F1-score**   **Support**\n------------------ --------------- ------------ -------------- -------------\nAcc                     1.00           0.50          0.67            2\nDat                     0.00           0.00          0.00            0\nGen                     0.25           0.67          0.36            3\nIns                     0.86           1.00          0.92            6\nLoc                     0.00           0.00          0.00            7\nNom                     0.79           0.94          0.86           16\nUNK                     0.00           0.00          0.00            2\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case', ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context.""]","*spaCy*'s performance in detecting grammatical cases varied between the incorrect learner forms and their corrected counterparts. For the incorrect forms, *spaCy* achieved an overall accuracy of 60%, with specific performance metrics as follows:

- Nom: 0.74 precision, 0.73 recall, 0.73 F1-score
- Gen: 0.60 precision, 0.59 recall, 0.60 F1-score
- Ins: 0.75 precision, 0.55 recall, 0.63 F1-score

In contrast, for the corrected forms, *spaCy* showed improved accuracy at 75%, with highest performance on Gen (0.90 precision, 0.65 recall, 0.75 F1-score) and Ins (0.73 precision, 1.00 recall, 0.85 F1-score).

Additionally, when evaluated on a small native Polish corpus, *spaCy* garnered an overall accuracy of 67% (Accuracy metrics detailed above). The results indicate that while *spaCy* performs reasonably well with corrected forms, it still faces challenges with both learner errors and native utterances, influenced by the complexity of the Polish case system.","The evaluation of spaCy's case detection showed varying performance:

| Corpus type | Accuracy |
|-------------|----------|
| Erroneous learner forms | 60% |
| Corrected Polish forms | 75% |
| Native Polish utterances | 67% |

Key observations:
- The interlanguage nature of the data significantly affected performance, particularly when errors impacted word suffixes due to pronunciation deviations
- The tool also struggled with native Polish utterances, indicating that the complexity of the Polish case system itself poses challenges
- The locative case was particularly problematic, with 0% precision and recall across all evaluations
- The nominative case achieved the highest F1-scores (0.73 for erroneous forms, 0.62 for correct forms)

The author suggests that incorporating broader syntactic context by including preceding words might improve spaCy's performance.",1.0,0.8813343854280197,0.999999999975,0.8181818181818182
What are the main limitations of using ASR systems like Whisper for transcribing learner speech?,"['Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.', 'Headers: General Context > State of the Art > Conclusions\nHeaders: General Context > State of the Art > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. For example, the system might produce incorrect text or suggest pronunciation corrections that do not match the learner\'s actual production, potentially providing misleading guidance. However, continuous improvements in machine learning and the increasing availability of diverse speech data have significantly reduced the accuracy gap between native and non-native recognition (e.g., Google ASR reduced this gap from 20% to 3--5%) [@gottardi; @https://doi.org/10.1002/tesq.3006].  \nRecent research highlights both the potential and the challenges of using automatic speech recognition (ASR) for pronunciation training. [@michot2024errorpreservingautomaticspeechrecognition] addressed the crucial issue of designing an ASR system that not only transcribes learner speech accurately but also preserves their errors, thus enabling effective corrective feedback. To this end, they collected approximately 85 hours of spontaneous English speech from Swiss learners in grades 4--6 (about 45,000 utterances) and manually transcribed it with explicit error annotations. They proposed a new evaluation metric, the Word-Based Error Preservation Rate (WEPR), to measure the extent to which ASR systems maintain learner errors instead of automatically ""correcting"" them. Their findings demonstrated that a fine-tuned ASR model, trained directly on children\'s data, achieved a substantially higher WEPR and lower Word Error Rate (WER) than off-the-shelf systems, underscoring the promise of error-preserving ASR for pedagogical purposes.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\n\nSince systems like Whisper are trained primarily on standard language transcribing interlanguage presents a significant challenge. This study explores the use of automatic transcription for interlanguage in the context of second language acquisition. In this setting, the goal of the ASR tool is not simply to provide a correct transcription, but rather to reproduce the learner's utterance as faithfully as possible, including any linguistic errors. Overcorrection, therefore, is undesirable, as it obscures the learner's original production. Based on these considerations, it can be hypothesized that overcorrection is likely to be the most frequent type of transcription error encountered in this corpus. In this section, we assess Whisper's performance on such dataset and examine the extent to which its output faithfully reflects the learners' original speech.""]","The main limitations of using ASR systems like Whisper for transcribing learner speech include:

1. **Overcorrection**: These systems often ""hyper-normalize"" learner speech by correcting errors, which can introduce inaccuracies and obscure the learner's original productions, such as misrepresenting forms like *expériencer* as *expérimenter* ({El Ayari} and Li, 2024). 

2. **Loss of Disfluencies**: ASR systems tend to omit disfluencies, such as repetitions and pauses, which are important for understanding the learner's speech patterns and the process of language acquisition ({El Ayari} and Li, 2024).

3. **Dependence on Native Training Data**: ASR systems are primarily trained on native speech, leading to a performance disparity when processing non-native input. This can result in lower transcription accuracy and provide misleading corrections or interpretations of learner speech (Gottardi et al., 2022) (McCrocklin and Edalatishams, 2020).

4. **Lack of Robustness**: Early ASR systems demonstrated potential but lacked robustness, and even modern models like Whisper risk excessive normalization of learner speech, hindering the accurate representation of interlanguage features (Michot et al., 2024).

5. **Insufficient Adaptation to Learner Data**: There is a need for fine-tuning ASR models on learner-specific data to ensure that these systems can accurately capture and represent the unique patterns in non-native speech without suppressing errors (Gottardi et al., 2022) (McCrocklin and Edalatishams, 2020). 

Overall, these limitations compromise the reliability of ASR tools for research in second language acquisition (SLA) and effective pedagogical application.","The study identified several key limitations:

1. **Overcorrection tendency**: Whisper often ""hyper-normalizes"" learner speech by correcting errors, which obscures the interlanguage phenomena that SLA researchers need to study (El Ayari & Li, 2024)

2. **Hallucinations**: The system sometimes produces entirely invented words or phrases, especially when confronted with highly deformed or unclear learner speech (16.31% of pronunciation-related cases)

3. **Training data mismatch**: ASR systems are trained on native speech and perform poorly with non-native input, which exhibits variations that standard ASR systems are not trained to recognize

4. **Language detection issues**: 15 out of 89 examples were transcribed in languages other than Polish due to the distorted nature of interlanguage and occasional code-switching

5. **Missing transcriptions**: In 15.71% of pronunciation-related cases, no transcription was produced at all

6. **Omission of disfluencies**: Systems tend to ignore repetitions, pauses, and other disfluencies that are important for SLA research",1.0,0.9999995360536422,0.999999999975,0.5714285714285714
What future directions does the author propose for improving ASR systems for interlanguage transcription?,"['Headers: General Context > State of the Art > Conclusions\nHeaders: General Context > State of the Art > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', 'Headers: General Context > State of the Art > Introduction\nHeaders: General Context > State of the Art > Introduction\n\nAutomatic Speech Recognition (ASR) has undergone remarkable progress in recent decades, evolving from early systems limited to a small set of commands to deep learning--based models capable of handling spontaneous, continuous speech in real-world conditions. While ASR technologies are now widely applied in domains such as virtual assistants, customer service, and accessibility tools, their use in second language (L2) learning and assessment still requires careful evaluation of their performance.', ""Headers: Experimentations > Future Perspectives > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives > Open Questions and Obstacles\n\nA key question in designing such a system is whether it should be tailored to learners of a specific native language or whether a more general model would suffice. On the one hand, the error analysis in this study shows that speakers of different native languages often exhibit consistent patterns, particularly in pronunciation. This suggests that separate models for pronunciation errors could be developed for different L1 groups, although some errors may also be universal across learners. On the other hand, case-related errors appear to be largely independent of the learner's native language, indicating that a universal model would likely be sufficient for handling morphological deviations.  \nA major challenge remains the inherently dynamic and individual nature of interlanguage. Learners follow unique developmental trajectories, and errors evolve over time depending on exposure, proficiency, and learning strategies. This raises questions about whether separate corpora or models would be needed for different proficiency levels, which would significantly increase data requirements and necessitate careful learner selection.  \nFinally, the corpus used in this study is highly task-specific, focusing exclusively on giving and understanding route directions. To develop a more robust and generalizable interlanguage-adapted Whisper, training data would need to cover a broader variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across different communicative situations.  \nAnother avenue for future development is the creation of a dual-model system for language learning. One model could faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while a second model could provide the corrected, standard version of the utterance. Such a setup would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction."", ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage.""]","The author proposes several future directions for improving ASR systems for interlanguage transcription:

1. **Tailored Models**: There is a consideration of developing separate models for different native language groups, particularly for pronunciation errors. While some errors may be universal, others are consistent among specific L1 groups.

2. **Dynamic Learning Trajectories**: Acknowledging the unique developmental paths of learners, there is a need to create models or corpora that account for different proficiency levels, although this would require significant data and careful learner selection.

3. **Broader Training Data**: To enhance the robustness and generalizability of ASR systems, the training data should encompass a wider variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across various communicative situations.

4. **Dual-Model System**: The development of a dual-model system is suggested, where one model would accurately reproduce the learner's interlanguage, and the other would provide the corrected standard version. This would allow learners to compare their own productions with target forms, aiding self-monitoring and guided correction.

These approaches aim to better capture learner-specific patterns and improve the accuracy of ASR technologies in the context of second language acquisition.","The author proposes several directions for future work:

1. **Fine-tuning Whisper on interlanguage corpora**: Training the model to recognize and transcribe interlanguage forms rather than correcting them, using manually annotated data from native Polish speakers with linguistics or SLA backgrounds

2. **L1-specific vs. universal models**: For pronunciation errors, separate models could be developed for different L1 groups since speakers show consistent patterns; for case-related errors, a universal model would likely suffice since these appear language-independent

3. **Proficiency-level considerations**: Investigating whether separate corpora or models are needed for different proficiency levels, given the dynamic nature of interlanguage development

4. **Broader training data**: Expanding beyond task-specific data (route directions) to cover various linguistic contexts and speaking styles

5. **Dual-model system**: Creating one model to faithfully reproduce interlanguage and another to provide corrected versions, allowing learners to compare their productions with target forms

6. **Improved morphosyntactic tools**: Enhancing tools like spaCy for better case identification in learner speech",1.0,0.9999994671169983,0.8055555555287036,0.8571428571428571
What evaluation metrics were used to assess ASR performance and why?,"['Headers: General Context > State of the Art > Introduction\nHeaders: General Context > State of the Art > Introduction\n\nAutomatic Speech Recognition (ASR) has undergone remarkable progress in recent decades, evolving from early systems limited to a small set of commands to deep learning--based models capable of handling spontaneous, continuous speech in real-world conditions. While ASR technologies are now widely applied in domains such as virtual assistants, customer service, and accessibility tools, their use in second language (L2) learning and assessment still requires careful evaluation of their performance.', 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. For example, the system might produce incorrect text or suggest pronunciation corrections that do not match the learner\'s actual production, potentially providing misleading guidance. However, continuous improvements in machine learning and the increasing availability of diverse speech data have significantly reduced the accuracy gap between native and non-native recognition (e.g., Google ASR reduced this gap from 20% to 3--5%) [@gottardi; @https://doi.org/10.1002/tesq.3006].  \nRecent research highlights both the potential and the challenges of using automatic speech recognition (ASR) for pronunciation training. [@michot2024errorpreservingautomaticspeechrecognition] addressed the crucial issue of designing an ASR system that not only transcribes learner speech accurately but also preserves their errors, thus enabling effective corrective feedback. To this end, they collected approximately 85 hours of spontaneous English speech from Swiss learners in grades 4--6 (about 45,000 utterances) and manually transcribed it with explicit error annotations. They proposed a new evaluation metric, the Word-Based Error Preservation Rate (WEPR), to measure the extent to which ASR systems maintain learner errors instead of automatically ""correcting"" them. Their findings demonstrated that a fine-tuned ASR model, trained directly on children\'s data, achieved a substantially higher WEPR and lower Word Error Rate (WER) than off-the-shelf systems, underscoring the promise of error-preserving ASR for pedagogical purposes.', 'Headers: General Context > State of the Art > Conclusions\nHeaders: General Context > State of the Art > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate].""]","The evaluation metrics used to assess ASR performance include Word Error Rate (WER) and Character Error Rate (CER), as well as the Word-Based Error Preservation Rate (WEPR). 

WER is a commonly used metric but is noted to be a weaker indicator for interlanguage, as it does not correlate well with human intelligibility and overlooks semantics and grammar. This is especially problematic for learner speech, where pronunciation deviations can lead to significant penalties at the word level. 

In contrast, CER provides a more detailed assessment by focusing on character-level similarities, rewarding even partially correct transcriptions. This makes it more informative for capturing the nuances of learner speech.

The WEPR was specifically designed to evaluate how well an ASR system maintains learner errors rather than automatically correcting them, which is crucial for providing effective feedback in language learning contexts. This metric demonstrated that fine-tuned ASR models, trained on learner data, achieve higher accuracy and better representation of interlanguage features, making it particularly relevant for pedagogical purposes (Michot et al., 2024) (Hollands et al., 2022) (K et al., 2024).","Two standard ASR evaluation metrics were used:

1. **Word Error Rate (WER)**: Based on Levenshtein distance, calculated as (Substitutions + Deletions + Insertions) / Number of words in reference

2. **Character Error Rate (CER)**: Similarly calculated but at the character level

The author notes that **CER is a more informative metric for interlanguage evaluation** because:
- WER does not correlate well with human intelligibility since it ignores semantics, pragmatics, and grammar (Hollands et al., 2022)
- Pronunciation deviations often cause entire words to be misrecognized, heavily penalizing WER
- CER provides finer-grained perspective where partially correct transcriptions are rewarded for character-level similarity
- CER better reflects the degree to which ASR output preserves traces of the learner's original production
- CER is more appropriate for multilingual contexts (K et al., 2024)",1.0,0.9333074596126416,0.499999999975,1.0
What is the significance of the study's findings for second language acquisition research and pedagogy?,"['Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.', ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","The study's findings are significant for second language acquisition research and pedagogy as they enhance understanding of the processes involved in the early stages of learning a second language. They highlight the need to consider both cross-linguistic influences and the structural characteristics of the target language, which are crucial for developing effective tools for the automatic transcription of interlanguage. The integration of computational tools within corpus-based research offers the potential for more efficient and large-scale analyses of learner data, paving the way for improved methodologies in studying language acquisition.

Moreover, the research emphasizes the dynamic and systematic nature of interlanguage, shaped by various factors including the learners' native language. It illustrates that learners employ various strategies during acquisition, such as simplification and overgeneralization, confirming the complexities faced, particularly in the case of Polish. By combining manual transcriptions with automatic speech recognition, the study also demonstrates the utility of these methodologies for future applications in second language teaching and research, indicating a promising avenue for enhancing pedagogical approaches (Experimentations > General conclusion).","The study's findings have several important implications:

**For SLA research:**
- Confirms that interlanguage is a systematic and dynamic system shaped by multiple factors beyond L1 transfer
- Demonstrates that learners employ strategies such as simplification, overgeneralization, and omission in early acquisition
- Provides detailed error patterns that can inform understanding of developmental sequences in Polish L2 acquisition
- Highlights that case-related difficulties arise primarily from the target language complexity rather than native language interference

**For pedagogy:**
- Identifies specific pronunciation challenges (retroflex consonants, nasal vowels) and case confusions that instructors should address
- Supports the development of targeted pronunciation training similar to earlier CAPT systems like AzAR (Wagner, 2010)
- Suggests that error-preserving ASR could become a valuable tool for providing accurate feedback to learners

**For computational tools:**
- Demonstrates that learner corpora should be conceptualized as a low-resource language variety requiring specialized approaches (El Ayari & Li, 2024)
- Shows the potential and current limitations of integrating ASR with morphosyntactic analysis for language learning applications",0.8461538461538461,0.9344009849984591,0.999999999975,0.7692307692307693
Who is the author of this master's thesis?,"['Front Matter > Title Page\nFront Matter > Title Page\n\nThis is the title page and metadata of the thesis.\nauthor:\n- Agata SKRZYNIARZ\nbibliography: biblio.bib\ntitle: Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage\n---\n\n::: center\n     \n  -------------------------------------- ------------------------------------------\n:::\n\n::: center\n**Institut National des Langues et Civilisations Orientales**\\\n(National Institute for Oriental Languages and Civilizations)\n\nDépartement Textes, Informatique, Multilinguisme\\\n(Department of Texts, Computing, and Multilingualism)\n\n------------------------------------------------------------------------\n\n**Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage**\n\n------------------------------------------------------------------------\n\n[Master]\n\n[Traitement Automatique des Langues]\\\n[(Natural Language Processing)]\n\n*Specialization:*\n\n*Research and Development*\n\nby\n\n**Agata [Skrzyniarz]**\n\n*Thesis Supervisor:*\n\n*Sarra El Ayari*\n\nAcademic Year 2024/2025\n:::', ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']",The author of this master's thesis is Agata Skrzyniarz.,The author of this master's thesis is Agata Skrzyniarz.,1.0,0.9999994150459566,0.9999999999,1.0
At which institution was this thesis carried out?,"['Front Matter > Title Page\nFront Matter > Title Page\n\nThis is the title page and metadata of the thesis.\nauthor:\n- Agata SKRZYNIARZ\nbibliography: biblio.bib\ntitle: Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage\n---\n\n::: center\n     \n  -------------------------------------- ------------------------------------------\n:::\n\n::: center\n**Institut National des Langues et Civilisations Orientales**\\\n(National Institute for Oriental Languages and Civilizations)\n\nDépartement Textes, Informatique, Multilinguisme\\\n(Department of Texts, Computing, and Multilingualism)\n\n------------------------------------------------------------------------\n\n**Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage**\n\n------------------------------------------------------------------------\n\n[Master]\n\n[Traitement Automatique des Langues]\\\n[(Natural Language Processing)]\n\n*Specialization:*\n\n*Research and Development*\n\nby\n\n**Agata [Skrzyniarz]**\n\n*Thesis Supervisor:*\n\n*Sarra El Ayari*\n\nAcademic Year 2024/2025\n:::', ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work.""]",This thesis was carried out at the Institut National des Langues et Civilisations Orientales (Inalco).,This thesis was carried out at the Institut National des Langues et Civilisations Orientales (National Institute for Oriental Languages and Civilizations).,1.0,0.8310940074540794,0.99999999995,1.0
What laboratory was the internship conducted at?,"[""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", 'Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.', ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data.""]",The internship was conducted at the *Structures Formelles du Langage* laboratory.,The internship was conducted at the Structures Formelles du Langage laboratory.,1.0,0.8442799574492966,0.9999999999,1.0
What is interlanguage according to the thesis?,"[""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.', ""Headers: General Context > Context > Interlanguage in Second Language Acquisition > Definition of Interlanguage\nHeaders: General Context > Context > Interlanguage in Second Language Acquisition > Definition of Interlanguage\n\n*Interlanguage* is a concept introduced by [@selinker-1972] to describe the linguistic system that emerges when an adult learns a second language. It refers to a transitional linguistic system developed by the learner to communicate in the target language. This system is shaped by several factors, including the target language and the learner's native language [@tarone-2006]. In other words, interlanguage represents a transitional stage situated between the target language -- through the partial application of its lexical items and grammatical rules -- and the native language, from which the learner may potentially transfer previously acquired structures and patterns. As a result, interlanguage is typically marked by a high frequency of variations from the norm [@tarone-2006], reflecting its evolving and dynamic nature.  \n![Diagram of Interlanguage (Source: [@selinker-1972])](photos/interlanguage.png)"", ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage.""]","According to the thesis, *interlanguage* is a transitional linguistic system that emerges when an adult learns a second language. It is developed by the learner to communicate in the target language and is shaped by several factors, including the target language and the learner's native language (Selinker, 1972) (Tarone, 2006). Interlanguage represents a stage situated between the target and native languages, characterized by the partial application of the target language's lexical items and grammatical rules, as well as potential transfer from the native language. This results in a high frequency of variations from the norm, reflecting its evolving and dynamic nature (Tarone, 2006).","Interlanguage refers to a transitional linguistic system developed by the learner to communicate in the target language, shaped by factors including the target language and the learner's native language (Tarone, 2006).",1.0,0.9999999999999998,0.9999999999666667,1.0
To which language family does Polish belong?,"['Headers: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nPolish belongs to the family of West Slavic languages [@bartnicka-1990]. It uses the Latin alphabet, enriched with special diacritical marks and with double letters pronounced as one sound [@foland-2007].\\\nThe Polish alphabet has 32 letters:  \nBelow are selected letters that may present particular pronunciation challenges for non-native speakers:  \n:::\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ -----------------------------------------------------------------\nĄ                ą          /ɔŋ/, /ɔ̃w̃/  łąka /wɔŋka/ (\\""meadow\\""), szkołą /ʂkɔwɔ̃w̃/ (\\""school\\"", Instr.)\nC                c             /t͡s/     taca /tat͡sa/ (\\""plate\\"")\nĆ                ć             /t͡ɕ/     kochać /kɔxat͡ɕ/ (\\""to love\\"")\nĘ                ę          /ɛŋ/, /ɛ̃w̃/  ręka /rɛŋka/ (\\""arm\\""), szkołę /ʂkɔwɛ̃w̃/ (\\""school\\"", Acc.)\nJ                j             /j/      pająk /pajɔŋk/ (\\""spider\\"")\nK                k             /k/      sklep /sklɛp/ (\\""store\\"")\nŁ                ł             /w/      koło /kɔwɔ/ (\\""circle\\"")\nŃ                ń             /ɲ/      koń /kɔɲ/ (\\""horse\\"")\nÓ                ó             /u/      król /krul/ (\\""king\\"")\nŚ                ś             /ɕ/      śruba /ɕruba/ (\\""bolt\\"")\nU                u             /u/      drut /drut/ (\\""wire\\"")\nW                w           /v/, /f/   woda /vɔda/ (\\""water\\""), konewka /kɔnɛfka/ (\\""watering can\\"")\nY                y             /ɨ/      ryba /rɨba/ (\\""fish\\"")\nŹ                ź           /ʑ/, /ɕ/   źrebię /ʑrɛbjɛ̃w̃/ (\\""colt\\""), gryźć /ɡrɨɕt͡ɕ/ (\\""to bite\\"")\nŻ                ż           /ʐ/, /ʂ/   żaba /ʐaba/ (\\""frog\\""), wąż /vɔ̃w̃ʂ/ (\\""snake\\"")  \n: Selected Polish letters and their IPA transcriptions\n:::  \nIn addition, Polish includes several digraphs -- graphic combinations of two letters that represent a single sound [@foland-2007]:  \n:::\n**Upper case**   **Lower case**    **IPA**    **Example**', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", 'Headers: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\n\nAt this point, the corpus was not yet complete; however, the preliminary results showed that the majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners\' Polish interlanguage. Although some words were correctly classified (in bold), they remained a minority. Unfortunately, as many words from the \\*STU segments were simplified attempts at Polish words, the program sometimes incorrectly classified them as belonging to other languages.  \nTo allow for comparison with the native Polish corpus, the same language detection library was applied to the transcriptions produced by the four native speakers. Out of a total of 96 words, only one word -- the Polish word *teraz* (\\""now\\"") -- was mistakenly identified as Italian, representing just 1% of the data. This result confirms the overall reliability of the language detection tool and suggests that the challenges observed in the learner corpus are primarily due to the deformed nature of interlanguage forms rather than limitations of the library itself.  \nThis demonstrates that the automatic method was unreliable. As a result, the removal of non-Polish words had to be done manually.']","Polish belongs to the family of West Slavic languages (Bartnicka and Satkiewicz, 1990).","Polish belongs to the family of West Slavic languages (Bartnicka, 1990).",1.0,0.975149930991272,0.9999999999,1.0
How many letters does the Polish alphabet have?,"['Headers: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nPolish belongs to the family of West Slavic languages [@bartnicka-1990]. It uses the Latin alphabet, enriched with special diacritical marks and with double letters pronounced as one sound [@foland-2007].\\\nThe Polish alphabet has 32 letters:  \nBelow are selected letters that may present particular pronunciation challenges for non-native speakers:  \n:::\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ -----------------------------------------------------------------\nĄ                ą          /ɔŋ/, /ɔ̃w̃/  łąka /wɔŋka/ (\\""meadow\\""), szkołą /ʂkɔwɔ̃w̃/ (\\""school\\"", Instr.)\nC                c             /t͡s/     taca /tat͡sa/ (\\""plate\\"")\nĆ                ć             /t͡ɕ/     kochać /kɔxat͡ɕ/ (\\""to love\\"")\nĘ                ę          /ɛŋ/, /ɛ̃w̃/  ręka /rɛŋka/ (\\""arm\\""), szkołę /ʂkɔwɛ̃w̃/ (\\""school\\"", Acc.)\nJ                j             /j/      pająk /pajɔŋk/ (\\""spider\\"")\nK                k             /k/      sklep /sklɛp/ (\\""store\\"")\nŁ                ł             /w/      koło /kɔwɔ/ (\\""circle\\"")\nŃ                ń             /ɲ/      koń /kɔɲ/ (\\""horse\\"")\nÓ                ó             /u/      król /krul/ (\\""king\\"")\nŚ                ś             /ɕ/      śruba /ɕruba/ (\\""bolt\\"")\nU                u             /u/      drut /drut/ (\\""wire\\"")\nW                w           /v/, /f/   woda /vɔda/ (\\""water\\""), konewka /kɔnɛfka/ (\\""watering can\\"")\nY                y             /ɨ/      ryba /rɨba/ (\\""fish\\"")\nŹ                ź           /ʑ/, /ɕ/   źrebię /ʑrɛbjɛ̃w̃/ (\\""colt\\""), gryźć /ɡrɨɕt͡ɕ/ (\\""to bite\\"")\nŻ                ż           /ʐ/, /ʂ/   żaba /ʐaba/ (\\""frog\\""), wąż /vɔ̃w̃ʂ/ (\\""snake\\"")  \n: Selected Polish letters and their IPA transcriptions\n:::  \nIn addition, Polish includes several digraphs -- graphic combinations of two letters that represent a single sound [@foland-2007]:  \n:::\n**Upper case**   **Lower case**    **IPA**    **Example**', 'Headers: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Phonetics and orthography\n\nIn addition, Polish includes several digraphs -- graphic combinations of two letters that represent a single sound [@foland-2007]:  \n:::\n**Upper case**   **Lower case**    **IPA**    **Example**\n---------------- ---------------- ------------ ------------------------------------------------------------------\nCh               ch            /x/      chata /xata/ (\\""hut\\"")\nCz               cz            /t͡ʂ/     czysty /t͡ʂɨstɨ/ (\\""clean\\"")\nDz               dz         /d͡z/, /t͡s/  dzwon /d͡zvɔn/ (\\""bell\\""), powiedz /pɔvjɛt͡s/ (\\""say\\"", imp., 2sg)\nDź               dź         /d͡ʑ/, /t͡ɕ/  dźwięk /d͡ʑvjɛŋk/ (\\""sound\\""), powódź /pɔvud͡ʑ/ (\\""flood\\"")\nDż               dż            /d͡ʐ/     dżem /d͡ʐɛm/ (\\""jam\\"")\nRz               rz          /ʐ/, /ʂ/   rzeka /ʐɛka/ (\\""river\\""), malarz /malaʂ/ (\\""painter\\"")\nSz               sz            /ʂ/      kosz /kɔʂ/ (\\""basket\\"")  \n: Polish digraphs and their IPA transcriptions\n:::  \nOne of the more challenging aspects of learning Polish is its pronunciation. The language contains phonemes that are not present in other widely spoken Western languages, even if some may appear similar. Moreover, the frequent occurrence of complex phoneme clusters (difficult sounds placed directly next to each other) further complicates pronunciation for learners attempting to articulate Polish words accurately.', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.']",The Polish alphabet has 32 letters.,The Polish alphabet has 32 letters.,1.0,0.9693973816147903,0.9999999999,1.0
What are the seven grammatical cases in Polish?,"['Headers: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nOne of the greatest grammatical challenges in the Polish language is the inflection of words for case. Case is an inflectional category with a textual function, used to signal the grammatical relationships between elements of a sentence. In Polish, we distinguish seven forms of cases:\\  \n-   Nominative -- Nominativus (Nom.),  \n-   Genitive -- Generativus (Gen.),  \n-   Dative -- Dativus (Dat.),  \n-   Accusative -- Accusativus (Acc.),  \n-   Instrumental -- Instrumentalis (Instr.),  \n-   Locative -- Locativus (Loc.),  \n-   Vocative -- Vocativus (Voc.).  \nParts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.\\\nBelow is an example of the declension of a Polish word -- *sklep* (store) -- depending on its syntactic role within a sentence:  \n:::\n**Case**     **Singular**    **Plural**   **Question (function)**\n-------------- -------------- -------------- -----------------------------------------------------\nNominative       sklep        sklep**y**   who? what? -- subject\nGenitive      sklep**u**    sklep**ów**   of whom? of what? -- possession, negation\nDative      sklep**owi**   sklep**om**   to whom? to what? -- indirect object\nAccusative       sklep        sklep**y**   whom? what? -- direct object\nInstrumental   sklep**em**    sklep**ami**  with whom? with what? -- means or accompaniment\nLocative     sklep**ie**    sklep**ach**  where? about whom? about what? -- location or topic\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::', 'Headers: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::  \nHowever, the case system does not end with just seven suffixes. The inflectional forms of nouns also depend on grammatical gender. Every noun has a gender: masculine, feminine, or neuter. The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) [@bartnicka-1990].', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\n**Case**    **Expected cases**   **Produced cases**   **Difference (%)**\n---------- -------------------- -------------------- --------------------\nAcc                 16                   13                 -18.75\nGen                106                   5                  -95.28\nIns                 59                   7                  -88.14\nLoc                 11                   19                 72.73\nNom                 12                  125                 941.67  \n: Comparison of expected and produced grammatical cases with relative differences (%)  \nThe following analysis of learner data shows that the most frequently required cases, presented in Table -- the genitive and instrumental -- also generate the highest number of errors among learners. The genitive case is typically used to express possession and appears frequently in phrases referring to street names, such as *ulica Juliusza Słowackiego* (\\""Juliusz Słowacki Street\\""). It also follows prepositions like *obok* (\\""next to\\"" or, in this context, \\""past\\""), which are commonly used in giving directions. The instrumental case, on the other hand, is used when describing movement along a path, especially after verbs of motion such as *iść* (\\""to go\\""), as in *iść ulicą Niską* (\\""go along Niska Street\\""). It is also required after the preposition *za* (\\""behind\\""), which frequently appears in this route direction task.  \nMoreover, one of the most common incorrect cases used by learners is the nominative. This is not unexpected, as the nominative is the default case in Polish. It is the form learners are most familiar with, and in the absence of explicit knowledge about declension rules, they often overgeneralize and use the nominative in contexts that require a different case. This tendency reflects a typical stage in interlanguage development, where learners rely on the most salient or frequent forms of the target language.', ""Headers: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors.""]","The seven grammatical cases in Polish are:

1. Nominative (Nom.)
2. Genitive (Gen.)
3. Dative (Dat.)
4. Accusative (Acc.)
5. Instrumental (Instr.)
6. Locative (Loc.)
7. Vocative (Voc.)","The seven grammatical cases in Polish are:
1. Nominative (Nominativus)
2. Genitive (Generativus)
3. Dative (Dativus)
4. Accusative (Accusativus)
5. Instrumental (Instrumentalis)
6. Locative (Locativus)
7. Vocative (Vocativus)",1.0,0.9999999999999998,0.9999999999,1.0
Which parts of speech are conjugated by cases in Polish?,"['Headers: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nOne of the greatest grammatical challenges in the Polish language is the inflection of words for case. Case is an inflectional category with a textual function, used to signal the grammatical relationships between elements of a sentence. In Polish, we distinguish seven forms of cases:\\  \n-   Nominative -- Nominativus (Nom.),  \n-   Genitive -- Generativus (Gen.),  \n-   Dative -- Dativus (Dat.),  \n-   Accusative -- Accusativus (Acc.),  \n-   Instrumental -- Instrumentalis (Instr.),  \n-   Locative -- Locativus (Loc.),  \n-   Vocative -- Vocativus (Voc.).  \nParts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.\\\nBelow is an example of the declension of a Polish word -- *sklep* (store) -- depending on its syntactic role within a sentence:  \n:::\n**Case**     **Singular**    **Plural**   **Question (function)**\n-------------- -------------- -------------- -----------------------------------------------------\nNominative       sklep        sklep**y**   who? what? -- subject\nGenitive      sklep**u**    sklep**ów**   of whom? of what? -- possession, negation\nDative      sklep**owi**   sklep**om**   to whom? to what? -- indirect object\nAccusative       sklep        sklep**y**   whom? what? -- direct object\nInstrumental   sklep**em**    sklep**ami**  with whom? with what? -- means or accompaniment\nLocative     sklep**ie**    sklep**ach**  where? about whom? about what? -- location or topic\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::', 'Headers: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::  \nHowever, the case system does not end with just seven suffixes. The inflectional forms of nouns also depend on grammatical gender. Every noun has a gender: masculine, feminine, or neuter. The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) [@bartnicka-1990].', ""Headers: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.']","In Polish, the parts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.","Parts of speech that are conjugated by cases in Polish are nouns, adjectives, numerals, and pronouns.",1.0,0.9792548647603289,0.7499999999625,1.0
What does the VILLA project stand for?,"['Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","The VILLA project stands for ""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation"" (Dimroth et al., 2013).","VILLA stands for ""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation.""",1.0,0.9999994506148951,0.9999999999,1.0
Who conducted the VILLA project?,"['Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy.""]","The VILLA project was conducted by (Dimroth et al., 2013).",The VILLA project was conducted by Dimroth et al. (2013).,1.0,1.0,0.9999999999,0.0
What were the five linguistic backgrounds of participants in the VILLA project?,"['Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","The five linguistic backgrounds of participants in the VILLA project were Dutch, English, French, German, and Italian (Dimroth et al., 2013).","The five linguistic backgrounds of participants were Dutch, English, French, German, and Italian.",0.0,0.900565636535649,0.9999999999,1.0
How many hours of Polish instruction did the VILLA project participants receive?,"['Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\']",The participants in the VILLA project received 14 hours of instruction in Polish as a foreign language.,The VILLA project participants received 14 hours of instruction in Polish as a foreign language.,1.0,0.9402295268078071,0.7499999999625,1.0
What was the Route Direction task in the VILLA project?,"[""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].']","The Route Direction task in the VILLA project required students to give directions from point A to point B using a map. All participants used the same map, which included named streets and visual representations of places such as a hospital, school, restaurant, and store. During the test, students had to speak in Polish independently, without any help. The oral productions from these tests were recorded and later transcribed, forming the corpus used in the study.","The Route Direction task required students to give directions from point A to point B using a map that included named streets and visual representations of places such as a hospital, school, restaurant, and store.",1.0,0.8374340484906722,0.8333333332916666,1.0
What were the two types of input provided to learner subgroups in the VILLA project?,"['Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', ""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", ""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage.""]","The two types of input provided to learner subgroups in the VILLA project were meaning-based input and form-based input. Learners exposed to meaning-based input received structured input focused on communication without meta-linguistic explanations or explicit correction, while those who received form-based input were explicitly directed to notice morphological forms and rules (Dimroth et al., 2013).",The two types of input were meaning-based input (focused on communication without meta-linguistic explanations) and form-based input (where learners were explicitly directed to notice morphological forms and rules).,1.0,1.0,0.99999999995,1.0
What factors influence the choice of noun endings in Polish?,"['Headers: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::  \nHowever, the case system does not end with just seven suffixes. The inflectional forms of nouns also depend on grammatical gender. Every noun has a gender: masculine, feminine, or neuter. The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) [@bartnicka-1990].', 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.']","The choice of noun endings in Polish is influenced by several factors:

1. **Grammatical Gender**: Every noun in Polish has a gender—masculine, feminine, or neuter—which determines the appropriate endings.

2. **Phonetic Factors**: The endings are affected by the phonetic properties of the noun stem, such as whether it ends in a hard or soft consonant or a vowel.

3. **Semantic Factors**: Considerations such as animacy (the distinction between animate and inanimate nouns) and personal versus non-personal reference within the masculine gender also play a role in the selection of endings (Bartnicka and Satkiewicz, 1990).","The choice of endings is influenced by phonetic factors (such as whether the noun stem ends in a hard or soft consonant, or a vowel) as well as semantic factors (such as the category of animacy, inanimacy, and personal vs. non-personal reference within the masculine gender) (Bartnicka, 1990).",0.8888888888888888,0.9999994813439531,0.8333333332916666,1.0
What is Whisper?,"['Headers: General Context > State of the Art > The Whisper Model\nHeaders: General Context > State of the Art > The Whisper Model\n\nWhisper [@radford2022robustspeechrecognitionlargescale] represents a new generation of ASR: a transformer encoder--decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. Models are released in multiple sizes, enabling a balance between speed and accuracy.  \nFor L2 speech, Whisper performs better than many commercial systems, but it often \\""over-corrects\\"" learner speech -- for example, restoring omitted particles or ignoring disfluencies. This behavior, observed in L2 French [@elayari:hal-04769687], risks erasing the very interlanguage phenomena. In the context of Polish, such normalization could obscure substitutions of nasal vowels or partial palatalization.  \nNevertheless, Whisper\'s open-source nature, high baseline accuracy, and multilingual scope make it an attractive candidate for adaptation. With targeted fine-tuning on learner corpora, it could become a powerful tool for L2 research.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", 'Headers: Abstract\nHeaders: Abstract\n\nThis thesis investigates the performance of automatic tools in processing Polish interlanguage produced by adult learners from the VILLA project, who completed a route-giving task after 14 hours of instruction. The study has two main objectives: first, to analyze learner deviations in case inflection and pronunciation, revealing patterns such as overuse of the nominative, confusion between genitive, instrumental, and locative forms, and difficulties with retroflex consonants and nasal vowels; second, to evaluate Whisper, an end-to-end ASR system, on its ability to transcribe Polish interlanguage. A detailed analysis shows that Whisper often overcorrects pronunciation errors but reproduces declension deviations more faithfully. These results underscore both the potential and limitations of Whisper and suggest directions for improvement, such as fine-tuning ASR models on learner corpora and integrating morphosyntactic analysis.\\\n**Keywords:** interlanguage, automatic speech recognition (ASR), Whisper, Polish, transcription, second language acquisition (SLA), learner error analysis']","Whisper is a transformer encoder-decoder model specifically designed for automatic speech recognition (ASR). It is trained on 680,000 hours of multilingual data, predicting text tokens directly from log-Mel spectrograms. This approach offers enhanced robustness across various domains, languages, and accents, distinguishing it from traditional HMM-based systems. Whisper is available in multiple sizes to balance speed and accuracy. While it performs well with L2 speech, it may overcorrect learner speech, which can obscure interlanguage phenomena. Its open-source nature and high baseline accuracy make it appealing for adaptation and fine-tuning on learner corpora for L2 research (Radford et al., 2022) ({El Ayari} and Li, 2024).","Whisper is a transformer encoder-decoder automatic speech recognition system trained on 680,000 hours of multilingual data, developed by OpenAI (Radford et al., 2022).",1.0,0.7937560615899512,0.7499999999625,1.0
What is a key challenge when using ASR systems for second language production?,"['Headers: General Context > State of the Art > Conclusions\nHeaders: General Context > State of the Art > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', 'Headers: General Context > State of the Art > Introduction\nHeaders: General Context > State of the Art > Introduction\n\nAutomatic Speech Recognition (ASR) has undergone remarkable progress in recent decades, evolving from early systems limited to a small set of commands to deep learning--based models capable of handling spontaneous, continuous speech in real-world conditions. While ASR technologies are now widely applied in domains such as virtual assistants, customer service, and accessibility tools, their use in second language (L2) learning and assessment still requires careful evaluation of their performance.', 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. For example, the system might produce incorrect text or suggest pronunciation corrections that do not match the learner\'s actual production, potentially providing misleading guidance. However, continuous improvements in machine learning and the increasing availability of diverse speech data have significantly reduced the accuracy gap between native and non-native recognition (e.g., Google ASR reduced this gap from 20% to 3--5%) [@gottardi; @https://doi.org/10.1002/tesq.3006].  \nRecent research highlights both the potential and the challenges of using automatic speech recognition (ASR) for pronunciation training. [@michot2024errorpreservingautomaticspeechrecognition] addressed the crucial issue of designing an ASR system that not only transcribes learner speech accurately but also preserves their errors, thus enabling effective corrective feedback. To this end, they collected approximately 85 hours of spontaneous English speech from Swiss learners in grades 4--6 (about 45,000 utterances) and manually transcribed it with explicit error annotations. They proposed a new evaluation metric, the Word-Based Error Preservation Rate (WEPR), to measure the extent to which ASR systems maintain learner errors instead of automatically ""correcting"" them. Their findings demonstrated that a fine-tuned ASR model, trained directly on children\'s data, achieved a substantially higher WEPR and lower Word Error Rate (WER) than off-the-shelf systems, underscoring the promise of error-preserving ASR for pedagogical purposes.', ""Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nHowever, other work has pointed to the persistent limitations of existing ASR tools in real learning contexts. For instance, [@john2022] examined the case of *th*-substitution (e.g., *thank* $\\rightarrow$ *tank*) among Quebec francophones learning English. In their study, eight participants (four female, four male) recorded 120 sentences with /$\\theta$/-, /h/-, and vowel-initial words in both correct and erroneous forms, resulting in 480 recordings processed through Google Translate's ASR. While correct pronunciations were generally well recognized (75% for real-word and 83% for nonword contexts), erroneous productions were often misrepresented: only 25% of *thank* $\\rightarrow$ *tank* substitutions were correctly identified, and in nearly half of the cases, the system misleadingly transcribed *tank* as *thank*. These findings illustrate the risk of false positive feedback, where ASR masks learners' mispronunciations, thus limiting its reliability. Together, the two studies highlight that while error-preserving ASR holds considerable promise for pronunciation pedagogy, mainstream tools such as Google Translate still struggle with systematic L2 pronunciation errors, demonstrating the need for tailored systems trained on learner-specific data.""]","A key challenge when using ASR systems for second language production is their poor performance with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. These systems, often trained on native speech, may misrepresent learner productions, either masking errors or providing misleading corrections, which limits their effectiveness in giving reliable feedback. Additionally, while error-preserving approaches demonstrate promise, mainstream ASR tools continue to struggle with systematic L2 pronunciation errors, highlighting the need for tailored systems trained on learner-specific data (Gottardi et al., 2022) (Michot et al., 2024) (John et al., 2022).","A key challenge is that learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize.",1.0,0.9568434865488056,0.999999999975,1.0
What is WER and how is it calculated?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate]."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\n\n:::\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance."", 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.']","Word Error Rate (WER) is a metric used to evaluate the performance of Automatic Speech Recognition (ASR) systems. It quantifies the accuracy of transcriptions by calculating the number of errors in the recognized output compared to a reference transcription. WER is defined based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription.

Formally, WER is calculated using the formula:

\[
\text{WER} = \frac{(S + D + I)}{N}
\]

where \(N\) is the total number of words in the reference transcription. Thus, WER provides a measure of the percentage of words that have been incorrectly recognized. The higher the WER, the lower the accuracy of the ASR system. In the context examined, the average WER for Whisper transcribing Polish interlanguage is reported to be 75.4% ({El Ayari} and Li, 2024).","WER stands for Word Error Rate and is calculated based on the Levenshtein distance, counting the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription.",1.0,0.7232079069112636,0.5833333333041666,1.0
What is CER?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate]."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\n\n:::\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance."", 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.']","CER stands for Character Error Rate. It is a metric used to evaluate the performance of Automatic Speech Recognition (ASR) systems by assessing the accuracy of transcriptions at the character level. CER measures the number of substitutions, deletions, and insertions required to transform the system output into the reference transcription, offering a more fine-grained perspective compared to Word Error Rate (WER). This makes CER particularly useful in contexts where partial correctness is important, such as in assessing learner speech, as it can capture phonetic approximations and provide insight into the degree of similarity between the ASR output and the original speech (K et al., 2024).","CER stands for Character Error Rate, which measures ASR performance at the character level rather than the word level.",1.0,0.7291013137932998,0.999999999975,1.0
Why is CER considered a better metric than WER for evaluating interlanguage transcription?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate]."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\n\n:::\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.']","CER is considered a better metric than WER for evaluating interlanguage transcription because it provides a more detailed assessment of transcription accuracy at the character level. Unlike WER, which can penalize the entire word for misrecognitions—often exacerbated by pronunciation deviations—CER rewards even partially correct transcriptions based on character similarities. This makes CER more reflective of the learner's original production and the actual phonetic approximations typical in interlanguage speech. Additionally, the frequent inaccuracies in learner speech can lead to high WER scores, while CER allows for a nuanced understanding of how well the ASR output captures the intended message despite deviations, thereby offering a more informative measure in the context of multilingualism (Hollands et al., 2022)(K et al., 2024).","CER provides a more fine-grained perspective because even partially correct transcriptions are rewarded for character-level similarity, and it better reflects the degree to which ASR output preserves traces of the learner's original production (K et al., 2024).",1.0,1.0,0.999999999975,0.6666666666666666
What tool was used for morphosyntactic analysis in this study?,"[""Headers: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Introduction\n\nThe first analysis conducted in this study focused on the non-standard forms made by learners. The primary objective was to identify the most common types of deviations produced by learners of Polish after a 14-hour course. In addition, the second goal was to investigate the potential influence of the learners' native languages on the nature of these productions. To facilitate a clearer visualization of deviations, a dedicated tool-platform will also be developed, enabling an easier and more systematic analysis of the data."", ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", ""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage.""]",The tool used for morphosyntactic analysis in this study is *spaCy*.,"The spaCy library was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features including case information.",1.0,0.9999999999999998,0.9999999999,1.0
What annotation tool was used for transcribing voice recordings?,"['Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThere are a few reasons why the recordings were transcribed in accordance with standard Polish orthography instead of the phonetic alphabet. Firstly, manual transcription is a very tedious and time-consuming process that requires a lot of attention. Consequently, the annotation rules should be as simple and intuitive as possible [@Grochola-Szczepanek_Woźniak_2018]. In addition, full phonemic transcription using the IPA would have been significantly more time-consuming. Given the limited time, this would have led to a substantial reduction in the size of the corpus. Moreover, such transcription facilitates processing by automated tools. Only general orthographic transcription allows the use of tools such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection, which are designed for standard orthography. Finally, the corpus and the analysis are intended for further work by other researchers in the laboratory, not only phoneticians and phonologists.  \nNevertheless, in the subsequent analysis of phonetic errors, the orthographic representations were automatically converted into IPA symbols to enable a more precise visualization of pronunciation deviations.  \nThe same task was also carried out by four native Polish speakers, whose utterances were recorded and transcribed following the same procedure as for the learner corpus. While this native speaker corpus is significantly smaller in size, it serves as a reference point for the subsequent evaluation of the performance of automatic linguistic tools.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\n\nSince systems like Whisper are trained primarily on standard language transcribing interlanguage presents a significant challenge. This study explores the use of automatic transcription for interlanguage in the context of second language acquisition. In this setting, the goal of the ASR tool is not simply to provide a correct transcription, but rather to reproduce the learner's utterance as faithfully as possible, including any linguistic errors. Overcorrection, therefore, is undesirable, as it obscures the learner's original production. Based on these considerations, it can be hypothesized that overcorrection is likely to be the most frequent type of transcription error encountered in this corpus. In this section, we assess Whisper's performance on such dataset and examine the extent to which its output faithfully reflects the learners' original speech."", ""Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n:::\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage.""]",The annotation tool used for transcribing voice recordings was ELAN.,"ELAN was used for annotating audio and video recordings, and files were saved in .eaf format.",1.0,0.9828240005137002,0.3333333333,1.0
What are the two parallel tiers included in each transcription file?,"[""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", ""Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n:::\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [] for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.""]","Each transcription file includes two parallel tiers:  
- **\*STU**: manual transcriptions that accurately reflect what the learner said;  
- **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.","The two parallel tiers are:
- *STU: manual transcriptions that accurately reflect what the learner said
- %pol: corrected versions in standard Polish, representing the intended meaning of the learner's utterance",1.0,0.7161324511890305,0.49999999995,1.0
How many recordings were included in the learner corpus from each country?,"[""Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n:::\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", ""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.']","The learner corpus included the following number of recordings from each country:

- France: 17 recordings
- Italy: 17 recordings
- Netherlands: 18 recordings
- England: 17 recordings
- Germany: 20 recordings","| Country | Number of wav/eaf/txt files | Total duration of recordings |
|---------|----------------------------|-----------------------------|
| France | 17 | 23 minutes 32 seconds |
| Italy | 17 | 26 minutes 39 seconds |
| Netherlands | 18 | 28 minutes 34 seconds |
| England | 17 | 29 minutes 34 seconds |
| Germany | 20 | 30 minutes 42 seconds |",1.0,1.0,0.9999999999,0.8333333333333334
What was the total duration of all learner recordings in the corpus?,"[""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", ""Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n:::\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [] for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.""]",The total duration of all learner recordings in the corpus is 2 hours and 19 minutes.,The total duration of all learner recordings was 2 hours and 19 minutes (89 files total).,1.0,0.9798276593208934,0.99999999995,1.0
Why were pronunciation errors indicated through Polish spelling rather than IPA?,"['Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThere are a few reasons why the recordings were transcribed in accordance with standard Polish orthography instead of the phonetic alphabet. Firstly, manual transcription is a very tedious and time-consuming process that requires a lot of attention. Consequently, the annotation rules should be as simple and intuitive as possible [@Grochola-Szczepanek_Woźniak_2018]. In addition, full phonemic transcription using the IPA would have been significantly more time-consuming. Given the limited time, this would have led to a substantial reduction in the size of the corpus. Moreover, such transcription facilitates processing by automated tools. Only general orthographic transcription allows the use of tools such as lemmatization, part-of-speech tagging, grammatical case identification, and language detection, which are designed for standard orthography. Finally, the corpus and the analysis are intended for further work by other researchers in the laboratory, not only phoneticians and phonologists.  \nNevertheless, in the subsequent analysis of phonetic errors, the orthographic representations were automatically converted into IPA symbols to enable a more precise visualization of pronunciation deviations.  \nThe same task was also carried out by four native Polish speakers, whose utterances were recorded and transcribed following the same procedure as for the learner corpus. While this native speaker corpus is significantly smaller in size, it serves as a reference point for the subsequent evaluation of the performance of automatic linguistic tools.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nThe five most frequent pronunciation errors observed in the learner corpus reveal recurring patterns and potential phonological challenges, most likely influenced by the learners' native languages. The most common error concerned the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups, with the highest number found among German speakers (10); however, all groups exhibited this error at some point. The second most common error involved the replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, where learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/. This suggests difficulty in distinguishing between retroflex and alveolar fricatives. Once again, German speakers accounted for the highest number of errors (10), while French learners made the fewest (2). A similar phenomenon appeared in the third error, where the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/ was omitted, resulting in the simplified form *iś* /iɕ/, produced by 25 learners. This pattern may indicate difficulty pronouncing complex affricates in word-final position. Interestingly, the English group committed this error most frequently (11), whereas it was least common among German learners (1). The fourth error again reflected confusion between retroflex and alveolar consonants: *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This error was most common among Dutch speakers (9) and was not observed at all in the English group. An interesting case worth mentioning, although it ranks only thirteenth most frequent error, is the tendency of Italian learners to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as *niskon*. This substitution illustrates the difficulty of"", 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nTaken together, these errors point to systematic challenges with Polish retroflex consonants and nasal vowels, as learners tend to replace them with more familiar alveolar sounds or denasalized vowels from their native phonological inventories. The full dataset provides a rich basis for further phonological and cross-linguistic analysis.']","Pronunciation errors were indicated through Polish spelling rather than IPA for several reasons. Firstly, manual transcription in IPA would have been too time-consuming and could have significantly reduced the corpus size due to limited time constraints. Using standard Polish orthography allows for simpler and more intuitive annotation rules, which is crucial for the transcription process. Additionally, general orthographic transcription facilitates the use of automated tools for tasks like lemmatization and part-of-speech tagging. Finally, since the corpus and analysis are intended for further research beyond just phonetics and phonology, standard spelling makes the data more accessible to a broader range of researchers.","The reasons were:
1. Manual transcription is time-consuming and annotation rules should be simple and intuitive
2. Full phonemic transcription would have substantially reduced corpus size
3. Standard orthographic transcription facilitates processing by automated tools like lemmatization and POS tagging
4. The corpus is intended for further work by researchers who may not be phoneticians",0.75,0.9956681807701254,0.9999999999,1.0
What percentage of words detected as belonging to another language were actually erroneous forms from learners' Polish interlanguage?,"['Headers: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\n\nAt this point, the corpus was not yet complete; however, the preliminary results showed that the majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners\' Polish interlanguage. Although some words were correctly classified (in bold), they remained a minority. Unfortunately, as many words from the \\*STU segments were simplified attempts at Polish words, the program sometimes incorrectly classified them as belonging to other languages.  \nTo allow for comparison with the native Polish corpus, the same language detection library was applied to the transcriptions produced by the four native speakers. Out of a total of 96 words, only one word -- the Polish word *teraz* (\\""now\\"") -- was mistakenly identified as Italian, representing just 1% of the data. This result confirms the overall reliability of the language detection tool and suggests that the challenges observed in the learner corpus are primarily due to the deformed nature of interlanguage forms rather than limitations of the library itself.  \nThis demonstrates that the automatic method was unreliable. As a result, the removal of non-Polish words had to be done manually.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy.""]",The percentage of words detected as belonging to another language that were actually erroneous forms from learners' Polish interlanguage was 66% (CONTEXT).,The majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners' Polish interlanguage.,1.0,0.9999993947533733,0.9999999999,1.0
What Python libraries were used in the implementation of this thesis?,"[""Headers: Experimentations > Corpus > Annotation and Preprocessing > Tools and Implementation\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Tools and Implementation\n\nAll scripts developed in this thesis were implemented in Python within a Jupyter Notebook environment. For the automatic speech recognition of learners' utterances, we used the small model of Whisper by OpenAI, in automatic language mode, provided by Huma-Num servers, since Polish was not available.  \nThe implementation further relied on a range of Python libraries, including *spaCy* for morphosyntactic analysis, *pandas* for data manipulation, *fuzzywuzzy* (Levenshtein distance) for fuzzy string matching, *Epitran* for grapheme-to-phoneme transcription, *langdetect* for language detecting, *matplotlib* and *seaborn* for visualization, *JiWER* for calculating WER and CER, as well as *json*, *xml.etree*, and *csv* for structured data processing and file management.  \nThis configuration ensured reproducibility and scalability, while enabling the efficient integration of data processing, linguistic analysis, and evaluation procedures."", ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", 'Front Matter > Title Page\nFront Matter > Title Page\n\nThis is the title page and metadata of the thesis.\nauthor:\n- Agata SKRZYNIARZ\nbibliography: biblio.bib\ntitle: Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage\n---\n\n::: center\n     \n  -------------------------------------- ------------------------------------------\n:::\n\n::: center\n**Institut National des Langues et Civilisations Orientales**\\\n(National Institute for Oriental Languages and Civilizations)\n\nDépartement Textes, Informatique, Multilinguisme\\\n(Department of Texts, Computing, and Multilingualism)\n\n------------------------------------------------------------------------\n\n**Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage**\n\n------------------------------------------------------------------------\n\n[Master]\n\n[Traitement Automatique des Langues]\\\n[(Natural Language Processing)]\n\n*Specialization:*\n\n*Research and Development*\n\nby\n\n**Agata [Skrzyniarz]**\n\n*Thesis Supervisor:*\n\n*Sarra El Ayari*\n\nAcademic Year 2024/2025\n:::', 'Headers: \nHeaders: \n\n---\nauthor:\n- Agata SKRZYNIARZ\nbibliography: biblio.bib\ntitle: Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage\n---  \n::: center  \n-------------------------------------- ------------------------------------------\n:::  \n::: center\n**Institut National des Langues et Civilisations Orientales**\\\n(National Institute for Oriental Languages and Civilizations)  \nDépartement Textes, Informatique, Multilinguisme\\\n(Department of Texts, Computing, and Multilingualism)  \n------------------------------------------------------------------------  \n**Performance Evaluation of Tools for Automatic Processing of Polish L2 Interlanguage**  \n------------------------------------------------------------------------  \n[Master]  \n[Traitement Automatique des Langues]\\\n[(Natural Language Processing)]  \n*Specialization:*  \n*Research and Development*  \nby  \n**Agata [Skrzyniarz]**  \n*Thesis Supervisor:*  \n*Sarra El Ayari*  \nAcademic Year 2024/2025\n:::']","The implementation of this thesis utilized the following Python libraries:

- *spaCy* for morphosyntactic analysis
- *pandas* for data manipulation
- *fuzzywuzzy* (Levenshtein distance) for fuzzy string matching
- *Epitran* for grapheme-to-phoneme transcription
- *langdetect* for language detecting
- *matplotlib* and *seaborn* for visualization
- *JiWER* for calculating WER and CER
- *json*, *xml.etree*, and *csv* for structured data processing and file management.","The Python libraries used included spaCy for morphosyntactic analysis, pandas for data manipulation, fuzzywuzzy (Levenshtein distance) for fuzzy string matching, Epitran for grapheme-to-phoneme transcription, langdetect for language detecting, matplotlib and seaborn for visualization, JiWER for calculating WER and CER, as well as json, xml.etree, and csv for structured data processing and file management.",1.0,0.9785344767974762,0.9999999999,1.0
What percentage of aligned word pairs were identified as erroneous in the learner corpus?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [] for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\niść                isze                           1              0        1        0        0        0     5109  \n: Excerpt with correct and erroneous forms and learner distribution  \nOut of 3,466 aligned pairs, 1,352 were identified as erroneous, accounting for 39.01% of the data. This corpus serves as the foundation for the subsequent analysis of learners' errors."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.  \nThe next step was the extraction of the erroneous words, i.e. the pairs where the word from the manual transcription differs from the corresponding correct version. To achieve this, a script was written to process the JSON file containing aligned segments for each learner. For every pair of words, the script checks whether both manual and correct forms are present and different. If so, the error is registered along with the learner ID and their country. To avoid double-counting, each unique error per learner is stored only once. The results are then grouped by correct form, incorrect (manual) form, and country, and saved into a CSV file listing the number of learners per country who made each error, along with their IDs. In addition, global statistics are computed to count the total number of aligned word pairs and how many of them contain an error.  \n**Correct form**   **Erroneous form**    **No. of learners**   **FR**   **IT**   **NL**   **UK**   **GE**  **Learners**\n------------------ -------------------- --------------------- -------- -------- -------- -------- -------- --------------------\niść                idź                            5              5        0        0        0        0     1104, 1108, (\\...)\niść                iś                            25              2        8        3        11       1     1115, 1118, (\\...)\niść                iszcze                         1              1        0        0        0        0     1117\niść                iścz                           1              1        0        0        0        0     1117\niść                isze                           1              0        1        0        0        0     5109  \n: Excerpt with correct and erroneous forms and learner distribution', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.""]",39.01% of the aligned word pairs were identified as erroneous in the learner corpus.,"Out of 3,466 aligned pairs, 1,352 were identified as erroneous, accounting for 39.01% of the data.",1.0,0.9948970129085903,0.5833333333041666,1.0
What percentage of manual transcription words were successfully aligned with their correct counterparts?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nIn order to systematically identify and extract learner errors from the corpus, an automatic alignment procedure was implemented to compare learners' manual transcriptions with their corresponding correct Polish versions at the word level. The script performs an automatic word-by-word alignment between learners' manual transcriptions and their corresponding correct versions in Polish. First, it loads the processed and organised transcription data as well as the dictionary with words associated with lemmas. Based on this dictionary, the script builds a reverse mapping from word forms to their most frequent lemmas. For each pair of utterances (manual transcription and correct version), the script attempts to align the words by comparing their lemmas. If no lemma match is found, it falls back on fuzzy string matching to identify the most likely corresponding word, using a similarity threshold. Each aligned pair of words is saved into a structured format, including the learner ID, country, and aligned segments. The final output is a JSON file containing the aligned word pairs, which are the base for further error analysis (see [] for an example of a segment with pairs of words from the manual transcription and the corresponding correct version).  \nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Corpus Processing for Extraction of Deviations\n\nOut of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.  \nThe next step was the extraction of the erroneous words, i.e. the pairs where the word from the manual transcription differs from the corresponding correct version. To achieve this, a script was written to process the JSON file containing aligned segments for each learner. For every pair of words, the script checks whether both manual and correct forms are present and different. If so, the error is registered along with the learner ID and their country. To avoid double-counting, each unique error per learner is stored only once. The results are then grouped by correct form, incorrect (manual) form, and country, and saved into a CSV file listing the number of learners per country who made each error, along with their IDs. In addition, global statistics are computed to count the total number of aligned word pairs and how many of them contain an error.  \n**Correct form**   **Erroneous form**    **No. of learners**   **FR**   **IT**   **NL**   **UK**   **GE**  **Learners**\n------------------ -------------------- --------------------- -------- -------- -------- -------- -------- --------------------\niść                idź                            5              5        0        0        0        0     1104, 1108, (\\...)\niść                iś                            25              2        8        3        11       1     1115, 1118, (\\...)\niść                iszcze                         1              1        0        0        0        0     1117\niść                iścz                           1              1        0        0        0        0     1117\niść                isze                           1              0        1        0        0        0     5109  \n: Excerpt with correct and erroneous forms and learner distribution', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", 'Headers: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\n\nAt this point, the corpus was not yet complete; however, the preliminary results showed that the majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners\' Polish interlanguage. Although some words were correctly classified (in bold), they remained a minority. Unfortunately, as many words from the \\*STU segments were simplified attempts at Polish words, the program sometimes incorrectly classified them as belonging to other languages.  \nTo allow for comparison with the native Polish corpus, the same language detection library was applied to the transcriptions produced by the four native speakers. Out of a total of 96 words, only one word -- the Polish word *teraz* (\\""now\\"") -- was mistakenly identified as Italian, representing just 1% of the data. This result confirms the overall reliability of the language detection tool and suggests that the challenges observed in the learner corpus are primarily due to the deformed nature of interlanguage forms rather than limitations of the library itself.  \nThis demonstrates that the automatic method was unreliable. As a result, the removal of non-Polish words had to be done manually.']",82.96% of the manual transcription words were successfully aligned with their correct counterparts.,"Out of 4,178 words in the manual transcriptions, 3,466 were successfully aligned with their correct counterparts, accounting for 82.96% of the manual transcription corpus.",1.0,0.9924174551629551,0.9166666666361111,1.0
What was spaCy's accuracy in case detection for incorrect learner forms versus corrected forms?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nAn evaluation of *spaCy*'s performance in case detection was conducted separately for the incorrect learner forms and their corrected counterparts. The results show that *spaCy* achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.  \n**Case**                           **Precision**    **Recall**   **F1-score**   **Support**\n--------------------------------- ---------------- ------------ -------------- -------------\n*Evaluation on erroneous cases*\nAcc                                     0.38           0.40          0.39           20\nDat                                     0.00           0.00          0.00            0\nGen                                     0.60           0.59          0.60           61\nIns                                     0.75           0.55          0.63           22\nLoc                                     0.00           0.00          0.00           21\nNom                                     0.74           0.73          0.73           142\nnan                                     0.10           0.50          0.16            6\n**Accuracy**                       **0.60** / 272\n**Macro avg**                           0.37           0.39          0.36           272\n**Weighted avg**                        0.61           0.60          0.60           272\n*Evaluation on correct cases*\nAcc                                     1.00           1.00          1.00           23\nDat                                     0.00           0.00          0.00            0\nGen                                     0.90           0.65          0.75           162\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5"", 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5\n**Accuracy**                       **0.75** / 306\n**Macro avg**                           0.44           0.52          0.46           306\n**Weighted avg**                        0.77           0.75          0.74           306  \n: Classification metrics for erroneous and correct forms by grammatical case  \nTo better understand whether these difficulties stem from interlanguage or from the complexity of the language itself, the same procedure was applied to the small Polish native corpus. The overall accuracy in this case was only 67%, which falls between the scores observed for learner errors and corrected forms.  \n**Case**            **Precision**   **Recall**   **F1-score**   **Support**\n------------------ --------------- ------------ -------------- -------------\nAcc                     1.00           0.50          0.67            2\nDat                     0.00           0.00          0.00            0\nGen                     0.25           0.67          0.36            3\nIns                     0.86           1.00          0.92            6\nLoc                     0.00           0.00          0.00            7\nNom                     0.79           0.94          0.86           16\nUNK                     0.00           0.00          0.00            2\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case', 'Headers: Experimentations > Future Perspectives > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives > Open Questions and Obstacles\n\nMoreover, for case-related learning, tools such as *spaCy* could be employed to automatically identify cases in learner speech. However, current results indicate that *spaCy* does not yet handle this task with high accuracy, highlighting an area for potential improvement in future work.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Corpus Processing\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Corpus Processing\n\n: Excerpt of forms with grammatical cases, correspondence, and learner distribution by country  \nNevertheless, the automatic identification of grammatical cases presents certain limitations. Firstly, in the context of interlanguage, the system may assign incorrect cases due to the presence of non-standard or unrecognised forms that are not part of the Polish lexicon. Secondly, the Polish case system itself is highly complex -- a single inflected form may correspond to multiple cases. As a result, accurately identifying the correct case often requires considering the broader syntactic context of the word within the sentence.  \nFor this reason, the table was manually corrected and saved as a new CSV file for the subsequent evaluation of *spaCy* in case attribution.  \nNext, all examples with the word \\""identical\\"" in the \\""correspondence\\"" column or with empty values were removed from the table to create a corpus consisting solely of incorrect inflections. Consequently, the final table contains 204 examples.']",*spaCy* achieved 60% accuracy in case detection for incorrect learner forms and 75% accuracy for corrected forms.,SpaCy achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.,1.0,0.9450487226093247,0.9999999999,1.0
What was spaCy's accuracy in case detection for native Polish speakers?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5\n**Accuracy**                       **0.75** / 306\n**Macro avg**                           0.44           0.52          0.46           306\n**Weighted avg**                        0.77           0.75          0.74           306  \n: Classification metrics for erroneous and correct forms by grammatical case  \nTo better understand whether these difficulties stem from interlanguage or from the complexity of the language itself, the same procedure was applied to the small Polish native corpus. The overall accuracy in this case was only 67%, which falls between the scores observed for learner errors and corrected forms.  \n**Case**            **Precision**   **Recall**   **F1-score**   **Support**\n------------------ --------------- ------------ -------------- -------------\nAcc                     1.00           0.50          0.67            2\nDat                     0.00           0.00          0.00            0\nGen                     0.25           0.67          0.36            3\nIns                     0.86           1.00          0.92            6\nLoc                     0.00           0.00          0.00            7\nNom                     0.79           0.94          0.86           16\nUNK                     0.00           0.00          0.00            2\n**Accuracy**        **0.67** / 36\n**Macro avg**           0.41           0.44          0.40           36\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case', ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context."", ""Headers: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\nAn evaluation of *spaCy*'s performance in case detection was conducted separately for the incorrect learner forms and their corrected counterparts. The results show that *spaCy* achieved 60% accuracy on the incorrect forms and 75% accuracy on the corrected forms.  \n**Case**                           **Precision**    **Recall**   **F1-score**   **Support**\n--------------------------------- ---------------- ------------ -------------- -------------\n*Evaluation on erroneous cases*\nAcc                                     0.38           0.40          0.39           20\nDat                                     0.00           0.00          0.00            0\nGen                                     0.60           0.59          0.60           61\nIns                                     0.75           0.55          0.63           22\nLoc                                     0.00           0.00          0.00           21\nNom                                     0.74           0.73          0.73           142\nnan                                     0.10           0.50          0.16            6\n**Accuracy**                       **0.60** / 272\n**Macro avg**                           0.37           0.39          0.36           272\n**Weighted avg**                        0.61           0.60          0.60           272\n*Evaluation on correct cases*\nAcc                                     1.00           1.00          1.00           23\nDat                                     0.00           0.00          0.00            0\nGen                                     0.90           0.65          0.75           162\nIns                                     0.73           1.00          0.85           74\nLoc                                     0.00           0.00          0.00           13\nNom                                     0.45           1.00          0.62           29\nnan                                     0.00           0.00          0.00            5""]",*spaCy*'s accuracy in case detection for native Polish speakers was 67% (**Accuracy** 0.67 / 36).,"The overall accuracy for native Polish speech was only 67%, which falls between the scores observed for learner errors and corrected forms.",1.0,0.9450213349287632,0.9999999999666667,1.0
Which grammatical case was most overused by learners according to the analysis?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nIn addition, heatmaps were generated to visualize the distribution of grammatical case errors, comparing the incorrect cases used by learners with the correct ones. Cells outlined in green correspond to correct case usage, but since such examples were excluded from the corpus at an earlier stage, these cells all show zero values.  \nFrom the first table (Figure[]), we can confirm the previously mentioned observation that the nominative case is dominant among incorrect usages. Although the overall number of accusative and locative errors is relatively low, in most of these cases (around 80%), learners incorrectly used the nominative instead of the expected form. Similarly, both genitive and instrumental cases are frequently replaced by the nominative -- approximately 63% of the time -- though some of these errors also involve confusion between genitive, instrumental, and locative.  \nThe locative case, which also appears to be slightly overused, is typically required after prepositions such as *na* (\\""on\\"") or *w* (\\""in\\""). This overuse may stem from learners relying on familiar phrases and generalising them to contexts where other cases are expected. The characteristic suffixes of Polish cases (such as -*u*, -*e*, -*em*, or -*a*) can be particularly misleading for learners. For example, the phrase *obok szpitalu* instead of the correct *obok szpitala* (\\""next to the hospital\\"") illustrates confusion between the genitive and locative, likely influenced by more frequent expressions like *w szpitalu* (\\""in the hospital\\""). In fact, 52.63% of incorrect uses of the locative occurred in contexts where the genitive case was required. Furthermore, 36.84% of the same locative errors involved confusion with the instrumental (*za szpitalem* (\\""behind the hospital\\"")).', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\n**Case**    **Expected cases**   **Produced cases**   **Difference (%)**\n---------- -------------------- -------------------- --------------------\nAcc                 16                   13                 -18.75\nGen                106                   5                  -95.28\nIns                 59                   7                  -88.14\nLoc                 11                   19                 72.73\nNom                 12                  125                 941.67  \n: Comparison of expected and produced grammatical cases with relative differences (%)  \nThe following analysis of learner data shows that the most frequently required cases, presented in Table -- the genitive and instrumental -- also generate the highest number of errors among learners. The genitive case is typically used to express possession and appears frequently in phrases referring to street names, such as *ulica Juliusza Słowackiego* (\\""Juliusz Słowacki Street\\""). It also follows prepositions like *obok* (\\""next to\\"" or, in this context, \\""past\\""), which are commonly used in giving directions. The instrumental case, on the other hand, is used when describing movement along a path, especially after verbs of motion such as *iść* (\\""to go\\""), as in *iść ulicą Niską* (\\""go along Niska Street\\""). It is also required after the preposition *za* (\\""behind\\""), which frequently appears in this route direction task.  \nMoreover, one of the most common incorrect cases used by learners is the nominative. This is not unexpected, as the nominative is the default case in Polish. It is the form learners are most familiar with, and in the absence of explicit knowledge about declension rules, they often overgeneralize and use the nominative in contexts that require a different case. This tendency reflects a typical stage in interlanguage development, where learners rely on the most salient or frequent forms of the target language.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.']",The grammatical case most overused by learners according to the analysis is the nominative case.,"The nominative case was most overused by learners, with 941.67% more produced cases than expected, as the nominative is the default case in Polish and learners overgeneralize when lacking explicit declension knowledge.",1.0,0.9774845235704642,0.6388888888675925,1.0
Which grammatical cases showed the highest reduction between expected and produced forms?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\n**Case**    **Expected cases**   **Produced cases**   **Difference (%)**\n---------- -------------------- -------------------- --------------------\nAcc                 16                   13                 -18.75\nGen                106                   5                  -95.28\nIns                 59                   7                  -88.14\nLoc                 11                   19                 72.73\nNom                 12                  125                 941.67  \n: Comparison of expected and produced grammatical cases with relative differences (%)  \nThe following analysis of learner data shows that the most frequently required cases, presented in Table -- the genitive and instrumental -- also generate the highest number of errors among learners. The genitive case is typically used to express possession and appears frequently in phrases referring to street names, such as *ulica Juliusza Słowackiego* (\\""Juliusz Słowacki Street\\""). It also follows prepositions like *obok* (\\""next to\\"" or, in this context, \\""past\\""), which are commonly used in giving directions. The instrumental case, on the other hand, is used when describing movement along a path, especially after verbs of motion such as *iść* (\\""to go\\""), as in *iść ulicą Niską* (\\""go along Niska Street\\""). It is also required after the preposition *za* (\\""behind\\""), which frequently appears in this route direction task.  \nMoreover, one of the most common incorrect cases used by learners is the nominative. This is not unexpected, as the nominative is the default case in Polish. It is the form learners are most familiar with, and in the absence of explicit knowledge about declension rules, they often overgeneralize and use the nominative in contexts that require a different case. This tendency reflects a typical stage in interlanguage development, where learners rely on the most salient or frequent forms of the target language.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nIn addition, heatmaps were generated to visualize the distribution of grammatical case errors, comparing the incorrect cases used by learners with the correct ones. Cells outlined in green correspond to correct case usage, but since such examples were excluded from the corpus at an earlier stage, these cells all show zero values.  \nFrom the first table (Figure[]), we can confirm the previously mentioned observation that the nominative case is dominant among incorrect usages. Although the overall number of accusative and locative errors is relatively low, in most of these cases (around 80%), learners incorrectly used the nominative instead of the expected form. Similarly, both genitive and instrumental cases are frequently replaced by the nominative -- approximately 63% of the time -- though some of these errors also involve confusion between genitive, instrumental, and locative.  \nThe locative case, which also appears to be slightly overused, is typically required after prepositions such as *na* (\\""on\\"") or *w* (\\""in\\""). This overuse may stem from learners relying on familiar phrases and generalising them to contexts where other cases are expected. The characteristic suffixes of Polish cases (such as -*u*, -*e*, -*em*, or -*a*) can be particularly misleading for learners. For example, the phrase *obok szpitalu* instead of the correct *obok szpitala* (\\""next to the hospital\\"") illustrates confusion between the genitive and locative, likely influenced by more frequent expressions like *w szpitalu* (\\""in the hospital\\""). In fact, 52.63% of incorrect uses of the locative occurred in contexts where the genitive case was required. Furthermore, 36.84% of the same locative errors involved confusion with the instrumental (*za szpitalem* (\\""behind the hospital\\"")).', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Corpus Processing\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Corpus Processing\n\n: Excerpt of forms with grammatical cases, correspondence, and learner distribution by country  \nNevertheless, the automatic identification of grammatical cases presents certain limitations. Firstly, in the context of interlanguage, the system may assign incorrect cases due to the presence of non-standard or unrecognised forms that are not part of the Polish lexicon. Secondly, the Polish case system itself is highly complex -- a single inflected form may correspond to multiple cases. As a result, accurately identifying the correct case often requires considering the broader syntactic context of the word within the sentence.  \nFor this reason, the table was manually corrected and saved as a new CSV file for the subsequent evaluation of *spaCy* in case attribution.  \nNext, all examples with the word \\""identical\\"" in the \\""correspondence\\"" column or with empty values were removed from the table to create a corpus consisting solely of incorrect inflections. Consequently, the final table contains 204 examples.']","The grammatical cases that showed the highest reduction between expected and produced forms are the genitive case, with a reduction of -95.28%, and the instrumental case, with a reduction of -88.14% (as indicated in the table).",The genitive showed a 95.28% reduction and the instrumental showed an 88.14% reduction between expected and produced forms.,1.0,0.9999999999999998,0.99999999995,1.0
What percentage of accusative and locative errors involved learners incorrectly using the nominative?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nIn addition, heatmaps were generated to visualize the distribution of grammatical case errors, comparing the incorrect cases used by learners with the correct ones. Cells outlined in green correspond to correct case usage, but since such examples were excluded from the corpus at an earlier stage, these cells all show zero values.  \nFrom the first table (Figure[]), we can confirm the previously mentioned observation that the nominative case is dominant among incorrect usages. Although the overall number of accusative and locative errors is relatively low, in most of these cases (around 80%), learners incorrectly used the nominative instead of the expected form. Similarly, both genitive and instrumental cases are frequently replaced by the nominative -- approximately 63% of the time -- though some of these errors also involve confusion between genitive, instrumental, and locative.  \nThe locative case, which also appears to be slightly overused, is typically required after prepositions such as *na* (\\""on\\"") or *w* (\\""in\\""). This overuse may stem from learners relying on familiar phrases and generalising them to contexts where other cases are expected. The characteristic suffixes of Polish cases (such as -*u*, -*e*, -*em*, or -*a*) can be particularly misleading for learners. For example, the phrase *obok szpitalu* instead of the correct *obok szpitala* (\\""next to the hospital\\"") illustrates confusion between the genitive and locative, likely influenced by more frequent expressions like *w szpitalu* (\\""in the hospital\\""). In fact, 52.63% of incorrect uses of the locative occurred in contexts where the genitive case was required. Furthermore, 36.84% of the same locative errors involved confusion with the instrumental (*za szpitalem* (\\""behind the hospital\\"")).', ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\n**Case**    **Expected cases**   **Produced cases**   **Difference (%)**\n---------- -------------------- -------------------- --------------------\nAcc                 16                   13                 -18.75\nGen                106                   5                  -95.28\nIns                 59                   7                  -88.14\nLoc                 11                   19                 72.73\nNom                 12                  125                 941.67  \n: Comparison of expected and produced grammatical cases with relative differences (%)  \nThe following analysis of learner data shows that the most frequently required cases, presented in Table -- the genitive and instrumental -- also generate the highest number of errors among learners. The genitive case is typically used to express possession and appears frequently in phrases referring to street names, such as *ulica Juliusza Słowackiego* (\\""Juliusz Słowacki Street\\""). It also follows prepositions like *obok* (\\""next to\\"" or, in this context, \\""past\\""), which are commonly used in giving directions. The instrumental case, on the other hand, is used when describing movement along a path, especially after verbs of motion such as *iść* (\\""to go\\""), as in *iść ulicą Niską* (\\""go along Niska Street\\""). It is also required after the preposition *za* (\\""behind\\""), which frequently appears in this route direction task.  \nMoreover, one of the most common incorrect cases used by learners is the nominative. This is not unexpected, as the nominative is the default case in Polish. It is the form learners are most familiar with, and in the absence of explicit knowledge about declension rules, they often overgeneralize and use the nominative in contexts that require a different case. This tendency reflects a typical stage in interlanguage development, where learners rely on the most salient or frequent forms of the target language.']",Approximately 80% of accusative errors and around 63% of locative errors involved learners incorrectly using the nominative instead of the expected forms.,Around 80% of accusative and locative errors involved learners incorrectly using the nominative instead of the expected form.,0.5,0.9999995256245521,0.8055555555287036,1.0
What was the most common pronunciation error observed in the learner corpus?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nThe five most frequent pronunciation errors observed in the learner corpus reveal recurring patterns and potential phonological challenges, most likely influenced by the learners' native languages. The most common error concerned the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups, with the highest number found among German speakers (10); however, all groups exhibited this error at some point. The second most common error involved the replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, where learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/. This suggests difficulty in distinguishing between retroflex and alveolar fricatives. Once again, German speakers accounted for the highest number of errors (10), while French learners made the fewest (2). A similar phenomenon appeared in the third error, where the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/ was omitted, resulting in the simplified form *iś* /iɕ/, produced by 25 learners. This pattern may indicate difficulty pronouncing complex affricates in word-final position. Interestingly, the English group committed this error most frequently (11), whereas it was least common among German learners (1). The fourth error again reflected confusion between retroflex and alveolar consonants: *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This error was most common among Dutch speakers (9) and was not observed at all in the English group. An interesting case worth mentioning, although it ranks only thirteenth most frequent error, is the tendency of Italian learners to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as *niskon*. This substitution illustrates the difficulty of"", 'Headers: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Corpus Processing\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Corpus Processing\n\n: Excerpt: Distribution of correct vs. erroneous forms and example words per learner country\n:::  \nNevertheless, this way of presenting phonetic errors is not ideal. For future linguistic analysis, it is crucial to retain information about the specific words in which a given phonetic error occurred, as this can help identify underlying factors such as native language interference or target language influence. While in this representation we can see which words contained a particular phoneme error, it does not indicate whether all learners actually mispronounced those words. For instance, in the first example, one learner might have pronounced Juliusza correctly but made an error in proszę. Although this representation already offers some insights, it lacks precision and may not be sufficiently informative for in-depth phonetic analysis or error pattern discovery.  \nWe developped a second method of grouping pronunciation errors involved organizing them by lemma in order to identify recurring mispronunciations of the same lexical item. For each entry, the script extracts the lemma of the correct form using the Polish *spaCy* model. Then, it groups all instances that share the same lemma, correct form, and corresponding erroneous pronunciation. Within each group, it aggregates the different correct and incorrect forms as well as the learner IDs associated with the error. As always, the script also shows the number of learners from each country and the total number of learners for each error.  \nIn the second part, the code uses the *Epitran* library to convert all correct and erroneous forms into their phonetic representations. This results in a final file where all entries are transcribed in IPA, allowing for a more fine-grained analysis of recurring pronunciation patterns and errors across learners. Both representations are saved into new CSV files.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\niɕt͡ɕ                  iɕ                      t͡ɕ          --            2        8        3        11       1     25                   1115, (...)\nt͡ʂtɛrɨ                ʂtɛrɛ, ʂtɛri, (\\...)    t͡ʂ          ʂ             2        7        9        0        7     25                   1103, (...)\nʂkɔwɨ                 skawa, skɔla, (\\...)    ʂ           s             5        5        3        2        10    25                   1108, (...)  \n: Excerpt of correct and erroneous forms with learner distribution by country (IPA)\n:::  \nThese tables present the most frequent pronunciation errors made by the learners, based on a total of 310 examples. The \\""base\\"" of each entry corresponds to the correct form of a word -- or multiple forms sharing the same lemma (e.g., different case-inflected variants of the same word). For each entry, the table includes the erroneous forms produced by the learners, the correct-erroneous sound pair, and the statistical data. This representation allows for a clearer understanding of how many learners from each country produced the same phonetic error within a given word.']","The most common pronunciation error observed in the learner corpus was the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups.","The most common error concerned the substitution of the Polish phoneme /w/ (spelled ł) with /l/, particularly in the word szkoły /ʂkɔwɨ/, which was frequently realized as skola /skɔla/ or similar forms, made by 32 learners across all language groups.",1.0,1.0,0.999999999975,1.0
What total number of pronunciation error examples were analyzed?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Corpus Processing\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Corpus Processing\n\n: Excerpt: Distribution of correct vs. erroneous forms and example words per learner country\n:::  \nNevertheless, this way of presenting phonetic errors is not ideal. For future linguistic analysis, it is crucial to retain information about the specific words in which a given phonetic error occurred, as this can help identify underlying factors such as native language interference or target language influence. While in this representation we can see which words contained a particular phoneme error, it does not indicate whether all learners actually mispronounced those words. For instance, in the first example, one learner might have pronounced Juliusza correctly but made an error in proszę. Although this representation already offers some insights, it lacks precision and may not be sufficiently informative for in-depth phonetic analysis or error pattern discovery.  \nWe developped a second method of grouping pronunciation errors involved organizing them by lemma in order to identify recurring mispronunciations of the same lexical item. For each entry, the script extracts the lemma of the correct form using the Polish *spaCy* model. Then, it groups all instances that share the same lemma, correct form, and corresponding erroneous pronunciation. Within each group, it aggregates the different correct and incorrect forms as well as the learner IDs associated with the error. As always, the script also shows the number of learners from each country and the total number of learners for each error.  \nIn the second part, the code uses the *Epitran* library to convert all correct and erroneous forms into their phonetic representations. This results in a final file where all entries are transcribed in IPA, allowing for a more fine-grained analysis of recurring pronunciation patterns and errors across learners. Both representations are saved into new CSV files.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\niɕt͡ɕ                  iɕ                      t͡ɕ          --            2        8        3        11       1     25                   1115, (...)\nt͡ʂtɛrɨ                ʂtɛrɛ, ʂtɛri, (\\...)    t͡ʂ          ʂ             2        7        9        0        7     25                   1103, (...)\nʂkɔwɨ                 skawa, skɔla, (\\...)    ʂ           s             5        5        3        2        10    25                   1108, (...)  \n: Excerpt of correct and erroneous forms with learner distribution by country (IPA)\n:::  \nThese tables present the most frequent pronunciation errors made by the learners, based on a total of 310 examples. The \\""base\\"" of each entry corresponds to the correct form of a word -- or multiple forms sharing the same lemma (e.g., different case-inflected variants of the same word). For each entry, the table includes the erroneous forms produced by the learners, the correct-erroneous sound pair, and the statistical data. This representation allows for a clearer understanding of how many learners from each country produced the same phonetic error within a given word.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nTaken together, these errors point to systematic challenges with Polish retroflex consonants and nasal vowels, as learners tend to replace them with more familiar alveolar sounds or denasalized vowels from their native phonological inventories. The full dataset provides a rich basis for further phonological and cross-linguistic analysis.']",A total of 310 pronunciation error examples were analyzed.,A total of 310 pronunciation error examples were analyzed.,1.0,0.9534789468637028,0.3333333333,1.0
What challenges do Polish retroflex consonants present for learners?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nTaken together, these errors point to systematic challenges with Polish retroflex consonants and nasal vowels, as learners tend to replace them with more familiar alveolar sounds or denasalized vowels from their native phonological inventories. The full dataset provides a rich basis for further phonological and cross-linguistic analysis.', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', ""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nThe five most frequent pronunciation errors observed in the learner corpus reveal recurring patterns and potential phonological challenges, most likely influenced by the learners' native languages. The most common error concerned the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups, with the highest number found among German speakers (10); however, all groups exhibited this error at some point. The second most common error involved the replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, where learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/. This suggests difficulty in distinguishing between retroflex and alveolar fricatives. Once again, German speakers accounted for the highest number of errors (10), while French learners made the fewest (2). A similar phenomenon appeared in the third error, where the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/ was omitted, resulting in the simplified form *iś* /iɕ/, produced by 25 learners. This pattern may indicate difficulty pronouncing complex affricates in word-final position. Interestingly, the English group committed this error most frequently (11), whereas it was least common among German learners (1). The fourth error again reflected confusion between retroflex and alveolar consonants: *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This error was most common among Dutch speakers (9) and was not observed at all in the English group. An interesting case worth mentioning, although it ranks only thirteenth most frequent error, is the tendency of Italian learners to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as *niskon*. This substitution illustrates the difficulty of""]","Polish retroflex consonants pose significant challenges for learners primarily due to their tendency to replace these sounds with more familiar alveolar sounds from their native phonological inventories. For instance, learners often confuse the retroflex /ʂ/ with the alveolar /s/, as seen in the word *szpital*, which is commonly produced as *spita* or *spytal*. Additionally, distinctions between retroflex affricates like /t͡ɕ/ and their alveolar counterparts can be difficult, leading to omissions in production, such as in the verb *iść*, often simplified to *iś*. This systematic substitution reflects the learners' struggles in articulating sounds that are absent or distinctly different in their native languages, contributing to persistent pronunciation deviations in their interlanguage speech (see citations).","Learners have difficulty distinguishing between retroflex and alveolar fricatives, often replacing /ʂ/ with /s/ (as in szpital becoming spita) and /t͡ʂ/ with /ʂ/ (as in cztery becoming sztere).",1.0,0.9941529114432677,0.6388888888675925,1.0
What specific pronunciation challenge was noted among Italian learners?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nis the tendency of Italian learners to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as *niskon*. This substitution illustrates the difficulty of acquiring nasal vowels, which are absent from many learners' native phonological systems."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nThe five most frequent pronunciation errors observed in the learner corpus reveal recurring patterns and potential phonological challenges, most likely influenced by the learners' native languages. The most common error concerned the substitution of the Polish phoneme /w/ (spelled *ł*) with /l/, particularly in the word *szkoły* /ʂkɔwɨ/, which was frequently realized as *skola* /skɔla/, *skole* /skɔlɛ/, *szkole* /ʂkɔlɛ/, and similar forms. This error was made by 32 learners across all language groups, with the highest number found among German speakers (10); however, all groups exhibited this error at some point. The second most common error involved the replacement of /ʂ/ with /s/ in the word *szpital* /ʂpital/, where learners produced forms such as *spita* /spita/ or *spytal* /spɨtal/. This suggests difficulty in distinguishing between retroflex and alveolar fricatives. Once again, German speakers accounted for the highest number of errors (10), while French learners made the fewest (2). A similar phenomenon appeared in the third error, where the affricate /t͡ɕ/ in the verb *iść* /iɕt͡ɕ/ was omitted, resulting in the simplified form *iś* /iɕ/, produced by 25 learners. This pattern may indicate difficulty pronouncing complex affricates in word-final position. Interestingly, the English group committed this error most frequently (11), whereas it was least common among German learners (1). The fourth error again reflected confusion between retroflex and alveolar consonants: *cztery* /t͡ʂtɛrɨ/ was often realized as *sztere* /ʂtɛrɛ/ or *szteri* /ʂtɛrɨ/, with /t͡ʂ/ replaced by /ʂ/. This error was most common among Dutch speakers (9) and was not observed at all in the English group. An interesting case worth mentioning, although it ranks only thirteenth most frequent error, is the tendency of Italian learners to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as *niskon*. This substitution illustrates the difficulty of"", 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Results\n\nTaken together, these errors point to systematic challenges with Polish retroflex consonants and nasal vowels, as learners tend to replace them with more familiar alveolar sounds or denasalized vowels from their native phonological inventories. The full dataset provides a rich basis for further phonological and cross-linguistic analysis.']","The specific pronunciation challenge noted among Italian learners was their tendency to replace the nasal vowel /ɔ̃w̃/ in *niską* /ɲiskɔ̃w̃/ with the sequence /ɔn/, resulting in forms such as *niskon*. This substitution illustrates the difficulty of acquiring nasal vowels, which are absent from many learners' native phonological systems.","Italian learners tended to replace the nasal vowel /ɔ̃w̃/ in niską /ɲiskɔ̃w̃/ with the sequence /ɔn/, producing forms such as niskon, illustrating the difficulty of acquiring nasal vowels absent from their native phonological system.",1.0,0.6815317501624254,0.5833333333041666,1.0
What were the global WER and CER results for Whisper on Polish interlanguage?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\n\n:::\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate].""]","The global results for Whisper on Polish interlanguage show a Word Error Rate (WER) of 75.4% and a Character Error Rate (CER) of 46.4% ({El Ayari} and Li, 2024).",The average WER reached 75.4% and the CER was 46.4% for Polish interlanguage transcription.,0.6666666666666666,0.8443449213748653,0.9166666666361111,1.0
What were the median WER and CER scores for Whisper on Polish interlanguage?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\n\n:::\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIn this section, we assess how Whisper performs when transcribing Polish interlanguage, focusing on its ability to accurately render learner speech at both the word and character levels. To this end, we calculate and analyse two standard ASR evaluation metrics: Word Error Rate (WER) and Character Error Rate (CER). Both metrics are commonly used to quantify ASR performance [@elayari:hal-04769687]. They are based on the Levenshtein distance, which counts the number of substitutions (S), deletions (D), and insertions (I) needed to transform the system output into the reference transcription. Formally, they are defined as follows:  \nThe comparison is based on the full dataset, using the JSON file containing all organised transcriptions for each learner. Given the deformed and often unstable nature of interlanguage, characterised by pronunciation deviations and non-standard forms, relatively low transcription accuracy is to be expected. The same evaluation was also performed on a small corpus of native Polish speech, providing a baseline to compare interlanguage and standard Polish transcription performance."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.""]","The median WER score for Whisper on Polish interlanguage was 50%, and the median CER score was 22.2% ({El Ayari} and Li, 2024).",The median WER was 50% and the median CER was 22.2%.,0.6666666666666666,0.9999937026343443,0.9999999999,1.0
How did Whisper perform on native Polish speech compared to interlanguage?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Future Perspectives > Introduction\nHeaders: Experimentations > Future Perspectives > Introduction\n\nOne promising direction for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage. This could potentially be achieved through fine-tuning the model using a dedicated interlanguage corpus. In such a setup, the system would be trained to recognize and transcribe interlanguage forms, rather than correcting them into standard Polish. The new vocabulary -- reflecting common learner errors -- would help the model predict and output words closer to what the learner actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers, ideally with a background in linguistics or second language acquisition.""]",This question is not related to the provided thesis context.,"Evaluation on native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%, compared to 75.4% WER and 46.4% CER for interlanguage.",0.0,0.0,0.8333333332916666,0.0
What percentage of pronunciation-related interlanguage words were identically transcribed by Whisper?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n-   **Identical reproduction:** the learner\'s interlanguage word was transcribed exactly as pronounced.  \n-   **Overcorrection -- correct in the context:** the transcription produces a valid Polish word that fits the intended meaning in the given context.  \n-   **Overcorrection -- incorrect in the context:** the transcription outputs a valid Polish word, but one that does not match the intended meaning in context.  \n-   **Hallucination -- word \\""invented\\"" by Whisper:** the model produced invented sequences not found in either the learner\'s input or the Polish lexicon.  \n-   **Omission:** the learner\'s interlanguage form was not transcribed at all.  \n##### Results  \n:::\n**Category**                                                          **Number of words**   **Percentage of corpus**\n------------------------------------------------------------------- --------------------- --------------------------\nIdentically transcribed words                                                          72                     10.88%\nOvercorrected words (correct in context)                                              202                     30.51%\nOvercorrected words (existing in Polish but incorrect in context)                     176                     26.59%\nWords invented by Whisper                                                             108                     16.31%\nUntranscribed words                                                                   104                     15.71%\n**Total**                                                                             662                       100%  \n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::']",The percentage of pronunciation-related interlanguage words that were identically transcribed by Whisper is 10.88% (72 words) (source: CONTEXT).,"Within the pronunciation-related interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper.",0.6666666666666666,0.9999993995711485,0.9166666666361111,1.0
What percentage of pronunciation-related interlanguage words were overcorrected by Whisper?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\n\nSince systems like Whisper are trained primarily on standard language transcribing interlanguage presents a significant challenge. This study explores the use of automatic transcription for interlanguage in the context of second language acquisition. In this setting, the goal of the ASR tool is not simply to provide a correct transcription, but rather to reproduce the learner's utterance as faithfully as possible, including any linguistic errors. Overcorrection, therefore, is undesirable, as it obscures the learner's original production. Based on these considerations, it can be hypothesized that overcorrection is likely to be the most frequent type of transcription error encountered in this corpus. In this section, we assess Whisper's performance on such dataset and examine the extent to which its output faithfully reflects the learners' original speech.""]","In the pronunciation-related interlanguage subset, 57.1% of the words were overcorrected by Whisper.","The majority of words (57.1%) were overcorrected, with 202 cases (30.51%) being correct in context and 176 cases (26.59%) being contextually inappropriate despite being valid Polish words.",1.0,0.9528869778877799,0.499999999975,1.0
What were the categories used to classify Whisper's outputs for pronunciation-related errors?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable.""]","Whisper's outputs for pronunciation-related errors were classified into the following categories:

1. **Identical Transcription**: 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output.
  
2. **Overcorrections**: The majority of words (57.1%) were overcorrected, where Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context (202 cases, 30.51%) or with a contextually inappropriate substitution (176 cases, 26.59%).

3. **Invented Forms**: Entirely new words were produced in 108 cases (16.31%), reflecting Whisper's tendency to generate plausible-sounding vocabulary.

4. **No Transcription**: In 104 instances (15.71%), no transcription was produced at all, indicating persistent recognition difficulties.","The categories were:
1. Identical reproduction (10.88%)
2. Overcorrection - correct in context (30.51%)
3. Overcorrection - incorrect in context (26.59%)
4. Hallucination - word invented by Whisper (16.31%)
5. Omission (15.71%)",0.7333333333333333,0.9937814497982926,0.3333333333,1.0
What percentage of declension-related interlanguage words were faithfully reproduced by Whisper?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", 'Headers: Experimentations > Evaluation of Whisper\'s Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper\'s Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\nFR            1101          ulic                       ?                          ulicy                       Loc                --                     --  \n: Comparison of learner interlanguage, correct Polish forms, and automatic transcriptions with grammatical cases\n:::  \nThe script categorizes the types of outcomes produced by Whisper when processing declension-related interlanguage phenomena, as follows:  \n-   **Faithful reproduction:** Whisper repeats the form used by the learner, reproducing the error.  \n-   **Overcorrection:** Whisper corrects the learner\'s form by using the grammatically correct Polish form according to standard grammar rules.  \n-   **Untranscribed:** Whisper fails to assign any grammatical case or produce a form (missing transcription).  \n-   **Unknown:** The grammatical case is either unidentified or uncertain, indicated by question marks (\\""?\\"").  \n-   **Invented form:** Whisper produces a grammatical form different from both the learner\'s and the correct form.  \n##### Results  \n:::\n**Category**                                         **Number of examples**   **Percentage of corpus**\n--------------------------------------------------- ------------------------ --------------------------\nFaithful reproduction (reproduction of the error)             221                      42.10%\nOvercorrection                                                114                      21.71%\nNot transcribed                                                43                      8.19%\nUnknown                                                        39                      7.43%\nInvented form                                                 108                      20.57%\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::']",42.10% of declension-related interlanguage words were faithfully reproduced by Whisper.,"In 42.10% of declension-related cases (221 examples), Whisper faithfully reproduced learners' errors.",1.0,1.0000000000000002,0.9166666666361111,1.0
How did Whisper's faithful reproduction rate differ between pronunciation and declension errors?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input.""]","Whisper's faithful reproduction rate for declension errors was 42.10%, while for pronunciation errors, it was significantly lower at 10.88%. This indicates that Whisper was much more effective at capturing declension-related learner errors compared to pronunciation-related ones.","The faithful reproduction rate for declension errors (42.10%) was notably higher than that observed for pronunciation errors (10.88%), suggesting Whisper is more suited to detecting systematic grammatical errors than phonetic inaccuracies.",1.0,0.8985238131634115,0.9999999999666667,1.0
What were the categories used to classify Whisper's outputs for declension-related errors?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Classification of Deviations > Introduction\n\nThe nature of the task allowed for the classification of learner errors into two main categories: declension errors (i.e., incorrect grammatical case inflections) and pronunciation errors. Since the learners were reproducing utterances they had previously heard and repeated after native Polish speakers -- rather than learning grammatical rules or case endings by heart -- their erroneous forms typically stem from either inaccurate pronunciation or misusage of case endings.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.']","The categories used to classify Whisper's outputs for declension-related errors include:

1. **Faithful Reproduction**: Whisper accurately reproduced the learner's erroneous form (42.10%).
2. **Invented Forms**: Whisper produced a grammatical form different from both the learner's and the correct form (20.57%).
3. **Overcorrections**: The system replaced the learner's form with a different, correct form (21.71%).
4. **Not Transcribed Items**: Instances where the system failed to recognize any input (8.19%).
5. **Ambiguous or Unidentifiable Output**: Cases where the output was unclear (7.43%).","The categories were:
1. Faithful reproduction (42.10%)
2. Overcorrection (21.71%)
3. Not transcribed (8.19%)
4. Unknown (7.43%)
5. Invented form (20.57%)",0.8333333333333334,0.9867641686536854,0.5833333333041666,0.8333333333333334
What did El Ayari and Li (2024) find when evaluating Whisper on French L2 learner corpus?,"['Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", 'Headers: General Context > State of the Art > The Whisper Model\nHeaders: General Context > State of the Art > The Whisper Model\n\nWhisper [@radford2022robustspeechrecognitionlargescale] represents a new generation of ASR: a transformer encoder--decoder trained on 680,000 hours of multilingual data. Unlike traditional HMM-based systems, Whisper directly predicts text tokens from log-Mel spectrograms, offering robustness across domains, languages, and accents. Models are released in multiple sizes, enabling a balance between speed and accuracy.  \nFor L2 speech, Whisper performs better than many commercial systems, but it often \\""over-corrects\\"" learner speech -- for example, restoring omitted particles or ignoring disfluencies. This behavior, observed in L2 French [@elayari:hal-04769687], risks erasing the very interlanguage phenomena. In the context of Polish, such normalization could obscure substitutions of nasal vowels or partial palatalization.  \nNevertheless, Whisper\'s open-source nature, high baseline accuracy, and multilingual scope make it an attractive candidate for adaptation. With targeted fine-tuning on learner corpora, it could become a powerful tool for L2 research.', 'Headers: Abstract\nHeaders: Abstract\n\nThis thesis investigates the performance of automatic tools in processing Polish interlanguage produced by adult learners from the VILLA project, who completed a route-giving task after 14 hours of instruction. The study has two main objectives: first, to analyze learner deviations in case inflection and pronunciation, revealing patterns such as overuse of the nominative, confusion between genitive, instrumental, and locative forms, and difficulties with retroflex consonants and nasal vowels; second, to evaluate Whisper, an end-to-end ASR system, on its ability to transcribe Polish interlanguage. A detailed analysis shows that Whisper often overcorrects pronunciation errors but reproduces declension deviations more faithfully. These results underscore both the potential and limitations of Whisper and suggest directions for improvement, such as fine-tuning ASR models on learner corpora and integrating morphosyntactic analysis.\\\n**Keywords:** interlanguage, automatic speech recognition (ASR), Whisper, Polish, transcription, second language acquisition (SLA), learner error analysis']","El Ayari and Li (2024) found that while Whisper achieved relatively good word error rate (WER) and character error rate (CER) scores on advanced French L2 learners, it often ""hyper-normalized"" learner speech by correcting errors, such as changing *expériencer* to *expérimenter*, which introduced hallucinations or omitted disfluencies like repetitions and pauses. This tendency compromises the reliability of automatic speech recognition (ASR) as a tool for second language acquisition (SLA) research since the deviations from the target norm are the primary focus of investigation. They also noted that ASR performance improves with learner proficiency, implying that error rates may reflect acquisition progress. The authors concluded that learner corpora should be viewed as a low-resource language variety and emphasized the importance of fine-tuning ASR models on such data to ensure accurate transcription and avoid overcorrection ({El Ayari} and Li, 2024).","El Ayari and Li (2024) found that although Whisper achieved relatively good WER and CER scores on advanced learners, it often hyper-normalized learner speech by correcting errors, introducing hallucinations, or omitting disfluencies such as repetitions and pauses.",0.8181818181818182,0.6175665664996807,0.9999999999666667,1.0
What early CAPT system was developed specifically for German learners of Polish?,"['Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech > Automatic Speech Recognition for L2 Polish Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech > Automatic Speech Recognition for L2 Polish Speech\n\nResearch on ASR for Polish, particularly for non-native speech, remains limited compared to English. The Polish language presents unique challenges for automatic recognition due to its rich inflectional system, free word order, and complex phonetic features, including nasal vowels, consonant clusters, and palatal fricatives [@zioko11_interspeech]. These linguistic characteristics make both accurate transcription and error detection in learner speech considerably more difficult than in less morphologically complex languages.  \nOne of the earliest Computer-Assisted Pronunciation Training (CAPT) systems for Polish, AzAR, was developed specifically for German learners and combined HMM-based ASR with error patterns typical of L2 Polish [@wagner2010]. This system successfully helped learners identify and practice problematic contrasts(e.g., /ɕ/, /ʐ/, nasal vowels), and nasal vowels, demonstrating the potential of ASR-assisted feedback in targeted pronunciation training. However, AzAR faced limitations in recognition accuracy and robustness, particularly when handling spontaneous or less controlled speech.  \nMore recently, end-to-end deep learning approaches, such as Whisper and wav2vec2, have opened new possibilities for Polish ASR. These models offer robustness across domains and the capacity to learn complex acoustic patterns directly from data. A promising direction is the fine-tuning of such large models on learner-specific corpora, like EURONOUNCE [@cylwik09_slate], which contains non-native Polish speech. Fine-tuning on these datasets could ensure that interlanguage features are preserved in the transcription rather than automatically normalized, thus providing more accurate feedback and enabling detailed analysis of learner errors.', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.']","The early CAPT system developed specifically for German learners of Polish is called AzAR (Wagner, 2014).","AzAR was an early Computer-Assisted Pronunciation Training system developed specifically for German learners, combining HMM-based ASR with error patterns typical of L2 Polish (Wagner, 2010).",0.5,0.9689482333263614,0.9999999999,1.0
What is the EURONOUNCE corpus?,"[""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage."", ""Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nThe corpus used for the analysis consists of manual transcriptions of voice recordings from the Route Direction task. The transcriptions were created by the author of the thesis (a native speaker of Polish), using ELAN, a tool for annotating audio and video recordings, and saved in `.eaf` format. Each file include two parallel tiers:\\  \n-   **\\*STU**: manual transcriptions that accurately reflect what the learner said;  \n-   **%pol**: corrected versions in standard Polish, representing the intended meaning of the learner's utterance.  \nThe corpus analysed in this study includes only data from the meaning-based groups across all five countries. This decision was made due to the limited availability of recordings from the form-based groups, as well as the intention to maintain a balanced dataset for each language group. Furthermore, the analysis is restricted to adult learners, as the data from the group of children (Germany) was also limited.  \nFor each country, the corpus includes the same types of data: audio recordings (`.wav` files), manual transcriptions (`.eaf` files), and automatic transcriptions generated by Whisper (`.txt` files).  \n:::\n**Country**    **Number of wav/eaf/txt files**  **Total duration of recordings**\n------------- --------------------------------- ----------------------------------\nFrance                       17                 23 minutes 32 seconds\nItaly                        17                 26 minutes 39 seconds\nNetherlands                  18                 28 minutes 34 seconds\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::"", 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.']",This question is not related to the provided thesis context.,"EURONOUNCE is a corpus containing non-native Polish speech that could be used for fine-tuning ASR models on learner-specific data (Cylwik et al., 2009).",0.0,0.0,0.49999999995,0.0
Why is overcorrection by ASR systems problematic for interlanguage research?,"['Headers: General Context > State of the Art > Conclusions\nHeaders: General Context > State of the Art > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\n\nSince systems like Whisper are trained primarily on standard language transcribing interlanguage presents a significant challenge. This study explores the use of automatic transcription for interlanguage in the context of second language acquisition. In this setting, the goal of the ASR tool is not simply to provide a correct transcription, but rather to reproduce the learner's utterance as faithfully as possible, including any linguistic errors. Overcorrection, therefore, is undesirable, as it obscures the learner's original production. Based on these considerations, it can be hypothesized that overcorrection is likely to be the most frequent type of transcription error encountered in this corpus. In this section, we assess Whisper's performance on such dataset and examine the extent to which its output faithfully reflects the learners' original speech."", 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nASR systems are trained on native speech and tend to perform poorly with non-native input, which can result in lower transcription accuracy and inaccurate evaluations of learner speech. For example, the system might produce incorrect text or suggest pronunciation corrections that do not match the learner\'s actual production, potentially providing misleading guidance. However, continuous improvements in machine learning and the increasing availability of diverse speech data have significantly reduced the accuracy gap between native and non-native recognition (e.g., Google ASR reduced this gap from 20% to 3--5%) [@gottardi; @https://doi.org/10.1002/tesq.3006].  \nRecent research highlights both the potential and the challenges of using automatic speech recognition (ASR) for pronunciation training. [@michot2024errorpreservingautomaticspeechrecognition] addressed the crucial issue of designing an ASR system that not only transcribes learner speech accurately but also preserves their errors, thus enabling effective corrective feedback. To this end, they collected approximately 85 hours of spontaneous English speech from Swiss learners in grades 4--6 (about 45,000 utterances) and manually transcribed it with explicit error annotations. They proposed a new evaluation metric, the Word-Based Error Preservation Rate (WEPR), to measure the extent to which ASR systems maintain learner errors instead of automatically ""correcting"" them. Their findings demonstrated that a fine-tuned ASR model, trained directly on children\'s data, achieved a substantially higher WEPR and lower Word Error Rate (WER) than off-the-shelf systems, underscoring the promise of error-preserving ASR for pedagogical purposes.', 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.']","Oversight by ASR systems is problematic for interlanguage research because it obscures the learner's original speech, including the linguistic errors that are essential for analyzing language acquisition. Accurate transcription should reflect the learner's utterances, mistakes included, as these errors provide critical insights into their interlanguage development. Overcorrection not only misrepresents the learners' productions but can also mislead corrective feedback, compromising the effectiveness of language instruction. Consequently, it hinders researchers' ability to study genuine learner patterns, which are vital for understanding second language acquisition processes (Michot et al., 2024) ({El Ayari} and Li, 2024).","Overcorrection is problematic because it obscures the learner's original production, and deviations from the target norm are precisely the phenomena under investigation in second language acquisition research.",1.0,0.8214909432420764,0.999999999975,1.0
What suggestion is made for future improvement of Whisper for interlanguage transcription?,"[""Headers: Experimentations > Future Perspectives > Introduction\nHeaders: Experimentations > Future Perspectives > Introduction\n\nOne promising direction for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage. This could potentially be achieved through fine-tuning the model using a dedicated interlanguage corpus. In such a setup, the system would be trained to recognize and transcribe interlanguage forms, rather than correcting them into standard Polish. The new vocabulary -- reflecting common learner errors -- would help the model predict and output words closer to what the learner actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers, ideally with a background in linguistics or second language acquisition."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Introduction\n\nSince systems like Whisper are trained primarily on standard language transcribing interlanguage presents a significant challenge. This study explores the use of automatic transcription for interlanguage in the context of second language acquisition. In this setting, the goal of the ASR tool is not simply to provide a correct transcription, but rather to reproduce the learner's utterance as faithfully as possible, including any linguistic errors. Overcorrection, therefore, is undesirable, as it obscures the learner's original production. Based on these considerations, it can be hypothesized that overcorrection is likely to be the most frequent type of transcription error encountered in this corpus. In this section, we assess Whisper's performance on such dataset and examine the extent to which its output faithfully reflects the learners' original speech."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context.""]","A suggestion for future improvement of Whisper for interlanguage transcription is to develop a version specifically adapted to Polish interlanguage by fine-tuning the model using a dedicated interlanguage corpus. This would involve training the system to recognize and transcribe interlanguage forms without correcting them to standard Polish, which would enhance the model's ability to predict and output words closer to what the learner actually said. Additionally, it is emphasized that to ensure high data quality, the interlanguage dataset used for fine-tuning should be manually annotated by native Polish speakers with expertise in linguistics or second language acquisition.","One promising direction is fine-tuning Whisper using a dedicated interlanguage corpus, training the system to recognize and transcribe interlanguage forms rather than correcting them into standard Polish.",1.0,0.8486451674355148,0.999999999975,1.0
What visualization tool was developed as part of this thesis?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Visualisation tool\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations > Visualisation tool\n\nAs reading data directly from the raw tables can be somewhat unclear, an interactive HTML platform was developed to facilitate the analysis of learners' pronunciation deviations. This tool allows users to filter all identical correct--erroneous phoneme pairs across the corpus, providing a clear overview of recurring patterns. Additionally, the interface includes buttons for switching between standard IPA representations, offering flexibility depending on the focus of the analysis. The platform serves as a valuable resource for further examining tendencies in Polish interlanguage among learners from the aforementioned countries. Moreover, it enables more detailed investigations into how specific characteristics of learners' native languages may contribute to disfluencies and other systematic deviations."", ""Headers: Introduction > General Presentation\nHeaders: Introduction > General Presentation\n\nThis thesis was carried out as part of an internship at the *Structures Formelles du Langage* laboratory within the Master's program in Natural Language Processing (*Traitement Automatique des Langues*) at Inalco. The primary objective of this work is to conduct a thorough analysis of automatic tools in the context of Polish interlanguage, as produced by learners during second language acquisition. While automatic speech recognition (ASR) systems have achieved remarkable accuracy for standard languages, their application to second language production remains challenging. Learners' productions often exhibit variations that differ from those of native speakers, which standard ASR systems are not trained to recognize. Nevertheless, ASR offers promising possibilities for the transcription of learner interlanguage."", ""Headers: Experimentations > Corpus > Annotation and Preprocessing > Tools and Implementation\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Tools and Implementation\n\nAll scripts developed in this thesis were implemented in Python within a Jupyter Notebook environment. For the automatic speech recognition of learners' utterances, we used the small model of Whisper by OpenAI, in automatic language mode, provided by Huma-Num servers, since Polish was not available.  \nThe implementation further relied on a range of Python libraries, including *spaCy* for morphosyntactic analysis, *pandas* for data manipulation, *fuzzywuzzy* (Levenshtein distance) for fuzzy string matching, *Epitran* for grapheme-to-phoneme transcription, *langdetect* for language detecting, *matplotlib* and *seaborn* for visualization, *JiWER* for calculating WER and CER, as well as *json*, *xml.etree*, and *csv* for structured data processing and file management.  \nThis configuration ensured reproducibility and scalability, while enabling the efficient integration of data processing, linguistic analysis, and evaluation procedures."", ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data.""]","An interactive HTML platform was developed to facilitate the analysis of learners' pronunciation deviations. This tool allows users to filter all identical correct--erroneous phoneme pairs across the corpus, providing a clear overview of recurring patterns. It also includes buttons for switching between standard IPA representations, allowing flexibility in the analysis of learners' pronunciation tendencies related to Polish interlanguage (see context).","An interactive HTML platform was developed to facilitate the analysis of learners' pronunciation deviations, allowing users to filter identical correct-erroneous phoneme pairs and switch between standard IPA representations.",1.0,0.32012066674912376,0.9999999999,1.0
What is the role of the Epitran library in this study?,"['Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.', ""Headers: General Context > Context > Conclusions\nHeaders: General Context > Context > Conclusions\n\nThis chapter established the theoretical and empirical foundations of the study. It introduced the concept of interlanguage as a transitional system shaped by both the target language and the learner's native language, highlighting its systematic and specific nature in adult second language acquisition. The discussion of Polish phonetics and morphosyntax emphasized the particular challenges posed by complex consonant clusters, nasal vowels, and the highly inflected case system, which together account for many learner difficulties. Finally, the presentation of the VILLA project and the Route Direction task provided the methodological framework on which the corpus of this thesis is based. Together, these components justify a detailed investigation of learner language patterns and the potential of automatic tools to process interlanguage data."", 'Headers: Experimentations > Corpus > Introduction\nHeaders: Experimentations > Corpus > Introduction\n\nThis chapter presents the learner and native speaker data used in the study, as well as the preprocessing and annotation procedures applied. It describes the collection, transcription, and organization of recordings from the Route Direction task, detailing both manual and automatic processing steps. The chapter also explains the rationale behind the corpus design, including decisions regarding participant selection, data format, and handling of interlanguage-specific phenomena, in order to ensure a reliable and analyzable dataset for subsequent linguistic and ASR evaluation.', ""Headers: Experimentations > Corpus > Conclusions\nHeaders: Experimentations > Corpus > Conclusions\n\nThis chapter described the composition and preparation of the corpora that form the basis of the present study. The learner corpus, derived from the VILLA project, was carefully transcribed and annotated to reflect both the learners' productions and their corrected Polish counterparts, amounting to a total of 89 files and 2 hours and 19 minutes of recordings, while the smaller native speaker corpus serves as a comparative benchmark. The annotation and preprocessing pipeline, combining manual and automatic procedures, allowed for the integration of multiple sources of data into a consolidated JSON file enriched with lemma-based alignments. Despite certain limitations (such as the difficulty of automatically detecting highly distorted forms) the resulting dataset provides a robust and structured resource for subsequent analyses. Overall, the corpora and their preparation ensure a reliable foundation for the evaluation of linguistic errors and the performance of automatic tools such as Whisper in processing Polish interlanguage.""]",This question is not related to the provided thesis context.,The Epitran library was used to convert correct and erroneous word forms into their phonetic (IPA) representations for fine-grained analysis of pronunciation patterns and errors across learners.,0.0,0.0,0.0,0.0
Which learner group showed the highest CER scores according to the analysis?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance\n\nIt is important to note that WER tends to be a weaker metric than CER for the evaluation of interlanguage. As [@wrro207725] point out, WER does not correlate well with human intelligibility, since it ignores semantics, pragmatics, grammar, and other functional aspects of language. In the case of learner speech, this issue is even more pronounced: deviations, particularly those related to pronunciation, often cause entire words to be misrecognised, which heavily penalises the ASR system at the word level. By contrast, CER provides a more fine-grained perspective, as even partially correct transcriptions are rewarded for character-level similarity. Consequently, CER better reflects the degree to which the ASR output preserves traces of the learner's original production, making it a more informative measure in the context of multilingualism [@k2024advocatingcharactererrorrate]."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\nHeaders: Experimentations > Evaluation of Whisper's Performance > Global Performance > WER and CER Results\n\n:::\n**Metric**            **Score**\n-------------------- ----------- --\nWER mean                0.754\nWER median              0.500\nCER mean                0.464\nCER median              0.222\nWER mean (natives)      0.137\nCER mean (natives)      0.064  \n: Global statistics for WER (Word Error Rate) and CER (Character Error Rate)\n:::  \nThe overall results show that Whisper faces significant challenges when transcribing Polish interlanguage. The average WER reaches 75.4%, while the CER of 46.4% reflects frequent inaccuracies at both the word and character level. As expected, the lower CER compared to WER reflects partially correct words that preserve some letters, capturing mostly phonetic approximations typical of interlanguage speech.  \nA major challenge is the presence of spikes or hallucinated outputs, where Whisper produces incorrect words or phrases, often influenced by strong accents or code-switching. Country-specific performance varies: Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.  \nConsequently, to mitigate the effect of extreme errors, median scores were computed: median WER is 50%, and median CER ranges is 22.2%.  \nIn contrast, evaluation on the small corpus of native Polish speech revealed substantially lower error rates, with a WER of 13.74% and a CER of 6.44%. According to [@elayari:hal-04769687], a WER between 10% and 20% is considered good, indicating that Whisper can reliably transcribe native Polish utterances. The stark difference between the learner and native corpora clearly illustrates the impact of interlanguage on Whisper's performance, highlighting the additional challenges posed by non-native pronunciation, variable articulation, and learner-specific speech patterns."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Introduction\nHeaders: Experimentations > Qualitative Linguistic Analysis > Introduction\n\nThe first analysis conducted in this study focused on the non-standard forms made by learners. The primary objective was to identify the most common types of deviations produced by learners of Polish after a 14-hour course. In addition, the second goal was to investigate the potential influence of the learners' native languages on the nature of these productions. To facilitate a clearer visualization of deviations, a dedicated tool-platform will also be developed, enabling an easier and more systematic analysis of the data."", 'Headers: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\nHeaders: General Context > State of the Art > Automatic Speech Recognition for L2 Speech\n\nBuilding on this line of inquiry, [@elayari:hal-04769687] evaluated Whisper on a longitudinal French L2 learner corpus and found that, although the system achieved relatively good WER and CER scores on advanced learners, it often ""hyper-normalized"" learner speech by correcting errors (e.g., *expériencer* $\\rightarrow$ *expérimenter*), introducing hallucinations, or omitting disfluencies such as repetitions and pauses. This tendency compromises the reliability of ASR as a tool for SLA research, since deviations from the target norm are precisely the phenomena under investigation. At the same time, the authors note that ASR performance improves with learner proficiency, suggesting that error rates may indirectly reflect acquisition progress. They conclude that learner corpora should be conceptualized as a low-resource language variety and that fine-tuning ASR models on such data is crucial to ensure faithful transcription and avoid overcorrection.']","The learner group that showed the highest CER scores, according to the analysis, was the Italian and British learners, both of whom had CERs above 60% (K et al., 2024).","Italian and British learners showed the highest CERs (above 60%), while Dutch learners achieved the lowest (27%), likely due to clearer articulation.",1.0,0.9888653351232073,0.49999999995,1.0
What does the thesis conclude about the relationship between case-related errors and learners' native languages?,"[""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", ""Headers: Experimentations > Future Perspectives > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives > Open Questions and Obstacles\n\nA key question in designing such a system is whether it should be tailored to learners of a specific native language or whether a more general model would suffice. On the one hand, the error analysis in this study shows that speakers of different native languages often exhibit consistent patterns, particularly in pronunciation. This suggests that separate models for pronunciation errors could be developed for different L1 groups, although some errors may also be universal across learners. On the other hand, case-related errors appear to be largely independent of the learner's native language, indicating that a universal model would likely be sufficient for handling morphological deviations.  \nA major challenge remains the inherently dynamic and individual nature of interlanguage. Learners follow unique developmental trajectories, and errors evolve over time depending on exposure, proficiency, and learning strategies. This raises questions about whether separate corpora or models would be needed for different proficiency levels, which would significantly increase data requirements and necessitate careful learner selection.  \nFinally, the corpus used in this study is highly task-specific, focusing exclusively on giving and understanding route directions. To develop a more robust and generalizable interlanguage-adapted Whisper, training data would need to cover a broader variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across different communicative situations.  \nAnother avenue for future development is the creation of a dual-model system for language learning. One model could faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while a second model could provide the corrected, standard version of the utterance. Such a setup would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', 'Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.']","The thesis concludes that case-related errors are not strongly dependent on the learners' native languages. The analysis indicates that such errors reflect universal developmental patterns and the inherent complexity of the Polish case system, rather than being significantly influenced by the learners' L1 (original citation tags: [Results], [Conclusions]).",The thesis concludes that case-related errors are not strongly dependent on the learners' native language and instead reflect universal developmental patterns and the inherent complexity of the Polish case system.,1.0,0.9713058277050026,0.9999999999666667,1.0
What conclusions does the thesis draw about pronunciation errors and native language influence?,"['Headers: Experimentations > Qualitative Linguistic Analysis > Conclusions\nHeaders: Experimentations > Qualitative Linguistic Analysis > Conclusions\n\nFrom the analysis of both declension and pronunciation errors, several important conclusions can be drawn.  \nFirstly, with respect to declension, learners tend to overuse the nominative case, which functions as the default or \\""base\\"" form in Polish. In the absence of explicit grammatical knowledge, this case is often overgeneralized to contexts where other forms are required. The results also demonstrate frequent confusion between the genitive, instrumental, locative, and accusative cases, largely due to their morphologically similar suffixes. Such overlap makes them particularly challenging to acquire. Importantly, the analysis suggests that case-related errors are not strongly dependent on the learners\' native language (at least within the five examined groups). Instead, they reflect universal developmental patterns and the inherent complexity of the Polish case system. Regarding pronunciation, the errors indicate systematic challenges with Polish retroflex consonants and nasal vowels. While the specific realizations vary across learners\' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. The patterns observed in the full dataset available through the visualization platform can be used to conduct a more detailed examination of pronunciation deviations, which in turn may facilitate a more effective adaptation of Whisper for accurate interlanguage transcription across different learner groups.', ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena.""]","The thesis concludes that pronunciation errors in Polish interlanguage are influenced by the learners' native languages, as learners often substitute unfamiliar Polish sounds with more familiar ones from their L1. However, the study also indicates that while there may be some transfer from the native language, the predominant challenges arise from the intrinsic complexity of Polish sounds, particularly retroflex consonants and nasal vowels. The analysis suggests that errors related to pronunciation become systematic patterns, yet the variability seen across different language groups points to the complexities of adapting to Polish phonology rather than a direct or consistent influence of the learners' native languages (c.f. the general conclusion).","While specific realizations vary across learners' native languages, clear tendencies can be observed for different language groups, suggesting that learners often substitute unfamiliar Polish sounds with more familiar ones from their L1.",0.875,0.7084371380499528,0.999999999975,1.0
What were the most frequently required grammatical cases in the Route Direction task?,"[""Headers: General Context > Context > The VILLA Project > Description of the Task\nHeaders: General Context > Context > The VILLA Project > Description of the Task\n\nAt the end of the course, the students' language skills were tested, during which they had to speak in Polish independently (without any help). One of the tasks, called *Route Direction*, required students to give directions from point A to point B using a map. The same map was used for all participants and included named streets and visual representations of places such as a hospital, school, restaurant, store, etc.  \nThe oral productions during these tests were recorded and later transcribed. These transcriptions constitute the corpus we used in this work."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nA similar pattern can be observed with accusative errors: 53.85% of incorrect accusative forms were used in contexts where the genitive was required, and 23.08% where the instrumental was expected. In such situations, learners may simply not recall the correct case and default to a form they have encountered more often or that sounds familiar.  \nThese tendencies underscore the crucial role that morphological endings play in learner errors. The overlap of case endings, combined with limited exposure and overgeneralisation, leads to predictable yet systematic patterns of confusion in learners' oral productions.  \nOverall, there is little evidence to suggest that the learners' native language had a significant influence on their case-related errors. While some languages like German also feature grammatical cases, the structure and endings differ considerably from those in Polish. Even if certain similarities exist, they do not seem to systematically affect learners' performance in this corpus. Moreover, the pedagogical method used in this project is an important factor to consider: rather than learning through explicit grammar instruction and memorisation of case endings, students were primarily exposed to native speaker input and encouraged to repeat phrases. This focus on auditory learning may have reduced the potential for native language transfer. Although cross-linguistic influence cannot be entirely ruled out, the variation and nature of errors suggest that case-related difficulties arise more from the complexity of the Polish case system itself than from the influence of the learners' L1."", 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\n**Case**    **Expected cases**   **Produced cases**   **Difference (%)**\n---------- -------------------- -------------------- --------------------\nAcc                 16                   13                 -18.75\nGen                106                   5                  -95.28\nIns                 59                   7                  -88.14\nLoc                 11                   19                 72.73\nNom                 12                  125                 941.67  \n: Comparison of expected and produced grammatical cases with relative differences (%)  \nThe following analysis of learner data shows that the most frequently required cases, presented in Table -- the genitive and instrumental -- also generate the highest number of errors among learners. The genitive case is typically used to express possession and appears frequently in phrases referring to street names, such as *ulica Juliusza Słowackiego* (\\""Juliusz Słowacki Street\\""). It also follows prepositions like *obok* (\\""next to\\"" or, in this context, \\""past\\""), which are commonly used in giving directions. The instrumental case, on the other hand, is used when describing movement along a path, especially after verbs of motion such as *iść* (\\""to go\\""), as in *iść ulicą Niską* (\\""go along Niska Street\\""). It is also required after the preposition *za* (\\""behind\\""), which frequently appears in this route direction task.  \nMoreover, one of the most common incorrect cases used by learners is the nominative. This is not unexpected, as the nominative is the default case in Polish. It is the form learners are most familiar with, and in the absence of explicit knowledge about declension rules, they often overgeneralize and use the nominative in contexts that require a different case. This tendency reflects a typical stage in interlanguage development, where learners rely on the most salient or frequent forms of the target language.', 'Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Results\n\nIn addition, heatmaps were generated to visualize the distribution of grammatical case errors, comparing the incorrect cases used by learners with the correct ones. Cells outlined in green correspond to correct case usage, but since such examples were excluded from the corpus at an earlier stage, these cells all show zero values.  \nFrom the first table (Figure[]), we can confirm the previously mentioned observation that the nominative case is dominant among incorrect usages. Although the overall number of accusative and locative errors is relatively low, in most of these cases (around 80%), learners incorrectly used the nominative instead of the expected form. Similarly, both genitive and instrumental cases are frequently replaced by the nominative -- approximately 63% of the time -- though some of these errors also involve confusion between genitive, instrumental, and locative.  \nThe locative case, which also appears to be slightly overused, is typically required after prepositions such as *na* (\\""on\\"") or *w* (\\""in\\""). This overuse may stem from learners relying on familiar phrases and generalising them to contexts where other cases are expected. The characteristic suffixes of Polish cases (such as -*u*, -*e*, -*em*, or -*a*) can be particularly misleading for learners. For example, the phrase *obok szpitalu* instead of the correct *obok szpitala* (\\""next to the hospital\\"") illustrates confusion between the genitive and locative, likely influenced by more frequent expressions like *w szpitalu* (\\""in the hospital\\""). In fact, 52.63% of incorrect uses of the locative occurred in contexts where the genitive case was required. Furthermore, 36.84% of the same locative errors involved confusion with the instrumental (*za szpitalem* (\\""behind the hospital\\"")).']","The most frequently required grammatical cases in the Route Direction task were the genitive and instrumental cases. These cases are critical when expressing possession and describing movement along a path, particularly in phrases and prepositions commonly used in giving directions, such as referring to street names and verbs of motion (e.g., *iść*).",The most frequently required cases were the genitive (used for possession and after prepositions like obok) and instrumental (used when describing movement along a path and after the preposition za).,1.0,0.9772246380005207,0.6388888888675925,1.0
What challenge does the Polish case system pose for spaCy's automatic analysis?,"[""Headers: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\nHeaders: General Context > State of the Art > Morphosyntactic Analysis and Case Detection in NLP\n\nMorphosyntactic analysis assigns grammatical categories, such as part of speech, case, number, and gender, to textual units. In highly inflected languages like Polish, this process is essential due to the complexity of declension and conjugation. Accurate morphosyntactic tagging supports various NLP tasks, including syntactic parsing, machine translation, and automatic error detection in language learning. In this study, *spaCy* was used for Polish morphosyntactic analysis, providing lemmatization, part-of-speech tagging, and morphological features, including case information, in a flexible and accessible framework.  \nDetecting grammatical cases in Polish remains challenging due to the language's rich inflectional system. Correct case identification is crucial for analyzing learner speech, as it helps preserve interlanguage features in ASR outputs rather than normalizing them. Although general research on morphosyntactic analysis is extensive, studies focusing on Polish are more limited. Previous works [@kuta2007; @pawlik-etal-2013-optimizing] evaluated tagging accuracy and proposed optimized algorithms for inflectionally rich languages, highlighting the need for tailored approaches. Despite progress, morphological ambiguity and syntactic complexity continue to pose challenges, motivating the integration of advanced neural models with ASR to improve recognition and analysis of learner errors."", ""Headers: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\nHeaders: Experimentations > Qualitative Linguistic Analysis > Declension Deviations > Evaluation of *spaCy* in Case Attribution\n\n**Weighted avg**        0.57           0.67          0.60           36  \n: Classification metrics for a Polish native dataset by grammatical case  \nThe first two results suggest that the interlanguage nature of the data is a significant factor affecting *spaCy*'s performance in case detection; particularly in instances where errors impact the word's suffix due to pronunciation deviation (e. g. *niskon* /ɲiskɔn/ instead of *niską* /ɲiskɔ̃w̃/). However, the tool also struggles with correctly analysing native Polish utterances. It appears that the complexity of the Polish case system itself poses a great challenge for the tool, as well. Consequently, it may be beneficial in future work to incorporate a broader syntactic context by including a few words preceding each analysed token. This could help determine whether *spaCy*'s performance improves when given more linguistic context."", 'Headers: Experimentations > Corpus > Annotation and Preprocessing > Automatic Preprocessing\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Automatic Preprocessing\n\nIn addition, to facilitate the technical processing of the corpus, a script was developed that creates a dictionary grouping words according to their lemmas. It begins by extracting all the correct Polish versions from the dataset and lemmatizing them using the *spaCy* library -- including stopwords, which are also relevant for the analysis since learners sometimes produce distorted forms of these frequent function words. The resulting lemmas are stored in a sorted list.  \nIn the next step, a complete corpus is assembled by combining the automatic transcriptions, manual transcriptions, and the corrected Polish versions. This extended corpus is also lemmatized, and a sorted list of all lemmas is generated.  \nTo identify potentially unknown or erroneous word forms, the script compares the lemmas from the complete corpus with those from the correct Polish data. It then groups together words that belong to the same lemma. Unmatched forms are extracted and aligned with the closest known lemmas using Levenshtein distance. These alignments are stored in a dictionary that merges all words -- both the correct forms and those matched by similarity, while avoiding duplicates (see [] for an example of a group of words associated with the same lemma).  \nIt is important to note certain limitations of the automatic alignment process. Some words could not be matched due to significant distortions produced by learners, which complicates accurate lemma alignment. The short length and limited phonetic richness of stopwords further challenge their automatic grouping. Moreover, stopwords are sometimes confounded with hesitations or interrupted word attempts (e.g., \\""skre\\"" preceding the word *skręcić* is treated as a distinct word), which adds to the complexity of alignment. The final dictionary contributes to the subsequent automatic segmentation of the learners\' transcriptions.', 'Headers: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\nHeaders: General Context > Context > Key Features of the Polish Language for Learners > Morphosyntax: Case System\n\nOne of the greatest grammatical challenges in the Polish language is the inflection of words for case. Case is an inflectional category with a textual function, used to signal the grammatical relationships between elements of a sentence. In Polish, we distinguish seven forms of cases:\\  \n-   Nominative -- Nominativus (Nom.),  \n-   Genitive -- Generativus (Gen.),  \n-   Dative -- Dativus (Dat.),  \n-   Accusative -- Accusativus (Acc.),  \n-   Instrumental -- Instrumentalis (Instr.),  \n-   Locative -- Locativus (Loc.),  \n-   Vocative -- Vocativus (Voc.).  \nParts of speech that are conjugated by cases are nouns, adjectives, numerals, and pronouns.\\\nBelow is an example of the declension of a Polish word -- *sklep* (store) -- depending on its syntactic role within a sentence:  \n:::\n**Case**     **Singular**    **Plural**   **Question (function)**\n-------------- -------------- -------------- -----------------------------------------------------\nNominative       sklep        sklep**y**   who? what? -- subject\nGenitive      sklep**u**    sklep**ów**   of whom? of what? -- possession, negation\nDative      sklep**owi**   sklep**om**   to whom? to what? -- indirect object\nAccusative       sklep        sklep**y**   whom? what? -- direct object\nInstrumental   sklep**em**    sklep**ami**  with whom? with what? -- means or accompaniment\nLocative     sklep**ie**    sklep**ach**  where? about whom? about what? -- location or topic\nVocative     sklep**ie**     sklep**y**   O! -- direct address  \n: Declension of the noun \\""sklep\\"" in Polish\n:::']","The Polish case system poses a significant challenge for spaCy's automatic analysis due to the complexity of inflection involved. The rich inflectional system, which includes seven grammatical cases, leads to difficulties in accurately identifying and analyzing grammatical cases, particularly in the presence of morphological ambiguity and syntactic complexity. This complexity can cause spaCy to struggle with both learner utterances, where pronunciation deviations may affect word suffixes, and native Polish utterances as well (@kuta2007; @pawlik-etal-2013-optimizing). Therefore, enhancing the context provided for analysis by including surrounding words may improve performance in case attribution.","The Polish case system is highly complex because a single inflected form may correspond to multiple cases, and accurately identifying the correct case often requires considering the broader syntactic context of the word within the sentence.",1.0,0.9898675182708133,0.999999999975,1.0
What percentage of interlanguage words in the pronunciation subcorpus were invented by Whisper?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena."", ""Headers: Experimentations > Future Perspectives > Introduction\nHeaders: Experimentations > Future Perspectives > Introduction\n\nOne promising direction for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage. This could potentially be achieved through fine-tuning the model using a dedicated interlanguage corpus. In such a setup, the system would be trained to recognize and transcribe interlanguage forms, rather than correcting them into standard Polish. The new vocabulary -- reflecting common learner errors -- would help the model predict and output words closer to what the learner actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers, ideally with a background in linguistics or second language acquisition.""]","In the pronunciation subcorpus, Whisper produced entirely new words in 108 cases, which corresponds to 16.31% of the dataset.","Whisper produced entirely new words (hallucinations) in 108 cases, representing 16.31% of the pronunciation-related interlanguage corpus.",1.0,0.8266228647558426,0.49999999995,1.0
How many non-Polish transcriptions were generated by Whisper due to hallucinations?,"[""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Pronunciation-Related Interlanguage\n\n: Distribution of interlanguage words by categories (pronunciation-related errors)\n:::  \nWithin this interlanguage subset, 72 words (10.88%) were transcribed identically by Whisper, showing complete overlap between the learner's pronunciation and the model's output. Although this represents a relatively small proportion of the data, it suggests that adapting Whisper for interlanguage transcription may be feasible. As expected, the majority of words (57.1%) were overcorrected. In 202 cases (30.51%), Whisper replaced the interlanguage form with a standard Polish word that was correct in the given context, whereas in 176 cases (26.59%) the substitution was contextually inappropriate, despite the word being valid in Polish. This tendency indicates that, when processing Polish interlanguage, Whisper often normalizes non-standard learner forms into standard Polish rather than reproducing them faithfully. The model also produced entirely new words in 108 cases (16.31%), generating sequences absent from both the original utterance and the Polish lexicon. This behaviour reflects Whisper's inclination to produce plausible-sounding vocabulary when confronted with highly deformed or unclear learner speech. Finally, in 104 instances (15.71%), no transcription was produced at all, a result which nonetheless accounts for a substantial share of the dataset and points to persistent recognition difficulties with certain types of interlanguage input."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\nHeaders: Experimentations > Evaluation of Whisper's Performance > Evaluation on Polish Interlanguage > Evaluation on Declension-Related Interlanguage\n\n**Total**                                                     525                       100%  \n: Distribution of interlanguage words by categories (declination-related errors)\n:::  \nThe results show that in 42.10% of cases, Whisper faithfully reproduced learners' error, indicating that the system was able to capture the incorrect form as produced. This proportion is notably higher than that observed in the pronunciation error data (10.88%). Invented forms, where Whisper produced a grammatical form different from both the learner's and the correct form, accounted for 20.57% of the dataset. Overcorrections were observed in 21.71% of examples, where the system replaced the learner's form with a different, correct form, potentially masking the learner's actual interlanguage pattern. Not transcribed items represented 8.19%, reflecting instances where the system failed to recognize any input, while in 7.43% of cases the output was ambiguous or unidentifiable."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Introduction\nHeaders: Experimentations > Evaluation of Whisper's Performance > Introduction\n\nThis chapter evaluates Whisper's performance in transcribing Polish interlanguage, focusing on its ability to faithfully reproduce learners' speech, including errors and non-standard forms. The analysis highlights the challenges posed by interlanguage, including pronunciation deviations and grammatical errors, and provides insights into the model's strengths and limitations in this context."", ""Headers: Experimentations > Evaluation of Whisper's Performance > Conclusions\nHeaders: Experimentations > Evaluation of Whisper's Performance > Conclusions\n\nThe analyses of Whisper's performance on Polish interlanguage highlight distinct tendencies depending on the type of learner errors. For pronunciation errors, the system often overcorrects learner speech, reproducing canonical forms rather than the actual interlanguage output. In contrast, for declension errors, Whisper more frequently reproduces the learner's forms faithfully. However, even the 42% rate of faithful reproduction is still insufficient, indicating that improvements are needed to better capture case-related deviations.  \nThese patterns suggest that Whisper's current architecture is more suited to detecting systematic grammatical errors than phonetic inaccuracies. However, in the context of automatic transcription of interlanguage, this implies that while Whisper can provide a foundation for monitoring learner productions, enhancing the model's sensitivity to both pronunciation and declension deviations would make it a more effective tool for accurately capturing interlanguage phenomena.""]","Whisper generated entirely new words in 108 cases (16.31%), which reflects the system's inclination to produce non-Polish sequences when confronted with highly deformed or unclear learner speech.","Out of 89 examples, 15 were generated in a language other than Polish, caused by the highly distorted nature of the interlanguage and rare instances where learners briefly switched to their native language.",1.0,0.5523263613095591,0.0,0.0
What is input in the context of second language acquisition research?,"['Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nThe project VILLA (\\""Varieties of Initial Learners in Language Acquisition: Controlled classroom input and elementary forms of linguistic organisation\\"") conducted by [@dimroth-2013], investigated the initial stages of foreign language acquisition under controlled input conditions. In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system. The study involved complete beginners from five different linguistic backgrounds -- Dutch, English, French, German, and Italian -- who each received 14 hours of instruction in Polish as a foreign language.  \nThe project consisted of Polish language classes delivered by native Polish teachers, with communication-based methods. For each language group, two subgroups of up to 20 participants were formed, with members sharing similar profiles in terms of age, linguistic background, and field of study. All adult participants were university students, and none had any prior knowledge of Polish or another Slavic language [@dimroth-2013].  \nThe classes were monolingual and learners were not allowed to take notes or consult additional sources of information. Instruction relied on visual aids such as presentations with pictures, recordings of dialogues and short video clips. The input was delivered in interactive and relatively natural conditions, and all sessions were recorded and transcribed for detailed analysis [@dimroth-2013].', 'Headers: General Context > Context > The VILLA Project > Structure and Goals\nHeaders: General Context > Context > The VILLA Project > Structure and Goals\n\nAs previously mentioned, each native language group was divided into two subgroups, receiving different types of input: one meaning-based and the other form-based. Learners exposed to meaning-based input received only structured input focused on communication, without any meta-linguistic explanations or explicit correction. Overall, the teacher did not prompt learners to reflect on language forms. In contrast, learners who received form-based input were explicitly directed to notice morphological forms and rules [@dimroth-2013].', 'Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nOverall, the findings of this work contribute to a better understanding of the processes involved in the earliest stages of second language acquisition. They emphasize the importance of taking into account both cross-linguistic influences and the structural characteristics of the target language when developing tools for the automatic transcription of interlanguage. Furthermore, the integration of computational tools into corpus-based research holds promise for more efficient and large-scale analyses of learner data.', 'Headers: General Context > Context > Introduction\nHeaders: General Context > Context > Introduction\n\nThis section outlines the theoretical and empirical foundations relevant to the present study. It introduces the concept of interlanguage in second language acquisition, outlines the key linguistic features of Polish relevant for learners, and presents the VILLA project, which constitutes the source of the learner corpus analyzed in this thesis. Together, these elements establish the linguistic, cognitive, and pedagogical context in which the automatic transcription and error analysis of Polish interlanguage is conducted.']","In the context of second language acquisition research, input refers to the language that learners are exposed to in the target language. This input serves as the primary source of linguistic data that aids in the development of their interlanguage system (Dimroth et al., 2013).","In second language acquisition research, input refers to the language learners are exposed to in the target language, which provides the primary source of linguistic data for developing their interlanguage system.",1.0,0.9625535706742481,0.999999999975,1.0
What limitation was found with using langdetect for identifying non-Polish words in the learner corpus?,"['Headers: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\nHeaders: Experimentations > Corpus > Annotation and Preprocessing > Manual Preprocessing\n\nAt this point, the corpus was not yet complete; however, the preliminary results showed that the majority (66%) of the words detected as belonging to another language were in fact erroneous forms from the learners\' Polish interlanguage. Although some words were correctly classified (in bold), they remained a minority. Unfortunately, as many words from the \\*STU segments were simplified attempts at Polish words, the program sometimes incorrectly classified them as belonging to other languages.  \nTo allow for comparison with the native Polish corpus, the same language detection library was applied to the transcriptions produced by the four native speakers. Out of a total of 96 words, only one word -- the Polish word *teraz* (\\""now\\"") -- was mistakenly identified as Italian, representing just 1% of the data. This result confirms the overall reliability of the language detection tool and suggests that the challenges observed in the learner corpus are primarily due to the deformed nature of interlanguage forms rather than limitations of the library itself.  \nThis demonstrates that the automatic method was unreliable. As a result, the removal of non-Polish words had to be done manually.', 'Headers: Experimentations > Corpus > Learner Corpus\nHeaders: Experimentations > Corpus > Learner Corpus\n\nEngland                      17                 29 minutes 34 seconds\nGermany                      20                 30 minutes 42 seconds  \n: Summary of recordings by country\n:::  \nAs previously mentioned, Polish is a relatively difficult language to acquire, especially for learners with no prior exposure to Slavic languages. One of the primary challenges lies in its phonological system, which includes numerous sounds absent in many other languages. Another major difficulty is its grammar, especially the complex system of case inflection. After only 14 hours of study, it is expected that learners will produce numerous errors. The aim of this study is to faithfully represent these mistakes in order to contribute to improving the quality of foreign language instruction.  \nIt is important to note that all segments were transcribed in accordance with standard Polish orthographic norms. Consequently, pronunciation errors were indicated through Polish spelling rather than phonetic transcription using the International Phonetic Alphabet (IPA). For instance:  \n:::\n**\\*STU**        **%pol**\n----------------------- -----------------------\nza **sz**klepe (\\...)  za **s**klepem (\\...)  \n: Example forms\n:::  \nIn this example, the learner replaced the voiceless alveolar fricative /s/ in the instrumental form of the word *sklep* with the retroflex /ʂ/, represented in Polish orthography by the digraph *sz*. Additionally, the final /m/ was omitted.\\', 'Headers: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\nHeaders: Experimentations > Qualitative Linguistic Analysis > Pronunciation Deviations\n\nAnother significant challenge for the learners was Polish pronunciation, mostly due to its complex consonant clusters and unfamiliar sounds. A clear example is the verb *skręcić* (\\""to turn\\""), which contains a consonant cluster at the beginning (*skr*-) that is difficult to articulate for many non-native speakers. Additionally, the nasal vowel *ę* and the soft *ć* at the end require precise articulation that may not exist in the learners\' native phonetic systems. This combination of sounds makes words like *skręcić* particularly hard to pronounce accurately for beginners. Such pronunciation challenges often lead to distorted forms, contributing significantly to the deviations observed in interlanguage speech.', ""Headers: Experimentations > General conclusion\nHeaders: Experimentations > General conclusion\n\nThe present study has investigated the acquisition of Polish as a foreign language by adult learners within the framework of the VILLA project, focusing in particular on oral production data collected from the Route Direction task. By combining manual transcriptions with automatic speech recognition with Whisper, the research has offered both a qualitative and quantitative perspective on learner errors, with special attention to the influence of the native language and the challenges posed by the phonological and morphological systems of Polish.  \nThe analysis has highlighted that interlanguage remains a dynamic and systematic system shaped by a variety of factors, including but not limited to the learners' mother tongue. While some transfer from the native language was likely, particularly in pronunciation-related cases, the results also showed that learners employed strategies such as simplification, overgeneralization, or omission, confirming the multifaceted nature of early second language acquisition. The frequent occurrence of errors related to pronunciation and case marking further underlines the intrinsic complexity of Polish for non-Slavic learners, especially after such limited exposure.  \nAt the methodological level, the study has shown the relevance of combining manual annotation with automatic tools. Although automatic speech recognition systems like Whisper are not flawless in handling learner data, they provide a useful starting point for analysis and open perspectives for future applications in second language research and pedagogy.""]","The limitation found with using langdetect for identifying non-Polish words in the learner corpus was that it classified a significant number of words incorrectly due to the erroneous forms produced by the learners' Polish interlanguage. A notable example was that 66% of the words detected as belonging to another language were actually erroneous forms, which led to the conclusion that the automatic method was unreliable. Consequently, the removal of non-Polish words had to be done manually (citation tags: *STU*).","The automatic language detection method was unreliable because many simplified interlanguage words were incorrectly classified as belonging to other languages, as they were deformed attempts at Polish words rather than actual foreign language words.",1.0,0.9709354247815862,0.9999999999,1.0
What dual-model system is proposed for future language learning applications?,"[""Headers: Experimentations > Future Perspectives > Open Questions and Obstacles\nHeaders: Experimentations > Future Perspectives > Open Questions and Obstacles\n\nA key question in designing such a system is whether it should be tailored to learners of a specific native language or whether a more general model would suffice. On the one hand, the error analysis in this study shows that speakers of different native languages often exhibit consistent patterns, particularly in pronunciation. This suggests that separate models for pronunciation errors could be developed for different L1 groups, although some errors may also be universal across learners. On the other hand, case-related errors appear to be largely independent of the learner's native language, indicating that a universal model would likely be sufficient for handling morphological deviations.  \nA major challenge remains the inherently dynamic and individual nature of interlanguage. Learners follow unique developmental trajectories, and errors evolve over time depending on exposure, proficiency, and learning strategies. This raises questions about whether separate corpora or models would be needed for different proficiency levels, which would significantly increase data requirements and necessitate careful learner selection.  \nFinally, the corpus used in this study is highly task-specific, focusing exclusively on giving and understanding route directions. To develop a more robust and generalizable interlanguage-adapted Whisper, training data would need to cover a broader variety of linguistic contexts and speaking styles, including both spontaneous and scripted speech across different communicative situations.  \nAnother avenue for future development is the creation of a dual-model system for language learning. One model could faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while a second model could provide the corrected, standard version of the utterance. Such a setup would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction."", ""Headers: Experimentations > Future Perspectives > Introduction\nHeaders: Experimentations > Future Perspectives > Introduction\n\nOne promising direction for improving Whisper's performance on learner speech is the development of a version adapted specifically to Polish interlanguage. This could potentially be achieved through fine-tuning the model using a dedicated interlanguage corpus. In such a setup, the system would be trained to recognize and transcribe interlanguage forms, rather than correcting them into standard Polish. The new vocabulary -- reflecting common learner errors -- would help the model predict and output words closer to what the learner actually said. However, to ensure high data quality and reliability, the interlanguage dataset used for fine-tuning would need to be manually annotated by native Polish speakers, ideally with a background in linguistics or second language acquisition."", 'Headers: General Context > State of the Art > Conclusions\nHeaders: General Context > State of the Art > Conclusions\n\nAutomatic Speech Recognition has achieved remarkable progress, but accurately processing non-native speech remains a significant challenge. Systems trained on native input often misrepresent learner productions, either masking errors or providing misleading corrections. Recent research shows that error-preserving approaches, fine-tuned on learner data, can substantially improve both accuracy and the faithful representation of interlanguage features.  \nIn the case of Polish, challenges are even greater due to rich morphology, free word order, and complex phonetics. Early systems demonstrated potential but lacked robustness, while modern end-to-end models like Whisper risk excessive normalization. Moving forward, progress depends on adapting large ASR models through fine-tuning on learner corpora and combining them with morphosyntactic analysis, ensuring that learner-specific patterns are captured rather than erased. Such tailored approaches hold promise for advancing research on non-native speech.', 'Headers: General Context > State of the Art > Introduction\nHeaders: General Context > State of the Art > Introduction\n\nAutomatic Speech Recognition (ASR) has undergone remarkable progress in recent decades, evolving from early systems limited to a small set of commands to deep learning--based models capable of handling spontaneous, continuous speech in real-world conditions. While ASR technologies are now widely applied in domains such as virtual assistants, customer service, and accessibility tools, their use in second language (L2) learning and assessment still requires careful evaluation of their performance.']","The proposed dual-model system for future language learning applications consists of two models: one model would faithfully reproduce the learner's interlanguage, showing exactly what the learner said, while the second model would provide the corrected, standard version of the utterance. This configuration would allow learners to compare their own productions with the target forms, supporting both self-monitoring and guided correction.","A dual-model system is proposed where one model faithfully reproduces the learner's interlanguage (showing exactly what the learner said) while a second model provides the corrected standard version, allowing learners to compare their productions with target forms.",1.0,0.9569586113190202,0.999999999975,1.0
